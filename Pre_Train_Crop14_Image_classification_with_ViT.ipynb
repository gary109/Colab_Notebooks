{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-Train Crop14 Image classification with ViT",
      "provenance": [],
      "collapsed_sections": [
        "kYFkur3sEb6f",
        "NhO8MiJ41HLI",
        "F3AZ8EIyzzir",
        "5lYnSRfsvhd_",
        "hTFjalcwapjx",
        "XYwSZcbDD-ir"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gary109/Colab_Notebooks/blob/main/Pre_Train_Crop14_Image_classification_with_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Á¢∫Ë™ç GPU È°ûÂûã\n",
        "---"
      ],
      "metadata": {
        "id": "2ozr9xyv0ZMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
        "print(\"device name\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "DJgt_njFcA4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6f779d-67c6-4c5a-e213-7955bcfc6b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device name Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÊòØÂê¶Ë¶ÅÊéõËºâ Google Drive\n",
        "---"
      ],
      "metadata": {
        "id": "2kKsDcHu0hlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yEXRaZK1lWUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f37fd8-beb0-457c-8011-4f21f433846c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Á¢∫Ë™ç Ôº¥Ôº∞ÔºµË¶èÊ†º"
      ],
      "metadata": {
        "id": "kYFkur3sEb6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "ZCfuY-RMEctt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÂÆâË£ù transformers,datastes,... Áõ∏‰æùÂ•ó‰ª∂\n",
        "---"
      ],
      "metadata": {
        "id": "1O9n-3Ak0rik"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8eh87Hoee5d"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/huggingface/datasets.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install soundfile\n",
        "!pip install jiwer\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!apt install git-lfs\n",
        "!git config --global user.email \"gary109@gmail.com\"\n",
        "!git config --global user.name \"GARY\"\n",
        "!git config --global credential.helper store\n",
        "!pip install wandb\n",
        "!wandb login 2cf656515a3b158f4f603aeba63181236de2fc1b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÁôªÂÖ• huggingface \n",
        "---"
      ],
      "metadata": {
        "id": "A1JcSRcJ0_uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login\n",
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "fLI9ee6CkBQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac486bf3-d918-4ad4-e144-a6ec0e72ba92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens.\n",
            "        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n",
            "        \n",
            "Token: \n",
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‰∏ãËºâ ai-cup-2022-crop_classification Á®ãÂºèÁ¢º\n",
        "--- "
      ],
      "metadata": {
        "id": "NhO8MiJ41HLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://gary109:Gygy844109109@gitlab.com/gary109/ai-cup-2022-crop_classification.git"
      ],
      "metadata": {
        "id": "IfPGSNnqqdLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ËºâÂÖ• crop14-small crop14-balance crop14-pretrain Ë®ìÁ∑¥Ë≥áÊñôÈõÜ\n",
        "---"
      ],
      "metadata": {
        "id": "RcO8DSXZz7W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/datasets/crop14.py /content\n",
        "!cp /content/drive/MyDrive/datasets/crop14_colab.py /content"
      ],
      "metadata": {
        "id": "r_94awLWqXyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "# # dataset = load_dataset(\"/content/ai-cup-2022-crop_classification/datasets/crop14.py\", 'crop14-small')\n",
        "# dataset = load_dataset(\"/content/crop14.py\", 'crop14-balance')\n",
        "# dataset = load_dataset(\"gary109/crop14_balance\", use_auth_token=True)\n",
        "# dataset = load_dataset(\"gary109/crop14-small\", use_auth_token=True)\n",
        "# dataset = load_dataset(\"gary109/crop14-pretrain\", use_auth_token=True, cache_dir='/content/drive/MyDrive/datasets/crop14-pretrain')\n",
        "dataset = load_dataset(\"gary109/crop14_balance\", use_auth_token=True, cache_dir='/content/drive/MyDrive/datasets/cache_crop14-balance')\n",
        "dataset"
      ],
      "metadata": {
        "id": "BDNRJpgbkBTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils.dummy_vision_objects import ImageGPTFeatureExtractor\n",
        "import random\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "\n",
        "# def show_examples(ds, seed: int = 1234, examples_per_class: int = 3, size=(100, 100)):\n",
        "\n",
        "#     w, h = size\n",
        "#     labels = ds['train'].features['labels'].names\n",
        "#     # labels = labels[:9]\n",
        "#     grid = Image.new('RGB', size=(examples_per_class * w, len(labels) * h))\n",
        "#     draw = ImageDraw.Draw(grid)\n",
        "#     font = ImageFont.truetype(\"./fonts/LiberationMono-Bold.ttf\", 24)\n",
        "#     for label_id, label in enumerate(labels):\n",
        "\n",
        "#         # Filter the dataset by a single label, shuffle it, and grab a few samples\n",
        "#         ds_slice = ds['train'].filter(lambda ex: ex['labels'] == label_id).shuffle(seed).select(range(examples_per_class))\n",
        "\n",
        "#         # Plot this label's examples along a row\n",
        "#         for i, example in enumerate(ds_slice):\n",
        "#             image = example['image']\n",
        "#             idx = examples_per_class * label_id + i\n",
        "#             box = (idx % examples_per_class * w, idx // examples_per_class * h)\n",
        "#             grid.paste(image.resize(size), box=box)\n",
        "#             draw.text(box, str(label), (255, 255, 255), font=font)\n",
        "\n",
        "#     return grid\n",
        "\n",
        "# show_examples(dataset, seed=random.randint(0, 1337), examples_per_class=3)\n",
        "dataset['train'][random.randint(0, len(dataset['train']))]['image']"
      ],
      "metadata": {
        "id": "PoHV-3ge2iRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset.push_to_hub(\"gary109/crop14-small\")\n",
        "# dataset.push_to_hub('gary109/crop14_balance')\n",
        "# dataset.push_to_hub('gary109/crop14-pretrain')"
      ],
      "metadata": {
        "id": "BjAdBmoLkBWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÂÆâË£ùÂä†ÈÄüÂô®\n",
        "---"
      ],
      "metadata": {
        "id": "F3AZ8EIyzzir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install accelerate deepspeed"
      ],
      "metadata": {
        "id": "u6_ypCvRkBdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config"
      ],
      "metadata": {
        "id": "2MFGLCKC5DHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584a62b0-4088-4d44-b267-94139bc5149b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0\n",
            "Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU): 0\n",
            "Do you want to run your training on CPU only (even if a GPU is available)? [yes/NO]:\n",
            "Do you want to use DeepSpeed? [yes/NO]: \n",
            "How many processes in total will you use? [1]: \n",
            "Do you wish to use FP16 or BF16 (mixed precision)? [NO/fp16/bf16]: fp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate test"
      ],
      "metadata": {
        "id": "I0G_8Qs65EZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FOR TPU needs\n",
        "---"
      ],
      "metadata": {
        "id": "5lYnSRfsvhd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall -y torch\n",
        "!pip install torch==1.8.2+cpu torchvision==0.9.2+cpu -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "94vK4zQPvfGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÈñãÂßãË®ìÁ∑¥\n",
        "---"
      ],
      "metadata": {
        "id": "hdZtjk7Uy2e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/transformers/examples/pytorch/image-pretraining\n",
        "!cp /content/drive/MyDrive/datasets/run_mae.py /content\n",
        "!cp /content/drive/MyDrive/datasets/crop14.py /content\n",
        "!cp /content/drive/MyDrive/datasets/crop14_colab.py /content\n",
        "!cp /content/drive/MyDrive/datasets/run_mim.py /content\n",
        "!cp /content/drive/MyDrive/datasets/run_image_classification.py /content\n",
        "!cp /content/drive/MyDrive/datasets/run_image_classification_no_trainer.py /content\n",
        "!cp /content/drive/MyDrive/datasets/run_image_classification_ViT-MAE.py /content"
      ],
      "metadata": {
        "id": "7E5Kms3u0Gx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAE (by Facebook AI).\n",
        "---"
      ],
      "metadata": {
        "id": "qW0GTGnQzZnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_name_or_path\n",
        "- datasets_name \n",
        "    - [O] crop14-small\n",
        "    - [?] crop14-balance\n",
        "    - [?] crop14-pretrain\n",
        "- model_name_or_path\n",
        "    - [O] google/vit-base-patch16-224-in21k\n",
        "    - [?] google/vit-base-patch16-224-in21k\n",
        "    - [O] google/vit-large-patch16-224-in21k\n",
        "    - [?] google/vit-large-patch32-224-in21k\n",
        "    - [?] google/vit-huge-patch14-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "A5cejFcGAzqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_mae.py \\\n",
        "    --model_name_or_path \"google/vit-huge-patch14-224-in21k\" \\\n",
        "    --dataset_name \"gary109/crop14-small\" \\\n",
        "    --output_dir ./crop14-small_vit-huge-patch14-224-in21k/ \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id crop14-small_vit-huge-patch14-224-in21k \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 30 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 1 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337 \\\n",
        "    --gradient_accumulation_steps 8 \\\n",
        "    --gradient_checkpointing"
      ],
      "metadata": {
        "id": "XBJgzxj05VzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### facebook/vit-mae-large\n",
        "- crop14-balance_pretrain_vit-mae-large\n",
        "---"
      ],
      "metadata": {
        "id": "PntiQvYf92jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!OMP_NUM_THREADS=1 accelerate launch run_mae.py \\\n",
        "    --dataset_name=\"crop14.py\" \\\n",
        "    --dataset_config_name=\"crop14-balance\" \\\n",
        "    --model_name_or_path=\"facebook/vit-mae-large\" \\\n",
        "    --output_dir=\"./crop14-balance_pretrain_vit-mae-large\" \\\n",
        "    --remove_unused_columns=\"False\" \\\n",
        "    --label_names=\"pixel_values\" \\\n",
        "    --mask_ratio=\"0.75\" \\\n",
        "    --norm_pix_loss --do_train --do_eval \\\n",
        "    --base_learning_rate=\"1.5e-4\" \\\n",
        "    --lr_scheduler_type=\"cosine\" \\\n",
        "    --weight_decay=\"0.05\" \\\n",
        "    --num_train_epochs=\"800\" \\\n",
        "    --warmup_ratio=\"0.05\" \\\n",
        "    --per_device_train_batch_size=\"8\" \\\n",
        "    --per_device_eval_batch_size=\"8\" \\\n",
        "    --logging_strategy=\"steps\" \\\n",
        "    --logging_steps=\"10\" \\\n",
        "    --evaluation_strategy=\"epoch\" \\\n",
        "    --save_strategy=\"epoch\" \\\n",
        "    --load_best_model_at_end=\"True\" \\\n",
        "    --save_total_limit=\"3\" \\\n",
        "    --overwrite_output_dir \\\n",
        "    --push_to_hub \\\n",
        "    --hub_model_id=\"crop14-balance_pretrain_vit-mae-large\" \\\n",
        "    --hub_token=\"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\" \\\n",
        "    --seed=\"1337\" \\\n",
        "    --save_steps=\"5000\" \\\n",
        "    --use_auth_token=\"True\" \\\n",
        "    --cache_dir \"./cache_crop14-balance_pretrain_vit-mae-large\"\n",
        "\n",
        "    # --gradient_accumulation_steps=\"8\" \\\n",
        "    # --gradient_checkpointing \\\n",
        "# --dataset_name=\"crop14-balance\" \\\n",
        "# --dataset_name=\"gary109/crop14-balance\" \\\n",
        "# --dataset_config_name=\"crop14-balance\" \\"
      ],
      "metadata": {
        "id": "jlJ2BKsa90N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72be2d96-e3f9-460d-d1f5-cd600bb1bd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: accelerate: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### facebook/vit-mae-base\n",
        "- crop14-balance_pretrain_vit-mae-base\n",
        "---"
      ],
      "metadata": {
        "id": "hTFjalcwapjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch run_mae.py \\\n",
        "    --dataset_name=\"gary109/crop14-balance\" \\\n",
        "    --model_name_or_path=\"facebook/vit-mae-base\" \\\n",
        "    --output_dir=\"./crop14-balance_pretrain_vit-mae-base\" \\\n",
        "    --remove_unused_columns=\"False\" \\\n",
        "    --label_names=\"pixel_values\" \\\n",
        "    --mask_ratio=\"0.75\" \\\n",
        "    --norm_pix_loss --do_train --do_eval \\\n",
        "    --base_learning_rate=\"1.5e-4\" \\\n",
        "    --lr_scheduler_type=\"cosine\" \\\n",
        "    --weight_decay=\"0.05\" \\\n",
        "    --num_train_epochs=\"1000\" \\\n",
        "    --warmup_ratio=\"0.05\" \\\n",
        "    --per_device_train_batch_size=\"8\" \\\n",
        "    --per_device_eval_batch_size=\"8\" \\\n",
        "    --logging_strategy=\"steps\" \\\n",
        "    --logging_steps=\"10\" \\\n",
        "    --evaluation_strategy=\"epoch\" \\\n",
        "    --save_strategy=\"epoch\" \\\n",
        "    --load_best_model_at_end=\"True\" \\\n",
        "    --save_total_limit=\"3\" \\\n",
        "    --overwrite_output_dir \\\n",
        "    --push_to_hub \\\n",
        "    --hub_model_id=\"crop14-balance_pretrain_vit-mae-base\" \\\n",
        "    --hub_token=\"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\" \\\n",
        "    --seed=\"1337\" \\\n",
        "    --use_auth_token=\"True\""
      ],
      "metadata": {
        "id": "JEBRsz1hXsVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Not Ready] facebook/data2vec-vision-base\n",
        "- crop14_balance_pretrain_data2vec-vision-base-mae\n",
        "---"
      ],
      "metadata": {
        "id": "XYwSZcbDD-ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! OMP_NUM_THREADS=1 accelerate launch run_mae.py \\\n",
        "    --dataset_name=\"gary109/crop14_balance\" \\\n",
        "    --model_name_or_path=\"facebook/data2vec-vision-base\" \\\n",
        "    --output_dir=\"./crop14_balance_pretrain_data2vec-vision-base-mae\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --label_names pixel_values \\\n",
        "    --mask_ratio 0.75 \\\n",
        "    --norm_pix_loss \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --base_learning_rate 1.5e-4 \\\n",
        "    --lr_scheduler_type cosine \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --num_train_epochs 1000 \\\n",
        "    --save_steps=\"1000\" \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --per_device_train_batch_size 8 \\\n",
        "    --per_device_eval_batch_size 8 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --push_to_hub \\\n",
        "    --hub_model_id=\"crop14_balance_pretrain_data2vec-vision-base-mae\" \\\n",
        "\t--hub_token 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 \\\n",
        "    --seed 1337"
      ],
      "metadata": {
        "id": "f_yh5I-EEME6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimMIM (by Microsoft Research)\n",
        "---"
      ],
      "metadata": {
        "id": "DYfPoWy7m_lB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### google/vit-base-patch16-224-in21k\n",
        "- crop14-small_pretrain_vit-base-mim"
      ],
      "metadata": {
        "id": "4E2bj-wHBpbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch run_mim.py \\\n",
        "    --dataset_name=\"gary109/crop14-small\" \\\n",
        "    --model_name_or_path=\"google/vit-base-patch16-224-in21k\" \\\n",
        "    --model_type vit \\\n",
        "    --output_dir=\"./crop14-small_pretrain_vit-base-mim\" \\\n",
        "    --overwrite_output_dir \\\n",
        "    --remove_unused_columns False \\\n",
        "    --label_names=\"pixel_values\" \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --num_train_epochs 100 \\\n",
        "    --per_device_train_batch_size 64 \\\n",
        "    --per_device_eval_batch_size 64 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --push_to_hub \\\n",
        "    --hub_model_id=\"crop14-small_pretrain_vit-base-mim\" \\\n",
        "    --hub_token=\"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\" \\\n",
        "    --seed=\"1337\" \\\n",
        "    --use_auth_token=\"True\"\n",
        "\n",
        "# --label_names bool_masked_pos \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4zCymMkncEF",
        "outputId": "16206b6b-8c41-4ad6-b997-b5a9763a0e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/06/2022 13:58:23 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/06/2022 13:58:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.EPOCH,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=crop14-small_pretrain_vit-base-mim,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "label_names=['pixel_values'],\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./crop14-small_pretrain_vit-base-mim/runs/May06_13-58-23_f1d68f6fa2eb,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=100.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=./crop14-small_pretrain_vit-base-mim,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=./crop14-small_pretrain_vit-base-mim,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=3,\n",
            "seed=1337,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.05,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/06/2022 13:58:27 - WARNING - datasets.builder - Using custom data configuration gary109--crop14-small-d2283ee3b6a9a5fe\n",
            "05/06/2022 13:58:27 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/gary109___parquet/gary109--crop14-small-d2283ee3b6a9a5fe/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
            "100% 2/2 [00:00<00:00, 717.16it/s]\n",
            "[INFO|configuration_utils.py:659] 2022-05-06 13:58:28,372 >> loading configuration file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7bba26dd36a6ff9f6a9b19436dec361727bea03ec70fbfa82b70628109163eaa.92995a56e2eabab0c686015c4ad8275b4f9cbd858ed228f6a08936f2c31667e7\n",
            "[INFO|configuration_utils.py:708] 2022-05-06 13:58:28,372 >> Model config ViTConfig {\n",
            "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.19.0.dev0\"\n",
            "}\n",
            "\n",
            "[INFO|feature_extraction_utils.py:465] 2022-05-06 13:58:29,280 >> loading feature extractor configuration file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/7c7f3e780b30eeeacd3962294e5154788caa6d9aa555ed6d5c2f0d2c485eba18.c322cbf30b69973d5aae6c0866f5cba198b5fe51a2fe259d2a506827ec6274bc\n",
            "[INFO|configuration_utils.py:659] 2022-05-06 13:58:30,180 >> loading configuration file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7bba26dd36a6ff9f6a9b19436dec361727bea03ec70fbfa82b70628109163eaa.92995a56e2eabab0c686015c4ad8275b4f9cbd858ed228f6a08936f2c31667e7\n",
            "[INFO|configuration_utils.py:708] 2022-05-06 13:58:30,181 >> Model config ViTConfig {\n",
            "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"patch_size\": 16,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.19.0.dev0\"\n",
            "}\n",
            "\n",
            "[INFO|feature_extraction_utils.py:501] 2022-05-06 13:58:30,182 >> Feature extractor ViTFeatureExtractor {\n",
            "  \"do_normalize\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
            "  \"image_mean\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"image_std\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"resample\": 2,\n",
            "  \"size\": 224\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1953] 2022-05-06 13:58:31,109 >> loading weights file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/d01bfc4a52063e6f2cc1bc7063192e012043a7c6d8e75981bb6afbb9dc911001.e4710baf72bd00d091aab2ae692d487c057734cf044ba421696823447b95521e\n",
            "[WARNING|modeling_utils.py:2255] 2022-05-06 13:58:32,037 >> Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForMaskedImageModeling: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing ViTForMaskedImageModeling from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForMaskedImageModeling from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2266] 2022-05-06 13:58:32,037 >> Some weights of ViTForMaskedImageModeling were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['decoder.0.bias', 'decoder.0.weight', 'embeddings.mask_token']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/./crop14-small_pretrain_vit-base-mim is already a clone of https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "05/06/2022 13:58:42 - WARNING - huggingface_hub.repository - /content/./crop14-small_pretrain_vit-base-mim is already a clone of https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1294] 2022-05-06 13:58:46,140 >> ***** Running training *****\n",
            "[INFO|trainer.py:1295] 2022-05-06 13:58:46,140 >>   Num examples = 1260\n",
            "[INFO|trainer.py:1296] 2022-05-06 13:58:46,140 >>   Num Epochs = 100\n",
            "[INFO|trainer.py:1297] 2022-05-06 13:58:46,140 >>   Instantaneous batch size per device = 64\n",
            "[INFO|trainer.py:1298] 2022-05-06 13:58:46,140 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "[INFO|trainer.py:1299] 2022-05-06 13:58:46,140 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1300] 2022-05-06 13:58:46,141 >>   Total optimization steps = 2000\n",
            "[INFO|integrations.py:577] 2022-05-06 13:58:46,151 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgary109\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220506_135846-2qydnhky\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./crop14-small_pretrain_vit-base-mim\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/gary109/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/gary109/huggingface/runs/2qydnhky\u001b[0m\n",
            "{'loss': 0.4292, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4229, 'learning_rate': 1.98e-05, 'epoch': 1.0}\n",
            "  1% 20/2000 [04:08<6:19:25, 11.50s/it][INFO|trainer.py:2463] 2022-05-06 14:02:58,382 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:02:58,382 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:02:58,382 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.77s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.39572495222091675, 'eval_runtime': 25.937, 'eval_samples_per_second': 5.398, 'eval_steps_per_second': 0.116, 'epoch': 1.0}\n",
            "  1% 20/2000 [04:34<6:19:25, 11.50s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:03:24,321 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-20\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:03:24,322 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-20/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:03:24,892 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-20/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:03:24,892 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-20/preprocessor_config.json\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:03:28,971 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/preprocessor_config.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "05/06/2022 14:03:38 - WARNING - huggingface_hub.repository - Several commits (2) will be pushed upstream.\n",
            "  2% 30/2000 [07:09<7:53:26, 14.42s/it]{'loss': 0.409, 'learning_rate': 1.97e-05, 'epoch': 1.5}\n",
            "{'loss': 0.4008, 'learning_rate': 1.9600000000000002e-05, 'epoch': 2.0}\n",
            "  2% 40/2000 [09:29<6:56:25, 12.75s/it][INFO|trainer.py:2463] 2022-05-06 14:08:19,115 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:08:19,115 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:08:19,115 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:12<00:06,  6.29s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.3701923191547394, 'eval_runtime': 28.5183, 'eval_samples_per_second': 4.909, 'eval_steps_per_second': 0.105, 'epoch': 2.0}\n",
            "  2% 40/2000 [09:57<6:56:25, 12.75s/it]\n",
            "100% 3/3 [00:15<00:00,  4.74s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:08:47,636 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-40\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:08:47,637 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-40/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:08:48,234 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-40/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:08:48,235 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-40/preprocessor_config.json\n",
            "  2% 50/2000 [12:23<7:42:04, 14.22s/it]{'loss': 0.3772, 'learning_rate': 1.95e-05, 'epoch': 2.5}\n",
            "{'loss': 0.363, 'learning_rate': 1.94e-05, 'epoch': 3.0}\n",
            "  3% 60/2000 [14:38<6:28:59, 12.03s/it][INFO|trainer.py:2463] 2022-05-06 14:13:28,657 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:13:28,657 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:13:28,657 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                       \n",
            "                                 {'eval_loss': 0.34249240159988403, 'eval_runtime': 25.8285, 'eval_samples_per_second': 5.42, 'eval_steps_per_second': 0.116, 'epoch': 3.0}\n",
            "  3% 60/2000 [15:04<6:28:59, 12.03s/it]\n",
            "100% 3/3 [00:13<00:00,  4.28s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:13:54,488 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-60\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:13:54,489 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-60/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:13:55,067 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-60/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:13:55,067 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-60/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:13:57,070 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-158] due to args.save_total_limit\n",
            "  4% 70/2000 [17:13<6:59:08, 13.03s/it]{'loss': 0.345, 'learning_rate': 1.93e-05, 'epoch': 3.5}\n",
            "  4% 80/2000 [19:16<6:07:29, 11.48s/it]{'loss': 0.3301, 'learning_rate': 1.9200000000000003e-05, 'epoch': 4.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 14:18:06,314 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:18:06,314 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:18:06,314 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.71s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.3071352541446686, 'eval_runtime': 25.7281, 'eval_samples_per_second': 5.442, 'eval_steps_per_second': 0.117, 'epoch': 4.0}\n",
            "  4% 80/2000 [19:42<6:07:29, 11.48s/it]\n",
            "100% 3/3 [00:13<00:00,  4.27s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:18:32,044 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-80\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:18:32,045 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-80/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:18:32,607 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-80/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:18:32,608 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-80/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:18:34,766 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-20] due to args.save_total_limit\n",
            "  4% 90/2000 [21:50<6:46:24, 12.77s/it]{'loss': 0.3144, 'learning_rate': 1.91e-05, 'epoch': 4.5}\n",
            "{'loss': 0.2967, 'learning_rate': 1.9e-05, 'epoch': 5.0}\n",
            "  5% 100/2000 [23:52<6:03:47, 11.49s/it][INFO|trainer.py:2463] 2022-05-06 14:22:42,736 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:22:42,736 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:22:42,736 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.69s/it]\u001b[A\n",
            "                                        \n",
            "                                 {'eval_loss': 0.2826436758041382, 'eval_runtime': 25.6755, 'eval_samples_per_second': 5.453, 'eval_steps_per_second': 0.117, 'epoch': 5.0}\n",
            "  5% 100/2000 [24:18<6:03:47, 11.49s/it]\n",
            "100% 3/3 [00:13<00:00,  4.24s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:23:08,414 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-100\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:23:08,415 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:23:08,996 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-100/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:23:08,996 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-100/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:23:11,033 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-40] due to args.save_total_limit\n",
            "  6% 110/2000 [26:28<6:50:40, 13.04s/it]{'loss': 0.2841, 'learning_rate': 1.8900000000000002e-05, 'epoch': 5.5}\n",
            "  6% 120/2000 [28:29<5:53:37, 11.29s/it]{'loss': 0.2705, 'learning_rate': 1.88e-05, 'epoch': 6.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 14:27:19,016 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:27:19,016 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:27:19,016 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.69s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.26235514879226685, 'eval_runtime': 25.7027, 'eval_samples_per_second': 5.447, 'eval_steps_per_second': 0.117, 'epoch': 6.0}\n",
            "  6% 120/2000 [28:54<5:53:37, 11.29s/it]\n",
            "100% 3/3 [00:13<00:00,  4.25s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:27:44,721 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-120\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:27:44,722 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-120/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:27:45,246 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-120/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:27:45,247 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-120/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:27:47,291 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-60] due to args.save_total_limit\n",
            "{'loss': 0.2572, 'learning_rate': 1.8700000000000004e-05, 'epoch': 6.5}\n",
            "  7% 140/2000 [33:06<5:55:40, 11.47s/it]{'loss': 0.25, 'learning_rate': 1.86e-05, 'epoch': 7.0}\n",
            "  7% 140/2000 [33:06<5:55:40, 11.47s/it][INFO|trainer.py:2463] 2022-05-06 14:31:56,886 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:31:56,886 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:31:56,886 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.68s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.24156834185123444, 'eval_runtime': 25.6615, 'eval_samples_per_second': 5.456, 'eval_steps_per_second': 0.117, 'epoch': 7.0}\n",
            "  7% 140/2000 [33:32<5:55:40, 11.47s/it]\n",
            "100% 3/3 [00:13<00:00,  4.24s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:32:22,550 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-140\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:32:22,551 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-140/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:32:23,129 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-140/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:32:23,130 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-140/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:32:25,228 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-80] due to args.save_total_limit\n",
            "  8% 150/2000 [35:41<6:35:45, 12.84s/it]{'loss': 0.2409, 'learning_rate': 1.8500000000000002e-05, 'epoch': 7.5}\n",
            "{'loss': 0.2337, 'learning_rate': 1.8400000000000003e-05, 'epoch': 8.0}\n",
            "  8% 160/2000 [37:43<5:53:18, 11.52s/it][INFO|trainer.py:2463] 2022-05-06 14:36:33,510 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:36:33,510 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:36:33,510 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.66s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.22771194577217102, 'eval_runtime': 25.6829, 'eval_samples_per_second': 5.451, 'eval_steps_per_second': 0.117, 'epoch': 8.0}\n",
            "  8% 160/2000 [38:09<5:53:18, 11.52s/it]\n",
            "100% 3/3 [00:13<00:00,  4.24s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:36:59,195 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-160\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:36:59,196 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-160/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:36:59,804 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-160/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:36:59,805 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-160/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:37:01,839 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-100] due to args.save_total_limit\n",
            "{'loss': 0.2256, 'learning_rate': 1.83e-05, 'epoch': 8.5}\n",
            "  9% 180/2000 [42:19<5:50:31, 11.56s/it]{'loss': 0.2199, 'learning_rate': 1.8200000000000002e-05, 'epoch': 9.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 14:41:09,899 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:41:09,899 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:41:09,899 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.75s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.21783383190631866, 'eval_runtime': 25.8209, 'eval_samples_per_second': 5.422, 'eval_steps_per_second': 0.116, 'epoch': 9.0}\n",
            "  9% 180/2000 [42:45<5:50:31, 11.56s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:41:35,722 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-180\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:41:35,723 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-180/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:41:36,298 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-180/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:41:36,298 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-180/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:41:38,393 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-120] due to args.save_total_limit\n",
            " 10% 190/2000 [44:54<6:28:43, 12.89s/it]{'loss': 0.2115, 'learning_rate': 1.8100000000000003e-05, 'epoch': 9.5}\n",
            "{'loss': 0.2118, 'learning_rate': 1.8e-05, 'epoch': 10.0}\n",
            " 10% 200/2000 [46:57<5:48:17, 11.61s/it][INFO|trainer.py:2463] 2022-05-06 14:45:47,060 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:45:47,060 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:45:47,060 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.2079557627439499, 'eval_runtime': 25.7204, 'eval_samples_per_second': 5.443, 'eval_steps_per_second': 0.117, 'epoch': 10.0}\n",
            " 10% 200/2000 [47:22<5:48:17, 11.61s/it]\n",
            "100% 3/3 [00:13<00:00,  4.27s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:46:12,783 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-200\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:46:12,784 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-200/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:46:13,338 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-200/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:46:13,339 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-200/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:46:15,515 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-140] due to args.save_total_limit\n",
            " 10% 210/2000 [49:31<6:25:30, 12.92s/it]{'loss': 0.2067, 'learning_rate': 1.79e-05, 'epoch': 10.5}\n",
            " 11% 220/2000 [51:33<5:39:47, 11.45s/it]{'loss': 0.1988, 'learning_rate': 1.7800000000000002e-05, 'epoch': 11.0}\n",
            " 11% 220/2000 [51:33<5:39:47, 11.45s/it][INFO|trainer.py:2463] 2022-05-06 14:50:23,855 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:50:23,856 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:50:23,856 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.69s/it]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.20254528522491455, 'eval_runtime': 25.8062, 'eval_samples_per_second': 5.425, 'eval_steps_per_second': 0.116, 'epoch': 11.0}\n",
            " 11% 220/2000 [51:59<5:39:47, 11.45s/it]\n",
            "100% 3/3 [00:13<00:00,  4.24s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:50:49,664 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-220\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:50:49,664 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-220/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:50:50,224 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-220/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:50:50,225 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-220/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:50:52,447 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-160] due to args.save_total_limit\n",
            "{'loss': 0.1991, 'learning_rate': 1.77e-05, 'epoch': 11.5}\n",
            "{'loss': 0.1937, 'learning_rate': 1.76e-05, 'epoch': 12.0}\n",
            " 12% 240/2000 [56:10<5:32:38, 11.34s/it][INFO|trainer.py:2463] 2022-05-06 14:55:00,669 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:55:00,669 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:55:00,669 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.69s/it]\u001b[A\n",
            "{'eval_loss': 0.1928011178970337, 'eval_runtime': 25.6606, 'eval_samples_per_second': 5.456, 'eval_steps_per_second': 0.117, 'epoch': 12.0}\n",
            "\n",
            " 12% 240/2000 [56:36<5:32:38, 11.34s/it]\n",
            "100% 3/3 [00:13<00:00,  4.25s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 14:55:26,332 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-240\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 14:55:26,333 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-240/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 14:55:26,891 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-240/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 14:55:26,892 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-240/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 14:55:29,091 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-180] due to args.save_total_limit\n",
            " 12% 250/2000 [58:45<6:18:56, 12.99s/it]{'loss': 0.1914, 'learning_rate': 1.7500000000000002e-05, 'epoch': 12.5}\n",
            "{'loss': 0.1866, 'learning_rate': 1.7400000000000003e-05, 'epoch': 13.0}\n",
            " 13% 260/2000 [1:00:48<5:35:49, 11.58s/it][INFO|trainer.py:2463] 2022-05-06 14:59:38,687 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 14:59:38,687 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 14:59:38,687 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.18762405216693878, 'eval_runtime': 25.7985, 'eval_samples_per_second': 5.427, 'eval_steps_per_second': 0.116, 'epoch': 13.0}\n",
            " 13% 260/2000 [1:01:14<5:35:49, 11.58s/it]\n",
            "100% 3/3 [00:13<00:00,  4.28s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:00:04,488 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-260\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:00:04,488 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-260/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:00:05,056 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-260/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:00:05,057 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-260/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:00:06,989 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-200] due to args.save_total_limit\n",
            "{'loss': 0.1833, 'learning_rate': 1.73e-05, 'epoch': 13.5}\n",
            "{'loss': 0.1834, 'learning_rate': 1.72e-05, 'epoch': 14.0}\n",
            " 14% 280/2000 [1:05:26<5:35:21, 11.70s/it][INFO|trainer.py:2463] 2022-05-06 15:04:16,617 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:04:16,617 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:04:16,617 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.77s/it]\u001b[A\n",
            "{'eval_loss': 0.18254922330379486, 'eval_runtime': 26.4306, 'eval_samples_per_second': 5.297, 'eval_steps_per_second': 0.114, 'epoch': 14.0}\n",
            "\n",
            " 14% 280/2000 [1:05:53<5:35:21, 11.70s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:04:43,050 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-280\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:04:43,051 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-280/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:04:43,631 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-280/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:04:43,632 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-280/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:04:45,605 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-220] due to args.save_total_limit\n",
            "{'loss': 0.18, 'learning_rate': 1.7100000000000002e-05, 'epoch': 14.5}\n",
            "{'loss': 0.177, 'learning_rate': 1.7e-05, 'epoch': 15.0}\n",
            " 15% 300/2000 [1:10:05<5:24:02, 11.44s/it][INFO|trainer.py:2463] 2022-05-06 15:08:55,615 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:08:55,615 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:08:55,615 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.76s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.17832477390766144, 'eval_runtime': 25.9909, 'eval_samples_per_second': 5.387, 'eval_steps_per_second': 0.115, 'epoch': 15.0}\n",
            " 15% 300/2000 [1:10:31<5:24:02, 11.44s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:09:21,608 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-300\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:09:21,609 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-300/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:09:22,149 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-300/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:09:22,150 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-300/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:09:24,175 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-240] due to args.save_total_limit\n",
            " 16% 310/2000 [1:12:41<6:04:36, 12.94s/it]{'loss': 0.1749, 'learning_rate': 1.69e-05, 'epoch': 15.5}\n",
            "                                          {'loss': 0.1733, 'learning_rate': 1.6800000000000002e-05, 'epoch': 16.0}\n",
            " 16% 320/2000 [1:14:43<5:20:34, 11.45s/it][INFO|trainer.py:2463] 2022-05-06 15:13:33,742 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:13:33,742 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:13:33,742 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.74s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.17517198622226715, 'eval_runtime': 25.8661, 'eval_samples_per_second': 5.412, 'eval_steps_per_second': 0.116, 'epoch': 16.0}\n",
            " 16% 320/2000 [1:15:09<5:20:34, 11.45s/it]\n",
            "100% 3/3 [00:13<00:00,  4.28s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:13:59,610 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-320\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:13:59,611 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-320/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:14:00,179 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-320/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:14:00,179 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-320/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:14:02,202 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-260] due to args.save_total_limit\n",
            "{'loss': 0.1736, 'learning_rate': 1.67e-05, 'epoch': 16.5}\n",
            "{'loss': 0.1685, 'learning_rate': 1.66e-05, 'epoch': 17.0}\n",
            " 17% 340/2000 [1:19:21<5:20:46, 11.59s/it][INFO|trainer.py:2463] 2022-05-06 15:18:11,218 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:18:11,218 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:18:11,218 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.76s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.17252995073795319, 'eval_runtime': 25.8826, 'eval_samples_per_second': 5.409, 'eval_steps_per_second': 0.116, 'epoch': 17.0}\n",
            " 17% 340/2000 [1:19:47<5:20:46, 11.59s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:18:37,103 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-340\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:18:37,104 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-340/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:18:37,669 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-340/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:18:37,670 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-340/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:18:39,648 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-280] due to args.save_total_limit\n",
            "{'loss': 0.1708, 'learning_rate': 1.65e-05, 'epoch': 17.5}\n",
            "{'loss': 0.1687, 'learning_rate': 1.64e-05, 'epoch': 18.0}\n",
            " 18% 360/2000 [1:23:56<5:11:23, 11.39s/it][INFO|trainer.py:2463] 2022-05-06 15:22:46,736 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:22:46,736 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:22:46,736 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.71s/it]\u001b[A\n",
            "                                          \n",
            " 18% 360/2000 [1:24:22<5:11:23, 11.39s/it]\n",
            "100% 3/3 [00:13<00:00,  4.26s/it]\u001b[A{'eval_loss': 0.17024756968021393, 'eval_runtime': 25.6442, 'eval_samples_per_second': 5.459, 'eval_steps_per_second': 0.117, 'epoch': 18.0}\n",
            "\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:23:12,383 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-360\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:23:12,384 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-360/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:23:12,975 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-360/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:23:12,976 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-360/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:23:14,999 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-300] due to args.save_total_limit\n",
            "{'loss': 0.1687, 'learning_rate': 1.63e-05, 'epoch': 18.5}\n",
            "{'loss': 0.1652, 'learning_rate': 1.62e-05, 'epoch': 19.0}\n",
            " 19% 380/2000 [1:28:32<5:07:57, 11.41s/it][INFO|trainer.py:2463] 2022-05-06 15:27:22,439 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:27:22,439 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:27:22,439 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.64s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.16833335161209106, 'eval_runtime': 25.4158, 'eval_samples_per_second': 5.508, 'eval_steps_per_second': 0.118, 'epoch': 19.0}\n",
            " 19% 380/2000 [1:28:57<5:07:57, 11.41s/it]\n",
            "100% 3/3 [00:13<00:00,  4.22s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:27:47,857 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-380\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:27:47,858 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-380/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:27:48,436 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-380/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:27:48,436 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-380/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:27:50,926 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-320] due to args.save_total_limit\n",
            "{'loss': 0.1667, 'learning_rate': 1.6100000000000002e-05, 'epoch': 19.5}\n",
            "                                          {'loss': 0.1641, 'learning_rate': 1.6000000000000003e-05, 'epoch': 20.0}\n",
            " 20% 400/2000 [1:33:05<5:02:36, 11.35s/it][INFO|trainer.py:2463] 2022-05-06 15:31:55,806 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:31:55,806 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:31:55,806 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.65s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.16962271928787231, 'eval_runtime': 25.4711, 'eval_samples_per_second': 5.496, 'eval_steps_per_second': 0.118, 'epoch': 20.0}\n",
            " 20% 400/2000 [1:33:31<5:02:36, 11.35s/it]\n",
            "100% 3/3 [00:13<00:00,  4.23s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:32:21,279 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-400\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:32:21,280 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-400/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:32:21,868 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-400/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:32:21,869 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-400/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:32:23,912 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-340] due to args.save_total_limit\n",
            " 20% 410/2000 [1:35:38<5:38:24, 12.77s/it]{'loss': 0.1617, 'learning_rate': 1.5900000000000004e-05, 'epoch': 20.5}\n",
            " 21% 420/2000 [1:37:39<4:58:27, 11.33s/it]{'loss': 0.165, 'learning_rate': 1.58e-05, 'epoch': 21.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 15:36:29,733 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:36:29,733 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:36:29,733 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.60s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.16876201331615448, 'eval_runtime': 25.3533, 'eval_samples_per_second': 5.522, 'eval_steps_per_second': 0.118, 'epoch': 21.0}\n",
            " 21% 420/2000 [1:38:05<4:58:27, 11.33s/it]\n",
            "100% 3/3 [00:13<00:00,  4.19s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:36:55,089 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-420\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:36:55,090 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-420/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:36:55,641 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-420/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:36:55,642 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-420/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:36:58,102 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-360] due to args.save_total_limit\n",
            " 22% 430/2000 [1:40:13<5:37:50, 12.91s/it]{'loss': 0.1649, 'learning_rate': 1.5700000000000002e-05, 'epoch': 21.5}\n",
            "{'loss': 0.1606, 'learning_rate': 1.5600000000000003e-05, 'epoch': 22.0}\n",
            " 22% 440/2000 [1:42:15<5:00:17, 11.55s/it][INFO|trainer.py:2463] 2022-05-06 15:41:05,761 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:41:05,761 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:41:05,761 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.63s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.16570614278316498, 'eval_runtime': 25.4262, 'eval_samples_per_second': 5.506, 'eval_steps_per_second': 0.118, 'epoch': 22.0}\n",
            " 22% 440/2000 [1:42:41<5:00:17, 11.55s/it]\n",
            "100% 3/3 [00:13<00:00,  4.21s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:41:31,190 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-440\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:41:31,191 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-440/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:41:31,769 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-440/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:41:31,770 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-440/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:41:33,818 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-380] due to args.save_total_limit\n",
            "{'loss': 0.1624, 'learning_rate': 1.55e-05, 'epoch': 22.5}\n",
            "{'loss': 0.158, 'learning_rate': 1.54e-05, 'epoch': 23.0}\n",
            " 23% 460/2000 [1:46:51<4:52:35, 11.40s/it][INFO|trainer.py:2463] 2022-05-06 15:45:41,105 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:45:41,105 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:45:41,105 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.70s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.1620529443025589, 'eval_runtime': 25.6789, 'eval_samples_per_second': 5.452, 'eval_steps_per_second': 0.117, 'epoch': 23.0}\n",
            " 23% 460/2000 [1:47:16<4:52:35, 11.40s/it]\n",
            "100% 3/3 [00:13<00:00,  4.25s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:46:06,786 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-460\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:46:06,788 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-460/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:46:07,430 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-460/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:46:07,431 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-460/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:46:09,517 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-400] due to args.save_total_limit\n",
            "{'loss': 0.1607, 'learning_rate': 1.5300000000000003e-05, 'epoch': 23.5}\n",
            " 24% 480/2000 [1:51:27<4:46:49, 11.32s/it]{'loss': 0.1569, 'learning_rate': 1.5200000000000002e-05, 'epoch': 24.0}\n",
            " 24% 480/2000 [1:51:27<4:46:49, 11.32s/it][INFO|trainer.py:2463] 2022-05-06 15:50:17,272 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:50:17,272 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:50:17,272 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.74s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.16102932393550873, 'eval_runtime': 25.7433, 'eval_samples_per_second': 5.438, 'eval_steps_per_second': 0.117, 'epoch': 24.0}\n",
            " 24% 480/2000 [1:51:53<4:46:49, 11.32s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:50:43,017 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-480\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:50:43,019 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-480/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:50:43,619 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-480/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:50:43,619 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-480/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:50:45,746 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-420] due to args.save_total_limit\n",
            "{'loss': 0.1608, 'learning_rate': 1.5100000000000001e-05, 'epoch': 24.5}\n",
            "{'loss': 0.1566, 'learning_rate': 1.5000000000000002e-05, 'epoch': 25.0}\n",
            " 25% 500/2000 [1:56:04<4:45:50, 11.43s/it][INFO|trainer.py:2463] 2022-05-06 15:54:54,479 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:54:54,479 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:54:54,479 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.16239780187606812, 'eval_runtime': 25.9043, 'eval_samples_per_second': 5.405, 'eval_steps_per_second': 0.116, 'epoch': 25.0}\n",
            " 25% 500/2000 [1:56:30<4:45:50, 11.43s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:55:20,386 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-500\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:55:20,387 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:55:20,984 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-500/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:55:20,984 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-500/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:55:23,113 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-440] due to args.save_total_limit\n",
            "{'loss': 0.1564, 'learning_rate': 1.4900000000000001e-05, 'epoch': 25.5}\n",
            "{'loss': 0.1581, 'learning_rate': 1.48e-05, 'epoch': 26.0}\n",
            " 26% 520/2000 [2:00:40<4:41:55, 11.43s/it][INFO|trainer.py:2463] 2022-05-06 15:59:30,693 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 15:59:30,693 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 15:59:30,693 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.69s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.16159899532794952, 'eval_runtime': 25.7103, 'eval_samples_per_second': 5.445, 'eval_steps_per_second': 0.117, 'epoch': 26.0}\n",
            " 26% 520/2000 [2:01:06<4:41:55, 11.43s/it]\n",
            "100% 3/3 [00:13<00:00,  4.25s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 15:59:56,406 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-520\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 15:59:56,407 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-520/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 15:59:56,963 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-520/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 15:59:56,963 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-520/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 15:59:59,069 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-460] due to args.save_total_limit\n",
            "{'loss': 0.1555, 'learning_rate': 1.4700000000000002e-05, 'epoch': 26.5}\n",
            " 27% 540/2000 [2:05:18<4:40:06, 11.51s/it]{'loss': 0.1569, 'learning_rate': 1.46e-05, 'epoch': 27.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 16:04:08,610 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:04:08,610 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:04:08,610 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.76s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.1584053784608841, 'eval_runtime': 25.8443, 'eval_samples_per_second': 5.417, 'eval_steps_per_second': 0.116, 'epoch': 27.0}\n",
            " 27% 540/2000 [2:05:44<4:40:06, 11.51s/it]\n",
            "100% 3/3 [00:13<00:00,  4.31s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:04:34,457 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-540\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:04:34,458 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-540/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:04:35,032 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-540/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:04:35,032 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-540/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:04:37,032 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-480] due to args.save_total_limit\n",
            "{'loss': 0.1554, 'learning_rate': 1.45e-05, 'epoch': 27.5}\n",
            "{'loss': 0.155, 'learning_rate': 1.4400000000000001e-05, 'epoch': 28.0}\n",
            " 28% 560/2000 [2:09:54<4:32:18, 11.35s/it][INFO|trainer.py:2463] 2022-05-06 16:08:44,407 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:08:44,407 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:08:44,407 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.1564202755689621, 'eval_runtime': 25.8377, 'eval_samples_per_second': 5.418, 'eval_steps_per_second': 0.116, 'epoch': 28.0}\n",
            " 28% 560/2000 [2:10:20<4:32:18, 11.35s/it]\n",
            "100% 3/3 [00:13<00:00,  4.28s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:09:10,247 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-560\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:09:10,248 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-560/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:09:10,836 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-560/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:09:10,836 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-560/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:09:12,895 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-500] due to args.save_total_limit\n",
            "{'loss': 0.1556, 'learning_rate': 1.43e-05, 'epoch': 28.5}\n",
            "{'loss': 0.1538, 'learning_rate': 1.4200000000000001e-05, 'epoch': 29.0}\n",
            " 29% 580/2000 [2:14:30<4:28:41, 11.35s/it][INFO|trainer.py:2463] 2022-05-06 16:13:20,904 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:13:20,904 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:13:20,904 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.78s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15813402831554413, 'eval_runtime': 26.056, 'eval_samples_per_second': 5.373, 'eval_steps_per_second': 0.115, 'epoch': 29.0}\n",
            " 29% 580/2000 [2:14:57<4:28:41, 11.35s/it]\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:13:46,962 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-580\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:13:46,963 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-580/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:13:47,522 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-580/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:13:47,523 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-580/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:13:49,595 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-520] due to args.save_total_limit\n",
            "{'loss': 0.1564, 'learning_rate': 1.41e-05, 'epoch': 29.5}\n",
            "{'loss': 0.1508, 'learning_rate': 1.4e-05, 'epoch': 30.0}\n",
            " 30% 600/2000 [2:19:08<4:26:25, 11.42s/it][INFO|trainer.py:2463] 2022-05-06 16:17:58,656 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:17:58,656 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:17:58,656 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.76s/it]\u001b[A\n",
            "                                          \n",
            "                                 {'eval_loss': 0.15587855875492096, 'eval_runtime': 25.9022, 'eval_samples_per_second': 5.405, 'eval_steps_per_second': 0.116, 'epoch': 30.0}\n",
            " 30% 600/2000 [2:19:34<4:26:25, 11.42s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:18:24,560 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-600\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:18:24,562 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-600/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:18:25,134 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-600/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:18:25,135 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-600/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:18:27,252 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-540] due to args.save_total_limit\n",
            "{'loss': 0.1551, 'learning_rate': 1.39e-05, 'epoch': 30.5}\n",
            "{'loss': 0.1525, 'learning_rate': 1.38e-05, 'epoch': 31.0}\n",
            " 31% 620/2000 [2:23:46<4:20:23, 11.32s/it][INFO|trainer.py:2463] 2022-05-06 16:22:36,321 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:22:36,321 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:22:36,321 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                          \n",
            " 31% 620/2000 [2:24:12<4:20:23, 11.32s/it]\n",
            "{'eval_loss': 0.1539832502603531, 'eval_runtime': 25.7579, 'eval_samples_per_second': 5.435, 'eval_steps_per_second': 0.116, 'epoch': 31.0}\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:23:02,082 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-620\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:23:02,083 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-620/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:23:02,668 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-620/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:23:02,668 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-620/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:23:04,774 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-560] due to args.save_total_limit\n",
            " 32% 630/2000 [2:26:21<4:56:53, 13.00s/it]{'loss': 0.152, 'learning_rate': 1.3700000000000003e-05, 'epoch': 31.5}\n",
            " 32% 640/2000 [2:28:24<4:22:10, 11.57s/it]{'loss': 0.1529, 'learning_rate': 1.3600000000000002e-05, 'epoch': 32.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 16:27:14,009 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:27:14,009 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:27:14,010 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.76s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.1563902646303177, 'eval_runtime': 25.9088, 'eval_samples_per_second': 5.404, 'eval_steps_per_second': 0.116, 'epoch': 32.0}\n",
            " 32% 640/2000 [2:28:49<4:22:10, 11.57s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:27:39,921 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-640\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:27:39,922 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-640/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:27:40,522 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-640/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:27:40,522 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-640/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:27:42,630 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-580] due to args.save_total_limit\n",
            "{'loss': 0.1506, 'learning_rate': 1.3500000000000001e-05, 'epoch': 32.5}\n",
            " 33% 660/2000 [2:33:02<4:16:56, 11.50s/it]{'loss': 0.1547, 'learning_rate': 1.3400000000000002e-05, 'epoch': 33.0}\n",
            " 33% 660/2000 [2:33:02<4:16:56, 11.50s/it][INFO|trainer.py:2463] 2022-05-06 16:31:52,244 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:31:52,244 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:31:52,244 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.75s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15622355043888092, 'eval_runtime': 25.844, 'eval_samples_per_second': 5.417, 'eval_steps_per_second': 0.116, 'epoch': 33.0}\n",
            " 33% 660/2000 [2:33:28<4:16:56, 11.50s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:32:18,090 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-660\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:32:18,091 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-660/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:32:18,659 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-660/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:32:18,659 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-660/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:32:20,687 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-600] due to args.save_total_limit\n",
            " 34% 670/2000 [2:35:37<4:48:49, 13.03s/it]{'loss': 0.1538, 'learning_rate': 1.3300000000000001e-05, 'epoch': 33.5}\n",
            "{'loss': 0.1496, 'learning_rate': 1.3200000000000002e-05, 'epoch': 34.0}\n",
            " 34% 680/2000 [2:37:41<4:14:52, 11.59s/it][INFO|trainer.py:2463] 2022-05-06 16:36:31,021 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:36:31,022 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:36:31,022 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.75s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15450246632099152, 'eval_runtime': 25.966, 'eval_samples_per_second': 5.392, 'eval_steps_per_second': 0.116, 'epoch': 34.0}\n",
            " 34% 680/2000 [2:38:07<4:14:52, 11.59s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:36:56,990 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-680\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:36:56,991 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-680/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:36:57,607 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-680/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:36:57,608 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-680/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:36:59,656 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-640] due to args.save_total_limit\n",
            " 34% 690/2000 [2:40:15<4:43:40, 12.99s/it]{'loss': 0.1494, 'learning_rate': 1.3100000000000002e-05, 'epoch': 34.5}\n",
            "{'loss': 0.1528, 'learning_rate': 1.3000000000000001e-05, 'epoch': 35.0}\n",
            " 35% 700/2000 [2:42:19<4:13:11, 11.69s/it][INFO|trainer.py:2463] 2022-05-06 16:41:09,846 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:41:09,846 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:41:09,846 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.75s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.1533823013305664, 'eval_runtime': 25.8992, 'eval_samples_per_second': 5.406, 'eval_steps_per_second': 0.116, 'epoch': 35.0}\n",
            " 35% 700/2000 [2:42:45<4:13:11, 11.69s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:41:35,747 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-700\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:41:35,748 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-700/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:41:36,459 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-700/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:41:36,460 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-700/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:41:38,315 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-620] due to args.save_total_limit\n",
            " 36% 710/2000 [2:44:54<4:39:15, 12.99s/it]{'loss': 0.1489, 'learning_rate': 1.2900000000000002e-05, 'epoch': 35.5}\n",
            " 36% 720/2000 [2:46:58<4:06:24, 11.55s/it]{'loss': 0.1508, 'learning_rate': 1.2800000000000001e-05, 'epoch': 36.0}\n",
            " 36% 720/2000 [2:46:58<4:06:24, 11.55s/it][INFO|trainer.py:2463] 2022-05-06 16:45:48,157 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:45:48,158 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:45:48,158 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.74s/it]\u001b[A\n",
            "                                          {'eval_loss': 0.15411914885044098, 'eval_runtime': 25.8814, 'eval_samples_per_second': 5.409, 'eval_steps_per_second': 0.116, 'epoch': 36.0}\n",
            "\n",
            " 36% 720/2000 [2:47:24<4:06:24, 11.55s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:46:14,041 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-720\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:46:14,042 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-720/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:46:14,622 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-720/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:46:14,623 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-720/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:46:16,996 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-660] due to args.save_total_limit\n",
            "{'loss': 0.1494, 'learning_rate': 1.27e-05, 'epoch': 36.5}\n",
            " 37% 740/2000 [2:51:37<4:03:41, 11.60s/it]{'loss': 0.1492, 'learning_rate': 1.2600000000000001e-05, 'epoch': 37.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 16:50:27,590 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:50:27,590 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:50:27,590 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.74s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.1516621708869934, 'eval_runtime': 25.8713, 'eval_samples_per_second': 5.411, 'eval_steps_per_second': 0.116, 'epoch': 37.0}\n",
            " 37% 740/2000 [2:52:03<4:03:41, 11.60s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:50:53,463 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-740\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:50:53,464 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-740/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:50:54,036 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-740/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:50:54,037 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-740/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:50:56,085 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-680] due to args.save_total_limit\n",
            " 38% 750/2000 [2:54:12<4:31:42, 13.04s/it]{'loss': 0.1506, 'learning_rate': 1.25e-05, 'epoch': 37.5}\n",
            "{'loss': 0.1488, 'learning_rate': 1.2400000000000002e-05, 'epoch': 38.0}\n",
            " 38% 760/2000 [2:56:15<3:56:27, 11.44s/it][INFO|trainer.py:2463] 2022-05-06 16:55:04,994 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:55:04,994 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:55:04,994 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.72s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15472936630249023, 'eval_runtime': 25.7201, 'eval_samples_per_second': 5.443, 'eval_steps_per_second': 0.117, 'epoch': 38.0}\n",
            " 38% 760/2000 [2:56:40<3:56:27, 11.44s/it]\n",
            "100% 3/3 [00:13<00:00,  4.28s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 16:55:30,716 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-760\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 16:55:30,717 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-760/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 16:55:31,283 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-760/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 16:55:31,284 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-760/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 16:55:33,389 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-700] due to args.save_total_limit\n",
            " 38% 770/2000 [2:58:50<4:28:04, 13.08s/it]{'loss': 0.15, 'learning_rate': 1.23e-05, 'epoch': 38.5}\n",
            " 39% 780/2000 [3:00:52<3:54:45, 11.55s/it]{'loss': 0.1482, 'learning_rate': 1.22e-05, 'epoch': 39.0}\n",
            " 39% 780/2000 [3:00:52<3:54:45, 11.55s/it][INFO|trainer.py:2463] 2022-05-06 16:59:42,688 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 16:59:42,688 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 16:59:42,689 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.71s/it]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.15369774401187897, 'eval_runtime': 25.8741, 'eval_samples_per_second': 5.411, 'eval_steps_per_second': 0.116, 'epoch': 39.0}\n",
            " 39% 780/2000 [3:01:18<3:54:45, 11.55s/it]\n",
            "100% 3/3 [00:13<00:00,  4.27s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:00:08,565 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-780\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:00:08,566 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-780/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:00:09,142 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-780/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:00:09,142 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-780/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:00:11,193 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-720] due to args.save_total_limit\n",
            "{'loss': 0.1489, 'learning_rate': 1.2100000000000001e-05, 'epoch': 39.5}\n",
            "{'loss': 0.1492, 'learning_rate': 1.2e-05, 'epoch': 40.0}\n",
            " 40% 800/2000 [3:05:31<3:51:07, 11.56s/it][INFO|trainer.py:2463] 2022-05-06 17:04:21,359 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:04:21,359 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:04:21,359 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.75s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15291562676429749, 'eval_runtime': 25.9906, 'eval_samples_per_second': 5.387, 'eval_steps_per_second': 0.115, 'epoch': 40.0}\n",
            " 40% 800/2000 [3:05:57<3:51:07, 11.56s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:04:47,352 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-800\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:04:47,353 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-800/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:04:47,964 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-800/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:04:47,965 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-800/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:04:49,989 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-760] due to args.save_total_limit\n",
            "{'loss': 0.1486, 'learning_rate': 1.1900000000000001e-05, 'epoch': 40.5}\n",
            " 41% 820/2000 [3:10:10<3:46:58, 11.54s/it]{'loss': 0.1486, 'learning_rate': 1.18e-05, 'epoch': 41.0}\n",
            " 41% 820/2000 [3:10:10<3:46:58, 11.54s/it][INFO|trainer.py:2463] 2022-05-06 17:09:00,182 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:09:00,182 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:09:00,182 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.80s/it]\u001b[A\n",
            "100% 3/3 [00:13<00:00,  4.32s/it]\u001b[A{'eval_loss': 0.15306276082992554, 'eval_runtime': 26.0425, 'eval_samples_per_second': 5.376, 'eval_steps_per_second': 0.115, 'epoch': 41.0}\n",
            "                                          \n",
            " 41% 820/2000 [3:10:36<3:46:58, 11.54s/it]\n",
            "100% 3/3 [00:13<00:00,  4.32s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:09:26,227 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-820\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:09:26,228 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-820/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:09:26,806 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-820/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:09:26,807 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-820/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:09:29,365 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-780] due to args.save_total_limit\n",
            "{'loss': 0.1458, 'learning_rate': 1.17e-05, 'epoch': 41.5}\n",
            "{'loss': 0.1504, 'learning_rate': 1.16e-05, 'epoch': 42.0}\n",
            " 42% 840/2000 [3:14:49<3:42:54, 11.53s/it][INFO|trainer.py:2463] 2022-05-06 17:13:39,798 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:13:39,798 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:13:39,798 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.76s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15195824205875397, 'eval_runtime': 25.9982, 'eval_samples_per_second': 5.385, 'eval_steps_per_second': 0.115, 'epoch': 42.0}\n",
            " 42% 840/2000 [3:15:15<3:42:54, 11.53s/it]\n",
            "100% 3/3 [00:13<00:00,  4.31s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:14:05,799 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-840\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:14:05,800 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-840/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:14:06,367 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-840/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:14:06,368 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-840/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:14:08,535 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-800] due to args.save_total_limit\n",
            "{'loss': 0.1479, 'learning_rate': 1.15e-05, 'epoch': 42.5}\n",
            " 43% 860/2000 [3:19:28<3:40:40, 11.61s/it]{'loss': 0.147, 'learning_rate': 1.14e-05, 'epoch': 43.0}\n",
            " 43% 860/2000 [3:19:28<3:40:40, 11.61s/it][INFO|trainer.py:2463] 2022-05-06 17:18:18,786 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:18:18,787 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:18:18,787 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.80s/it]\u001b[A\n",
            "{'eval_loss': 0.15146279335021973, 'eval_runtime': 26.1123, 'eval_samples_per_second': 5.361, 'eval_steps_per_second': 0.115, 'epoch': 43.0}\n",
            "\n",
            " 43% 860/2000 [3:19:54<3:40:40, 11.61s/it]\n",
            "100% 3/3 [00:13<00:00,  4.34s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:18:44,901 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-860\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:18:44,902 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-860/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:18:45,489 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-860/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:18:45,490 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-860/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:18:47,571 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-740] due to args.save_total_limit\n",
            "{'loss': 0.1473, 'learning_rate': 1.13e-05, 'epoch': 43.5}\n",
            "                                          {'loss': 0.1476, 'learning_rate': 1.1200000000000001e-05, 'epoch': 44.0}\n",
            " 44% 880/2000 [3:24:09<3:36:18, 11.59s/it][INFO|trainer.py:2463] 2022-05-06 17:22:59,228 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:22:59,228 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:22:59,228 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.80s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15014319121837616, 'eval_runtime': 26.093, 'eval_samples_per_second': 5.365, 'eval_steps_per_second': 0.115, 'epoch': 44.0}\n",
            " 44% 880/2000 [3:24:35<3:36:18, 11.59s/it]\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:23:25,323 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-880\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:23:25,323 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-880/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:23:25,887 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-880/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:23:25,887 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-880/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:23:27,934 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-820] due to args.save_total_limit\n",
            "{'loss': 0.1471, 'learning_rate': 1.1100000000000002e-05, 'epoch': 44.5}\n",
            " 45% 900/2000 [3:28:50<3:33:46, 11.66s/it]{'loss': 0.148, 'learning_rate': 1.1000000000000001e-05, 'epoch': 45.0}\n",
            " 45% 900/2000 [3:28:50<3:33:46, 11.66s/it][INFO|trainer.py:2463] 2022-05-06 17:27:40,873 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:27:40,873 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:27:40,873 >>   Batch size = 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.80s/it]\u001b[A\n",
            "                                          \n",
            " 45% 900/2000 [3:29:17<3:33:46, 11.66s/it]{'eval_loss': 0.15323852002620697, 'eval_runtime': 26.1337, 'eval_samples_per_second': 5.357, 'eval_steps_per_second': 0.115, 'epoch': 45.0}\n",
            "\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:28:07,009 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-900\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:28:07,010 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-900/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:28:07,602 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-900/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:28:07,603 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-900/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:28:09,628 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-840] due to args.save_total_limit\n",
            "{'loss': 0.1471, 'learning_rate': 1.0900000000000002e-05, 'epoch': 45.5}\n",
            "{'loss': 0.1477, 'learning_rate': 1.0800000000000002e-05, 'epoch': 46.0}\n",
            " 46% 920/2000 [3:33:31<3:30:27, 11.69s/it][INFO|trainer.py:2463] 2022-05-06 17:32:21,761 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:32:21,761 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:32:21,761 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.81s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.1501471996307373, 'eval_runtime': 26.1623, 'eval_samples_per_second': 5.351, 'eval_steps_per_second': 0.115, 'epoch': 46.0}\n",
            " 46% 920/2000 [3:33:57<3:30:27, 11.69s/it]\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:32:47,926 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-920\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:32:47,927 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-920/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:32:48,514 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-920/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:32:48,514 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-920/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:32:50,540 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-860] due to args.save_total_limit\n",
            "{'loss': 0.1476, 'learning_rate': 1.0700000000000001e-05, 'epoch': 46.5}\n",
            "{'loss': 0.1444, 'learning_rate': 1.0600000000000002e-05, 'epoch': 47.0}\n",
            " 47% 940/2000 [3:38:11<3:22:10, 11.44s/it][INFO|trainer.py:2463] 2022-05-06 17:37:01,217 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:37:01,218 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:37:01,218 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.74s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.1478276550769806, 'eval_runtime': 25.9097, 'eval_samples_per_second': 5.403, 'eval_steps_per_second': 0.116, 'epoch': 47.0}\n",
            " 47% 940/2000 [3:38:37<3:22:10, 11.44s/it]\n",
            "100% 3/3 [00:13<00:00,  4.30s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:37:27,130 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-940\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:37:27,131 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-940/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:37:27,726 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-940/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:37:27,726 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-940/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:37:29,838 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-880] due to args.save_total_limit\n",
            "{'loss': 0.1437, 'learning_rate': 1.0500000000000001e-05, 'epoch': 47.5}\n",
            " 48% 960/2000 [3:42:50<3:20:10, 11.55s/it]{'loss': 0.1483, 'learning_rate': 1.04e-05, 'epoch': 48.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 17:41:40,498 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:41:40,498 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:41:40,498 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.73s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15032213926315308, 'eval_runtime': 25.9139, 'eval_samples_per_second': 5.402, 'eval_steps_per_second': 0.116, 'epoch': 48.0}\n",
            " 48% 960/2000 [3:43:16<3:20:10, 11.55s/it]\n",
            "100% 3/3 [00:13<00:00,  4.29s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:42:06,414 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-960\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:42:06,415 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-960/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:42:07,012 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-960/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:42:07,013 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-960/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:42:09,054 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-900] due to args.save_total_limit\n",
            " 48% 970/2000 [3:45:26<3:42:21, 12.95s/it]{'loss': 0.1454, 'learning_rate': 1.0300000000000001e-05, 'epoch': 48.5}\n",
            "{'loss': 0.1445, 'learning_rate': 1.02e-05, 'epoch': 49.0}\n",
            " 49% 980/2000 [3:47:29<3:18:44, 11.69s/it][INFO|trainer.py:2463] 2022-05-06 17:46:19,882 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:46:19,882 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:46:19,882 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.77s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.15124402940273285, 'eval_runtime': 25.9581, 'eval_samples_per_second': 5.393, 'eval_steps_per_second': 0.116, 'epoch': 49.0}\n",
            " 49% 980/2000 [3:47:55<3:18:44, 11.69s/it]\n",
            "100% 3/3 [00:13<00:00,  4.31s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:46:45,842 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-980\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:46:45,843 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-980/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:46:46,429 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-980/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:46:46,429 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-980/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:46:48,423 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-920] due to args.save_total_limit\n",
            " 50% 990/2000 [3:50:06<3:40:33, 13.10s/it]{'loss': 0.1465, 'learning_rate': 1.0100000000000002e-05, 'epoch': 49.5}\n",
            "                                           {'loss': 0.1444, 'learning_rate': 1e-05, 'epoch': 50.0}\n",
            " 50% 1000/2000 [3:52:09<3:12:26, 11.55s/it][INFO|trainer.py:2463] 2022-05-06 17:50:59,888 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:50:59,888 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:50:59,888 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.83s/it]\u001b[A\n",
            "                                           \n",
            "{'eval_loss': 0.15102767944335938, 'eval_runtime': 26.1527, 'eval_samples_per_second': 5.353, 'eval_steps_per_second': 0.115, 'epoch': 50.0}\n",
            " 50% 1000/2000 [3:52:36<3:12:26, 11.55s/it]\n",
            "100% 3/3 [00:13<00:00,  4.34s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:51:26,043 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1000\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:51:26,044 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:51:26,655 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:51:26,655 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1000/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:51:28,679 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-960] due to args.save_total_limit\n",
            " 50% 1010/2000 [3:54:45<3:34:50, 13.02s/it]{'loss': 0.1441, 'learning_rate': 9.9e-06, 'epoch': 50.5}\n",
            " 51% 1020/2000 [3:56:50<3:13:39, 11.86s/it]{'loss': 0.1478, 'learning_rate': 9.800000000000001e-06, 'epoch': 51.0}\n",
            " 51% 1020/2000 [3:56:50<3:13:39, 11.86s/it][INFO|trainer.py:2463] 2022-05-06 17:55:40,627 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 17:55:40,628 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 17:55:40,628 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.81s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.1505582332611084, 'eval_runtime': 26.2065, 'eval_samples_per_second': 5.342, 'eval_steps_per_second': 0.114, 'epoch': 51.0}\n",
            " 51% 1020/2000 [3:57:16<3:13:39, 11.86s/it]\n",
            "100% 3/3 [00:13<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 17:56:06,837 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1020\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 17:56:06,838 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1020/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 17:56:07,449 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1020/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 17:56:07,449 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1020/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 17:56:09,507 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-980] due to args.save_total_limit\n",
            "{'loss': 0.1446, 'learning_rate': 9.7e-06, 'epoch': 51.5}\n",
            "{'loss': 0.1463, 'learning_rate': 9.600000000000001e-06, 'epoch': 52.0}\n",
            " 52% 1040/2000 [4:01:32<3:07:58, 11.75s/it][INFO|trainer.py:2463] 2022-05-06 18:00:22,255 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:00:22,255 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:00:22,255 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.82s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14866727590560913, 'eval_runtime': 26.2075, 'eval_samples_per_second': 5.342, 'eval_steps_per_second': 0.114, 'epoch': 52.0}\n",
            " 52% 1040/2000 [4:01:58<3:07:58, 11.75s/it]\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:00:48,464 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1040\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:00:48,465 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1040/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:00:49,041 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1040/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:00:49,042 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1040/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:00:51,091 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1000] due to args.save_total_limit\n",
            " 52% 1050/2000 [4:04:09<3:27:17, 13.09s/it]{'loss': 0.1436, 'learning_rate': 9.5e-06, 'epoch': 52.5}\n",
            "{'loss': 0.1465, 'learning_rate': 9.4e-06, 'epoch': 53.0}\n",
            " 53% 1060/2000 [4:06:14<3:04:25, 11.77s/it][INFO|trainer.py:2463] 2022-05-06 18:05:04,117 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:05:04,117 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:05:04,117 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.77s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14710301160812378, 'eval_runtime': 26.1458, 'eval_samples_per_second': 5.355, 'eval_steps_per_second': 0.115, 'epoch': 53.0}\n",
            " 53% 1060/2000 [4:06:40<3:04:25, 11.77s/it]\n",
            "100% 3/3 [00:13<00:00,  4.32s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:05:30,265 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1060\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:05:30,266 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1060/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:05:30,844 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1060/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:05:30,845 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1060/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:05:32,899 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-940] due to args.save_total_limit\n",
            " 54% 1070/2000 [4:08:51<3:24:28, 13.19s/it]{'loss': 0.1464, 'learning_rate': 9.3e-06, 'epoch': 53.5}\n",
            "{'loss': 0.1445, 'learning_rate': 9.200000000000002e-06, 'epoch': 54.0}\n",
            " 54% 1080/2000 [4:10:56<2:58:28, 11.64s/it][INFO|trainer.py:2463] 2022-05-06 18:09:46,214 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:09:46,214 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:09:46,214 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.82s/it]\u001b[A\n",
            "                                           \n",
            " 54% 1080/2000 [4:11:22<2:58:28, 11.64s/it]\n",
            "100% 3/3 [00:13<00:00,  4.34s/it]\u001b[A\n",
            "                                 \u001b[A{'eval_loss': 0.1477428376674652, 'eval_runtime': 26.3178, 'eval_samples_per_second': 5.32, 'eval_steps_per_second': 0.114, 'epoch': 54.0}\n",
            "[INFO|trainer.py:2213] 2022-05-06 18:10:12,534 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1080\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:10:12,535 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1080/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:10:13,088 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1080/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:10:13,089 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1080/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:10:15,156 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1020] due to args.save_total_limit\n",
            "{'loss': 0.1441, 'learning_rate': 9.100000000000001e-06, 'epoch': 54.5}\n",
            " 55% 1100/2000 [4:15:37<2:57:24, 11.83s/it]{'loss': 0.1458, 'learning_rate': 9e-06, 'epoch': 55.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 18:14:27,865 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:14:27,865 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:14:27,865 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.82s/it]\u001b[A\n",
            "                                           \n",
            " 55% 1100/2000 [4:16:04<2:57:24, 11.83s/it]\n",
            "100% 3/3 [00:13<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A{'eval_loss': 0.1490269899368286, 'eval_runtime': 26.2456, 'eval_samples_per_second': 5.334, 'eval_steps_per_second': 0.114, 'epoch': 55.0}\n",
            "[INFO|trainer.py:2213] 2022-05-06 18:14:54,112 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1100\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:14:54,113 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1100/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:14:54,691 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1100/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:14:54,692 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1100/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:14:56,701 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1040] due to args.save_total_limit\n",
            " 56% 1110/2000 [4:18:14<3:13:26, 13.04s/it]{'loss': 0.1435, 'learning_rate': 8.900000000000001e-06, 'epoch': 55.5}\n",
            "{'loss': 0.1452, 'learning_rate': 8.8e-06, 'epoch': 56.0}\n",
            " 56% 1120/2000 [4:20:19<2:52:23, 11.75s/it][INFO|trainer.py:2463] 2022-05-06 18:19:09,098 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:19:09,098 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:19:09,098 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.86s/it]\u001b[A\n",
            "{'eval_loss': 0.14807812869548798, 'eval_runtime': 26.3279, 'eval_samples_per_second': 5.318, 'eval_steps_per_second': 0.114, 'epoch': 56.0}\n",
            "\n",
            " 56% 1120/2000 [4:20:45<2:52:23, 11.75s/it]\n",
            "100% 3/3 [00:13<00:00,  4.36s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:19:35,428 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1120\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:19:35,429 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1120/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:19:35,989 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1120/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:19:35,989 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1120/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:19:38,042 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1080] due to args.save_total_limit\n",
            "{'loss': 0.1438, 'learning_rate': 8.700000000000001e-06, 'epoch': 56.5}\n",
            "                                           {'loss': 0.1438, 'learning_rate': 8.6e-06, 'epoch': 57.0}\n",
            " 57% 1140/2000 [4:25:00<2:49:10, 11.80s/it][INFO|trainer.py:2463] 2022-05-06 18:23:50,605 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:23:50,605 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:23:50,605 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.77s/it]\u001b[A\n",
            "                                           \n",
            " 57% 1140/2000 [4:25:26<2:49:10, 11.80s/it]\n",
            "{'eval_loss': 0.14905942976474762, 'eval_runtime': 26.1886, 'eval_samples_per_second': 5.346, 'eval_steps_per_second': 0.115, 'epoch': 57.0}\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:24:16,795 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1140\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:24:16,796 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1140/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:24:17,378 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1140/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:24:17,379 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1140/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:24:19,387 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1100] due to args.save_total_limit\n",
            " 57% 1150/2000 [4:27:37<3:05:32, 13.10s/it]{'loss': 0.1438, 'learning_rate': 8.5e-06, 'epoch': 57.5}\n",
            "{'loss': 0.1444, 'learning_rate': 8.400000000000001e-06, 'epoch': 58.0}\n",
            " 58% 1160/2000 [4:29:41<2:42:29, 11.61s/it][INFO|trainer.py:2463] 2022-05-06 18:28:31,200 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:28:31,200 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:28:31,200 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.78s/it]\u001b[A\n",
            "                                           \n",
            "{'eval_loss': 0.14581499993801117, 'eval_runtime': 26.0988, 'eval_samples_per_second': 5.364, 'eval_steps_per_second': 0.115, 'epoch': 58.0}\n",
            " 58% 1160/2000 [4:30:07<2:42:29, 11.61s/it]\n",
            "100% 3/3 [00:13<00:00,  4.31s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:28:57,301 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1160\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:28:57,302 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1160/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:28:57,904 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1160/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:28:57,905 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1160/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:28:59,927 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1060] due to args.save_total_limit\n",
            " 58% 1170/2000 [4:32:18<3:02:29, 13.19s/it]{'loss': 0.1451, 'learning_rate': 8.3e-06, 'epoch': 58.5}\n",
            " 59% 1180/2000 [4:34:20<2:36:40, 11.46s/it]{'loss': 0.1437, 'learning_rate': 8.2e-06, 'epoch': 59.0}\n",
            " 59% 1180/2000 [4:34:20<2:36:40, 11.46s/it][INFO|trainer.py:2463] 2022-05-06 18:33:10,040 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:33:10,040 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:33:10,040 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.74s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14753271639347076, 'eval_runtime': 25.9399, 'eval_samples_per_second': 5.397, 'eval_steps_per_second': 0.116, 'epoch': 59.0}\n",
            " 59% 1180/2000 [4:34:46<2:36:40, 11.46s/it]\n",
            "100% 3/3 [00:13<00:00,  4.28s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:33:35,982 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1180\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:33:35,983 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1180/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:33:36,612 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1180/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:33:36,613 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1180/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:33:38,555 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1120] due to args.save_total_limit\n",
            "{'loss': 0.1452, 'learning_rate': 8.1e-06, 'epoch': 59.5}\n",
            "{'loss': 0.1438, 'learning_rate': 8.000000000000001e-06, 'epoch': 60.0}\n",
            " 60% 1200/2000 [4:38:59<2:36:16, 11.72s/it][INFO|trainer.py:2463] 2022-05-06 18:37:49,640 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:37:49,640 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:37:49,640 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.79s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.149642214179039, 'eval_runtime': 26.0911, 'eval_samples_per_second': 5.366, 'eval_steps_per_second': 0.115, 'epoch': 60.0}\n",
            " 60% 1200/2000 [4:39:25<2:36:16, 11.72s/it]\n",
            "100% 3/3 [00:13<00:00,  4.32s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:38:15,733 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1200\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:38:15,734 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1200/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:38:16,315 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1200/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:38:16,315 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1200/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:38:18,328 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1140] due to args.save_total_limit\n",
            "{'loss': 0.146, 'learning_rate': 7.9e-06, 'epoch': 60.5}\n",
            " 61% 1220/2000 [4:43:40<2:32:16, 11.71s/it][INFO|trainer.py:2463] 2022-05-06 18:42:30,901 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:42:30,901 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:42:30,901 >>   Batch size = 64\n",
            "{'loss': 0.1431, 'learning_rate': 7.800000000000002e-06, 'epoch': 61.0}\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.82s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.1489863395690918, 'eval_runtime': 26.1695, 'eval_samples_per_second': 5.35, 'eval_steps_per_second': 0.115, 'epoch': 61.0}\n",
            " 61% 1220/2000 [4:44:07<2:32:16, 11.71s/it]\n",
            "100% 3/3 [00:13<00:00,  4.34s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:42:57,073 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1220\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:42:57,074 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1220/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:42:57,667 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1220/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:42:57,668 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1220/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:42:59,688 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1180] due to args.save_total_limit\n",
            "{'loss': 0.144, 'learning_rate': 7.7e-06, 'epoch': 61.5}\n",
            "{'loss': 0.1435, 'learning_rate': 7.600000000000001e-06, 'epoch': 62.0}\n",
            " 62% 1240/2000 [4:48:22<2:28:03, 11.69s/it][INFO|trainer.py:2463] 2022-05-06 18:47:12,257 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:47:12,257 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:47:12,257 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.82s/it]\u001b[A\n",
            "{'eval_loss': 0.14575161039829254, 'eval_runtime': 26.2195, 'eval_samples_per_second': 5.34, 'eval_steps_per_second': 0.114, 'epoch': 62.0}\n",
            "\n",
            " 62% 1240/2000 [4:48:48<2:28:03, 11.69s/it]\n",
            "100% 3/3 [00:13<00:00,  4.35s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:47:38,479 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1240\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:47:38,480 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1240/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:47:39,056 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1240/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:47:39,057 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1240/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:47:41,095 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1160] due to args.save_total_limit\n",
            "{'loss': 0.1428, 'learning_rate': 7.500000000000001e-06, 'epoch': 62.5}\n",
            " 63% 1260/2000 [4:53:03<2:24:34, 11.72s/it]{'loss': 0.1435, 'learning_rate': 7.4e-06, 'epoch': 63.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 18:51:53,847 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:51:53,847 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:51:53,847 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.80s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14613033831119537, 'eval_runtime': 26.1429, 'eval_samples_per_second': 5.355, 'eval_steps_per_second': 0.115, 'epoch': 63.0}\n",
            " 63% 1260/2000 [4:53:30<2:24:34, 11.72s/it]\n",
            "100% 3/3 [00:13<00:00,  4.34s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:52:19,992 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1260\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:52:19,993 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1260/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:52:20,589 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1260/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:52:20,590 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1260/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:52:22,620 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1200] due to args.save_total_limit\n",
            " 64% 1270/2000 [4:55:42<2:40:37, 13.20s/it]{'loss': 0.1436, 'learning_rate': 7.3e-06, 'epoch': 63.5}\n",
            "{'loss': 0.1409, 'learning_rate': 7.2000000000000005e-06, 'epoch': 64.0}\n",
            " 64% 1280/2000 [4:57:45<2:18:41, 11.56s/it][INFO|trainer.py:2463] 2022-05-06 18:56:35,918 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 18:56:35,918 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 18:56:35,918 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.83s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.15023507177829742, 'eval_runtime': 26.2713, 'eval_samples_per_second': 5.329, 'eval_steps_per_second': 0.114, 'epoch': 64.0}\n",
            " 64% 1280/2000 [4:58:12<2:18:41, 11.56s/it]\n",
            "100% 3/3 [00:13<00:00,  4.36s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 18:57:02,192 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1280\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 18:57:02,193 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1280/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 18:57:02,784 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1280/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 18:57:02,784 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1280/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 18:57:04,937 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1220] due to args.save_total_limit\n",
            " 64% 1290/2000 [5:00:23<2:35:54, 13.18s/it]{'loss': 0.142, 'learning_rate': 7.100000000000001e-06, 'epoch': 64.5}\n",
            " 65% 1300/2000 [5:02:28<2:15:45, 11.64s/it]{'loss': 0.1458, 'learning_rate': 7e-06, 'epoch': 65.0}\n",
            " 65% 1300/2000 [5:02:28<2:15:45, 11.64s/it][INFO|trainer.py:2463] 2022-05-06 19:01:18,049 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:01:18,049 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:01:18,049 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.81s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.1454637050628662, 'eval_runtime': 26.2079, 'eval_samples_per_second': 5.342, 'eval_steps_per_second': 0.114, 'epoch': 65.0}\n",
            " 65% 1300/2000 [5:02:54<2:15:45, 11.64s/it]\n",
            "100% 3/3 [00:13<00:00,  4.35s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:01:44,259 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1300\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:01:44,260 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1300/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:01:44,846 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1300/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:01:44,847 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1300/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:01:46,973 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1240] due to args.save_total_limit\n",
            "{'loss': 0.1441, 'learning_rate': 6.9e-06, 'epoch': 65.5}\n",
            " 66% 1320/2000 [5:07:10<2:13:21, 11.77s/it]{'loss': 0.1429, 'learning_rate': 6.800000000000001e-06, 'epoch': 66.0}\n",
            " 66% 1320/2000 [5:07:10<2:13:21, 11.77s/it][INFO|trainer.py:2463] 2022-05-06 19:06:00,258 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:06:00,258 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:06:00,258 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.86s/it]\u001b[A\n",
            "                                           \n",
            " 66% 1320/2000 [5:07:36<2:13:21, 11.77s/it]\n",
            "100% 3/3 [00:14<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A{'eval_loss': 0.145236074924469, 'eval_runtime': 26.3082, 'eval_samples_per_second': 5.322, 'eval_steps_per_second': 0.114, 'epoch': 66.0}\n",
            "[INFO|trainer.py:2213] 2022-05-06 19:06:26,568 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1320\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:06:26,569 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1320/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:06:27,164 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1320/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:06:27,164 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1320/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:06:29,351 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1260] due to args.save_total_limit\n",
            "{'loss': 0.1449, 'learning_rate': 6.700000000000001e-06, 'epoch': 66.5}\n",
            "{'loss': 0.1411, 'learning_rate': 6.600000000000001e-06, 'epoch': 67.0}\n",
            " 67% 1340/2000 [5:11:52<2:07:31, 11.59s/it][INFO|trainer.py:2463] 2022-05-06 19:10:42,071 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:10:42,072 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:10:42,072 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.82s/it]\u001b[A\n",
            "                                           \n",
            " 67% 1340/2000 [5:12:18<2:07:31, 11.59s/it]\n",
            "100% 3/3 [00:14<00:00,  4.39s/it]\u001b[A\n",
            "                                 {'eval_loss': 0.14579841494560242, 'eval_runtime': 26.2368, 'eval_samples_per_second': 5.336, 'eval_steps_per_second': 0.114, 'epoch': 67.0}\n",
            "\u001b[A[INFO|trainer.py:2213] 2022-05-06 19:11:08,311 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1340\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:11:08,312 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1340/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:11:08,895 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1340/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:11:08,895 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1340/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:11:10,970 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1280] due to args.save_total_limit\n",
            "{'loss': 0.1413, 'learning_rate': 6.5000000000000004e-06, 'epoch': 67.5}\n",
            " 68% 1360/2000 [5:16:33<2:05:20, 11.75s/it]{'loss': 0.1442, 'learning_rate': 6.4000000000000006e-06, 'epoch': 68.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 19:15:23,145 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:15:23,145 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:15:23,145 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.84s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14788463711738586, 'eval_runtime': 26.2939, 'eval_samples_per_second': 5.324, 'eval_steps_per_second': 0.114, 'epoch': 68.0}\n",
            " 68% 1360/2000 [5:16:59<2:05:20, 11.75s/it]\n",
            "100% 3/3 [00:13<00:00,  4.35s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:15:49,441 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1360\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:15:49,442 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1360/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:15:50,033 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1360/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:15:50,034 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1360/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:15:52,053 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1300] due to args.save_total_limit\n",
            "{'loss': 0.1433, 'learning_rate': 6.300000000000001e-06, 'epoch': 68.5}\n",
            "{'loss': 0.1416, 'learning_rate': 6.200000000000001e-06, 'epoch': 69.0}\n",
            " 69% 1380/2000 [5:21:14<2:01:04, 11.72s/it][INFO|trainer.py:2463] 2022-05-06 19:20:04,855 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:20:04,855 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:20:04,855 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.84s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.1455240249633789, 'eval_runtime': 26.3913, 'eval_samples_per_second': 5.305, 'eval_steps_per_second': 0.114, 'epoch': 69.0}\n",
            " 69% 1380/2000 [5:21:41<2:01:04, 11.72s/it]\n",
            "100% 3/3 [00:13<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:20:31,249 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1380\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:20:31,250 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1380/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:20:31,848 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1380/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:20:31,849 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1380/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:20:33,624 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1340] due to args.save_total_limit\n",
            "{'loss': 0.1421, 'learning_rate': 6.1e-06, 'epoch': 69.5}\n",
            "{'loss': 0.1428, 'learning_rate': 6e-06, 'epoch': 70.0}\n",
            " 70% 1400/2000 [5:25:56<1:56:36, 11.66s/it][INFO|trainer.py:2463] 2022-05-06 19:24:46,943 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:24:46,944 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:24:46,944 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.87s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14573948085308075, 'eval_runtime': 26.4237, 'eval_samples_per_second': 5.298, 'eval_steps_per_second': 0.114, 'epoch': 70.0}\n",
            " 70% 1400/2000 [5:26:23<1:56:36, 11.66s/it]\n",
            "100% 3/3 [00:14<00:00,  4.38s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:25:13,369 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1400\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:25:13,370 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1400/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:25:13,985 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1400/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:25:13,986 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1400/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:25:16,323 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1360] due to args.save_total_limit\n",
            " 70% 1410/2000 [5:28:35<2:10:00, 13.22s/it]{'loss': 0.1421, 'learning_rate': 5.9e-06, 'epoch': 70.5}\n",
            " 71% 1420/2000 [5:30:39<1:52:54, 11.68s/it]{'loss': 0.1431, 'learning_rate': 5.8e-06, 'epoch': 71.0}\n",
            " 71% 1420/2000 [5:30:39<1:52:54, 11.68s/it][INFO|trainer.py:2463] 2022-05-06 19:29:29,470 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:29:29,470 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:29:29,470 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.80s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14530250430107117, 'eval_runtime': 26.1451, 'eval_samples_per_second': 5.355, 'eval_steps_per_second': 0.115, 'epoch': 71.0}\n",
            " 71% 1420/2000 [5:31:05<1:52:54, 11.68s/it]\n",
            "100% 3/3 [00:13<00:00,  4.33s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:29:55,617 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1420\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:29:55,619 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1420/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:29:56,182 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1420/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:29:56,183 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1420/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:29:58,381 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1380] due to args.save_total_limit\n",
            "{'loss': 0.1439, 'learning_rate': 5.7e-06, 'epoch': 71.5}\n",
            "{'loss': 0.1405, 'learning_rate': 5.600000000000001e-06, 'epoch': 72.0}\n",
            " 72% 1440/2000 [5:35:21<1:48:53, 11.67s/it][INFO|trainer.py:2463] 2022-05-06 19:34:11,442 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:34:11,442 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:34:11,442 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.90s/it]\u001b[A\n",
            "{'eval_loss': 0.1493758112192154, 'eval_runtime': 26.3914, 'eval_samples_per_second': 5.305, 'eval_steps_per_second': 0.114, 'epoch': 72.0}\n",
            "\n",
            " 72% 1440/2000 [5:35:47<1:48:53, 11.67s/it]\n",
            "100% 3/3 [00:14<00:00,  4.40s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:34:37,835 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1440\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:34:37,836 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1440/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:34:38,417 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1440/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:34:38,418 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1440/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:34:40,438 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1400] due to args.save_total_limit\n",
            " 72% 1450/2000 [5:37:58<1:59:31, 13.04s/it]{'loss': 0.1414, 'learning_rate': 5.500000000000001e-06, 'epoch': 72.5}\n",
            "{'loss': 0.1432, 'learning_rate': 5.400000000000001e-06, 'epoch': 73.0}\n",
            " 73% 1460/2000 [5:40:04<1:46:42, 11.86s/it][INFO|trainer.py:2463] 2022-05-06 19:38:54,372 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:38:54,372 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:38:54,372 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.83s/it]\u001b[A\n",
            "                                           \n",
            " 73% 1460/2000 [5:40:30<1:46:42, 11.86s/it]\n",
            "100% 3/3 [00:14<00:00,  4.38s/it]{'eval_loss': 0.14658255875110626, 'eval_runtime': 26.3398, 'eval_samples_per_second': 5.315, 'eval_steps_per_second': 0.114, 'epoch': 73.0}\n",
            "\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:39:20,714 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1460\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:39:20,715 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1460/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:39:21,282 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1460/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:39:21,283 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1460/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:39:23,323 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1420] due to args.save_total_limit\n",
            "{'loss': 0.1423, 'learning_rate': 5.300000000000001e-06, 'epoch': 73.5}\n",
            " 74% 1480/2000 [5:44:47<1:41:38, 11.73s/it]{'loss': 0.1428, 'learning_rate': 5.2e-06, 'epoch': 74.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 19:43:37,491 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:43:37,491 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:43:37,492 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.85s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14624786376953125, 'eval_runtime': 26.3175, 'eval_samples_per_second': 5.32, 'eval_steps_per_second': 0.114, 'epoch': 74.0}\n",
            " 74% 1480/2000 [5:45:13<1:41:38, 11.73s/it]\n",
            "100% 3/3 [00:14<00:00,  4.38s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:44:03,811 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1480\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:44:03,812 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1480/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:44:04,393 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1480/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:44:04,393 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1480/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:44:06,594 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1440] due to args.save_total_limit\n",
            "{'loss': 0.1418, 'learning_rate': 5.1e-06, 'epoch': 74.5}\n",
            " 75% 1500/2000 [5:49:30<1:37:56, 11.75s/it]{'loss': 0.141, 'learning_rate': 5e-06, 'epoch': 75.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 19:48:20,595 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:48:20,595 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:48:20,595 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.86s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14606311917304993, 'eval_runtime': 26.3861, 'eval_samples_per_second': 5.306, 'eval_steps_per_second': 0.114, 'epoch': 75.0}\n",
            " 75% 1500/2000 [5:49:57<1:37:56, 11.75s/it]\n",
            "100% 3/3 [00:14<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:48:46,983 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1500\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:48:46,984 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:48:47,531 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:48:47,532 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1500/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:48:49,558 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1460] due to args.save_total_limit\n",
            "{'loss': 0.1432, 'learning_rate': 4.9000000000000005e-06, 'epoch': 75.5}\n",
            "{'loss': 0.1397, 'learning_rate': 4.800000000000001e-06, 'epoch': 76.0}\n",
            " 76% 1520/2000 [5:54:14<1:33:35, 11.70s/it][INFO|trainer.py:2463] 2022-05-06 19:53:04,707 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:53:04,707 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:53:04,707 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.90s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14689229428768158, 'eval_runtime': 26.526, 'eval_samples_per_second': 5.278, 'eval_steps_per_second': 0.113, 'epoch': 76.0}\n",
            " 76% 1520/2000 [5:54:41<1:33:35, 11.70s/it]\n",
            "100% 3/3 [00:14<00:00,  4.39s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 19:53:31,235 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1520\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:53:31,236 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1520/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:53:31,799 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1520/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:53:31,800 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1520/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:53:33,873 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1480] due to args.save_total_limit\n",
            " 76% 1530/2000 [5:56:53<1:43:16, 13.18s/it]{'loss': 0.1421, 'learning_rate': 4.7e-06, 'epoch': 76.5}\n",
            " 77% 1540/2000 [5:58:58<1:30:26, 11.80s/it]{'loss': 0.1419, 'learning_rate': 4.600000000000001e-06, 'epoch': 77.0}\n",
            " 77% 1540/2000 [5:58:58<1:30:26, 11.80s/it][INFO|trainer.py:2463] 2022-05-06 19:57:47,962 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 19:57:47,962 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 19:57:47,962 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.89s/it]\u001b[A\n",
            "                                           \n",
            " 77% 1540/2000 [5:59:24<1:30:26, 11.80s/it]\n",
            "100% 3/3 [00:14<00:00,  4.40s/it]\u001b[A\n",
            "                                 \u001b[A{'eval_loss': 0.14643330872058868, 'eval_runtime': 26.5436, 'eval_samples_per_second': 5.274, 'eval_steps_per_second': 0.113, 'epoch': 77.0}\n",
            "[INFO|trainer.py:2213] 2022-05-06 19:58:14,508 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1540\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 19:58:14,509 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1540/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 19:58:15,072 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1540/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 19:58:15,073 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1540/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 19:58:17,379 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1500] due to args.save_total_limit\n",
            "                                           {'loss': 0.1438, 'learning_rate': 4.5e-06, 'epoch': 77.5}\n",
            " 78% 1560/2000 [6:03:42<1:26:48, 11.84s/it]{'loss': 0.1402, 'learning_rate': 4.4e-06, 'epoch': 78.0}\n",
            " 78% 1560/2000 [6:03:42<1:26:48, 11.84s/it][INFO|trainer.py:2463] 2022-05-06 20:02:32,701 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:02:32,701 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:02:32,702 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.91s/it]\u001b[A\n",
            "100% 3/3 [00:14<00:00,  4.40s/it]\u001b[A{'eval_loss': 0.14521874487400055, 'eval_runtime': 26.6234, 'eval_samples_per_second': 5.259, 'eval_steps_per_second': 0.113, 'epoch': 78.0}\n",
            "                                           \n",
            " 78% 1560/2000 [6:04:09<1:26:48, 11.84s/it]\n",
            "100% 3/3 [00:14<00:00,  4.40s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:02:59,327 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1560\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:02:59,328 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1560/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:02:59,907 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1560/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:02:59,907 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1560/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:03:01,961 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1320] due to args.save_total_limit\n",
            " 78% 1570/2000 [6:06:22<1:35:44, 13.36s/it]{'loss': 0.1428, 'learning_rate': 4.3e-06, 'epoch': 78.5}\n",
            "{'loss': 0.1404, 'learning_rate': 4.2000000000000004e-06, 'epoch': 79.0}\n",
            " 79% 1580/2000 [6:08:28<1:23:20, 11.91s/it][INFO|trainer.py:2463] 2022-05-06 20:07:18,737 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:07:18,737 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:07:18,737 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.91s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.146683931350708, 'eval_runtime': 26.5116, 'eval_samples_per_second': 5.281, 'eval_steps_per_second': 0.113, 'epoch': 79.0}\n",
            " 79% 1580/2000 [6:08:55<1:23:20, 11.91s/it]\n",
            "100% 3/3 [00:14<00:00,  4.39s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:07:45,250 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1580\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:07:45,251 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1580/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:07:45,866 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1580/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:07:45,867 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1580/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:07:47,782 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1520] due to args.save_total_limit\n",
            "{'loss': 0.1409, 'learning_rate': 4.1e-06, 'epoch': 79.5}\n",
            "{'loss': 0.1425, 'learning_rate': 4.000000000000001e-06, 'epoch': 80.0}\n",
            " 80% 1600/2000 [6:13:14<1:19:09, 11.87s/it][INFO|trainer.py:2463] 2022-05-06 20:12:04,312 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:12:04,312 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:12:04,312 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.87s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14702410995960236, 'eval_runtime': 26.6131, 'eval_samples_per_second': 5.261, 'eval_steps_per_second': 0.113, 'epoch': 80.0}\n",
            " 80% 1600/2000 [6:13:40<1:19:09, 11.87s/it]\n",
            "100% 3/3 [00:14<00:00,  4.38s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:12:30,927 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1600\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:12:30,928 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1600/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:12:31,510 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1600/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:12:31,510 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1600/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:12:33,566 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1540] due to args.save_total_limit\n",
            "{'loss': 0.1413, 'learning_rate': 3.900000000000001e-06, 'epoch': 80.5}\n",
            " 81% 1620/2000 [6:17:59<1:15:04, 11.85s/it]{'loss': 0.1413, 'learning_rate': 3.8000000000000005e-06, 'epoch': 81.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 20:16:49,004 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:16:49,004 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:16:49,005 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.95s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14569781720638275, 'eval_runtime': 26.6398, 'eval_samples_per_second': 5.255, 'eval_steps_per_second': 0.113, 'epoch': 81.0}\n",
            " 81% 1620/2000 [6:18:25<1:15:04, 11.85s/it]\n",
            "100% 3/3 [00:14<00:00,  4.44s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:17:15,646 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1620\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:17:15,647 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1620/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:17:16,230 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1620/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:17:16,231 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1620/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:17:18,372 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1580] due to args.save_total_limit\n",
            "{'loss': 0.1426, 'learning_rate': 3.7e-06, 'epoch': 81.5}\n",
            " 82% 1640/2000 [6:22:45<1:10:39, 11.78s/it]{'loss': 0.1385, 'learning_rate': 3.6000000000000003e-06, 'epoch': 82.0}\n",
            " 82% 1640/2000 [6:22:45<1:10:39, 11.78s/it][INFO|trainer.py:2463] 2022-05-06 20:21:35,085 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:21:35,085 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:21:35,085 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.96s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14647260308265686, 'eval_runtime': 26.7629, 'eval_samples_per_second': 5.231, 'eval_steps_per_second': 0.112, 'epoch': 82.0}\n",
            " 82% 1640/2000 [6:23:11<1:10:39, 11.78s/it]\n",
            "100% 3/3 [00:14<00:00,  4.44s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:22:01,850 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1640\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:22:01,851 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1640/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:22:02,448 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1640/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:22:02,449 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1640/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:22:04,684 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1600] due to args.save_total_limit\n",
            "{'loss': 0.1407, 'learning_rate': 3.5e-06, 'epoch': 82.5}\n",
            "{'loss': 0.1417, 'learning_rate': 3.4000000000000005e-06, 'epoch': 83.0}\n",
            " 83% 1660/2000 [6:27:31<1:07:28, 11.91s/it][INFO|trainer.py:2463] 2022-05-06 20:26:21,286 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:26:21,286 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:26:21,286 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.94s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.14634524285793304, 'eval_runtime': 26.5891, 'eval_samples_per_second': 5.265, 'eval_steps_per_second': 0.113, 'epoch': 83.0}\n",
            " 83% 1660/2000 [6:27:57<1:07:28, 11.91s/it]\n",
            "100% 3/3 [00:14<00:00,  4.42s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:26:47,877 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1660\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:26:47,878 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1660/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:26:48,451 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1660/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:26:48,452 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1660/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:26:50,480 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1620] due to args.save_total_limit\n",
            "{'loss': 0.1391, 'learning_rate': 3.3000000000000006e-06, 'epoch': 83.5}\n",
            "{'loss': 0.1433, 'learning_rate': 3.2000000000000003e-06, 'epoch': 84.0}\n",
            " 84% 1680/2000 [6:32:17<1:03:25, 11.89s/it][INFO|trainer.py:2463] 2022-05-06 20:31:07,644 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:31:07,644 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:31:07,644 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.91s/it]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.1438603550195694, 'eval_runtime': 26.5973, 'eval_samples_per_second': 5.264, 'eval_steps_per_second': 0.113, 'epoch': 84.0}\n",
            " 84% 1680/2000 [6:32:44<1:03:25, 11.89s/it]\n",
            "100% 3/3 [00:14<00:00,  4.40s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:31:34,244 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1680\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:31:34,244 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1680/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:31:34,836 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1680/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:31:34,837 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1680/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:31:36,870 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1560] due to args.save_total_limit\n",
            " 84% 1690/2000 [6:34:57<1:09:01, 13.36s/it]{'loss': 0.1402, 'learning_rate': 3.1000000000000004e-06, 'epoch': 84.5}\n",
            "{'loss': 0.1428, 'learning_rate': 3e-06, 'epoch': 85.0}\n",
            " 85% 1700/2000 [6:37:03<59:39, 11.93s/it][INFO|trainer.py:2463] 2022-05-06 20:35:53,206 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:35:53,206 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:35:53,206 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.95s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.14824825525283813, 'eval_runtime': 26.7057, 'eval_samples_per_second': 5.242, 'eval_steps_per_second': 0.112, 'epoch': 85.0}\n",
            " 85% 1700/2000 [6:37:29<59:39, 11.93s/it]\n",
            "100% 3/3 [00:14<00:00,  4.43s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:36:19,914 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1700\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:36:19,915 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1700/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:36:20,494 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1700/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:36:20,495 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1700/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:36:22,481 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1640] due to args.save_total_limit\n",
            "{'loss': 0.1421, 'learning_rate': 2.9e-06, 'epoch': 85.5}\n",
            "{'loss': 0.1411, 'learning_rate': 2.8000000000000003e-06, 'epoch': 86.0}\n",
            " 86% 1720/2000 [6:41:48<55:03, 11.80s/it][INFO|trainer.py:2463] 2022-05-06 20:40:38,419 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:40:38,419 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:40:38,419 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.92s/it]\u001b[A\n",
            "                                         \n",
            " 86% 1720/2000 [6:42:15<55:03, 11.80s/it]\n",
            "100% 3/3 [00:14<00:00,  4.41s/it]\u001b[A\n",
            "                                 \u001b[A{'eval_loss': 0.14808973670005798, 'eval_runtime': 26.5423, 'eval_samples_per_second': 5.275, 'eval_steps_per_second': 0.113, 'epoch': 86.0}\n",
            "[INFO|trainer.py:2213] 2022-05-06 20:41:04,963 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1720\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:41:04,964 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1720/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:41:05,563 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1720/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:41:05,564 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1720/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:41:07,596 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1660] due to args.save_total_limit\n",
            "{'loss': 0.1423, 'learning_rate': 2.7000000000000004e-06, 'epoch': 86.5}\n",
            " 87% 1740/2000 [6:46:33<51:02, 11.78s/it]{'loss': 0.1415, 'learning_rate': 2.6e-06, 'epoch': 87.0}\n",
            " 87% 1740/2000 [6:46:33<51:02, 11.78s/it][INFO|trainer.py:2463] 2022-05-06 20:45:23,837 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:45:23,837 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:45:23,837 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.90s/it]\u001b[A\n",
            "                                         \n",
            "{'eval_loss': 0.1469506174325943, 'eval_runtime': 26.5878, 'eval_samples_per_second': 5.266, 'eval_steps_per_second': 0.113, 'epoch': 87.0}\n",
            " 87% 1740/2000 [6:47:00<51:02, 11.78s/it]\n",
            "100% 3/3 [00:14<00:00,  4.39s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:45:50,427 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1740\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:45:50,428 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1740/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:45:51,024 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1740/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:45:51,025 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1740/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:45:53,071 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1700] due to args.save_total_limit\n",
            "{'loss': 0.1412, 'learning_rate': 2.5e-06, 'epoch': 87.5}\n",
            " 88% 1760/2000 [6:51:19<47:36, 11.90s/it]{'loss': 0.1413, 'learning_rate': 2.4000000000000003e-06, 'epoch': 88.0}\n",
            " 88% 1760/2000 [6:51:19<47:36, 11.90s/it][INFO|trainer.py:2463] 2022-05-06 20:50:09,740 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:50:09,741 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:50:09,741 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.87s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.14478132128715515, 'eval_runtime': 26.622, 'eval_samples_per_second': 5.259, 'eval_steps_per_second': 0.113, 'epoch': 88.0}\n",
            " 88% 1760/2000 [6:51:46<47:36, 11.90s/it]\n",
            "100% 3/3 [00:14<00:00,  4.42s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:50:36,365 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1760\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:50:36,366 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1760/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:50:36,951 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1760/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:50:36,952 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1760/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:50:38,994 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1720] due to args.save_total_limit\n",
            "{'loss': 0.1416, 'learning_rate': 2.3000000000000004e-06, 'epoch': 88.5}\n",
            "{'loss': 0.141, 'learning_rate': 2.2e-06, 'epoch': 89.0}\n",
            " 89% 1780/2000 [6:56:05<43:21, 11.82s/it][INFO|trainer.py:2463] 2022-05-06 20:54:55,593 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:54:55,593 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:54:55,595 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.91s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.1447717398405075, 'eval_runtime': 26.593, 'eval_samples_per_second': 5.265, 'eval_steps_per_second': 0.113, 'epoch': 89.0}\n",
            " 89% 1780/2000 [6:56:32<43:21, 11.82s/it]\n",
            "100% 3/3 [00:14<00:00,  4.43s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 20:55:22,188 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1780\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 20:55:22,189 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1780/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 20:55:22,772 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1780/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 20:55:22,773 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1780/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 20:55:24,795 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1740] due to args.save_total_limit\n",
            "{'loss': 0.1409, 'learning_rate': 2.1000000000000002e-06, 'epoch': 89.5}\n",
            " 90% 1800/2000 [7:00:50<39:20, 11.80s/it]{'loss': 0.1405, 'learning_rate': 2.0000000000000003e-06, 'epoch': 90.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 20:59:40,153 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 20:59:40,153 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 20:59:40,153 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.88s/it]\u001b[A\n",
            "                                         \n",
            "{'eval_loss': 0.14412449300289154, 'eval_runtime': 26.5237, 'eval_samples_per_second': 5.278, 'eval_steps_per_second': 0.113, 'epoch': 90.0}\n",
            " 90% 1800/2000 [7:01:16<39:20, 11.80s/it]\n",
            "100% 3/3 [00:14<00:00,  4.38s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:00:06,679 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1800\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:00:06,680 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1800/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:00:07,290 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1800/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:00:07,291 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1800/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:00:09,542 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1760] due to args.save_total_limit\n",
            "{'loss': 0.1414, 'learning_rate': 1.9000000000000002e-06, 'epoch': 90.5}\n",
            "{'loss': 0.1407, 'learning_rate': 1.8000000000000001e-06, 'epoch': 91.0}\n",
            " 91% 1820/2000 [7:05:33<34:45, 11.59s/it][INFO|trainer.py:2463] 2022-05-06 21:04:23,074 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:04:23,074 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:04:23,074 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.85s/it]\u001b[A\n",
            "                                         \n",
            "{'eval_loss': 0.14571037888526917, 'eval_runtime': 26.4004, 'eval_samples_per_second': 5.303, 'eval_steps_per_second': 0.114, 'epoch': 91.0}\n",
            " 91% 1820/2000 [7:05:59<34:45, 11.59s/it]\n",
            "100% 3/3 [00:13<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:04:49,476 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1820\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:04:49,478 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1820/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:04:50,061 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1820/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:04:50,061 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1820/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:04:52,084 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1780] due to args.save_total_limit\n",
            " 92% 1830/2000 [7:08:10<37:15, 13.15s/it]{'loss': 0.1412, 'learning_rate': 1.7000000000000002e-06, 'epoch': 91.5}\n",
            "{'loss': 0.1412, 'learning_rate': 1.6000000000000001e-06, 'epoch': 92.0}\n",
            " 92% 1840/2000 [7:10:16<31:18, 11.74s/it][INFO|trainer.py:2463] 2022-05-06 21:09:06,061 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:09:06,061 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:09:06,061 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.88s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.1436501294374466, 'eval_runtime': 26.5146, 'eval_samples_per_second': 5.28, 'eval_steps_per_second': 0.113, 'epoch': 92.0}\n",
            " 92% 1840/2000 [7:10:42<31:18, 11.74s/it]\n",
            "100% 3/3 [00:14<00:00,  4.39s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:09:32,578 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1840\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:09:32,579 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1840/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:09:33,172 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1840/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:09:33,173 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1840/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:09:35,279 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1680] due to args.save_total_limit\n",
            "{'loss': 0.1396, 'learning_rate': 1.5e-06, 'epoch': 92.5}\n",
            "{'loss': 0.1425, 'learning_rate': 1.4000000000000001e-06, 'epoch': 93.0}\n",
            " 93% 1860/2000 [7:14:59<27:23, 11.74s/it][INFO|trainer.py:2463] 2022-05-06 21:13:49,427 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:13:49,427 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:13:49,427 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.92s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.14588500559329987, 'eval_runtime': 26.7501, 'eval_samples_per_second': 5.234, 'eval_steps_per_second': 0.112, 'epoch': 93.0}\n",
            " 93% 1860/2000 [7:15:26<27:23, 11.74s/it]\n",
            "100% 3/3 [00:14<00:00,  4.43s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:14:16,179 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1860\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:14:16,180 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1860/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:14:16,750 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1860/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:14:16,751 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1860/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:14:18,772 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1800] due to args.save_total_limit\n",
            " 94% 1870/2000 [7:17:37<28:32, 13.17s/it]{'loss': 0.1403, 'learning_rate': 1.3e-06, 'epoch': 93.5}\n",
            "{'loss': 0.1413, 'learning_rate': 1.2000000000000002e-06, 'epoch': 94.0}\n",
            " 94% 1880/2000 [7:19:42<23:08, 11.57s/it][INFO|trainer.py:2463] 2022-05-06 21:18:32,246 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:18:32,246 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:18:32,246 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.93s/it]\u001b[A\n",
            "100% 3/3 [00:14<00:00,  4.42s/it]\u001b[A{'eval_loss': 0.14603273570537567, 'eval_runtime': 26.5472, 'eval_samples_per_second': 5.274, 'eval_steps_per_second': 0.113, 'epoch': 94.0}\n",
            "                                         \n",
            " 94% 1880/2000 [7:20:08<23:08, 11.57s/it]\n",
            "100% 3/3 [00:14<00:00,  4.42s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:18:58,795 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1880\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:18:58,797 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1880/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:18:59,391 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1880/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:18:59,392 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1880/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:19:01,401 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1820] due to args.save_total_limit\n",
            "{'loss': 0.139, 'learning_rate': 1.1e-06, 'epoch': 94.5}\n",
            " 95% 1900/2000 [7:24:24<19:36, 11.77s/it]{'loss': 0.1434, 'learning_rate': 1.0000000000000002e-06, 'epoch': 95.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 21:23:14,916 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:23:14,917 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:23:14,917 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.92s/it]\u001b[A\n",
            "                                         \n",
            " 95% 1900/2000 [7:24:51<19:36, 11.77s/it]\n",
            "100% 3/3 [00:14<00:00,  4.41s/it]{'eval_loss': 0.1457941085100174, 'eval_runtime': 26.5873, 'eval_samples_per_second': 5.266, 'eval_steps_per_second': 0.113, 'epoch': 95.0}\n",
            "\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:23:41,506 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1900\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:23:41,507 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1900/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:23:42,279 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1900/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:23:42,280 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1900/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:23:44,766 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1860] due to args.save_total_limit\n",
            "{'loss': 0.1397, 'learning_rate': 9.000000000000001e-07, 'epoch': 95.5}\n",
            " 96% 1920/2000 [7:29:08<15:34, 11.68s/it]{'loss': 0.1415, 'learning_rate': 8.000000000000001e-07, 'epoch': 96.0}\n",
            "[INFO|trainer.py:2463] 2022-05-06 21:27:57,987 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:27:57,987 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:27:57,987 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.86s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.1447780430316925, 'eval_runtime': 26.4015, 'eval_samples_per_second': 5.303, 'eval_steps_per_second': 0.114, 'epoch': 96.0}\n",
            " 96% 1920/2000 [7:29:34<15:34, 11.68s/it]\n",
            "100% 3/3 [00:14<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:28:24,390 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1920\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:28:24,391 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1920/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:28:24,948 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1920/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:28:24,949 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1920/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:28:26,971 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1880] due to args.save_total_limit\n",
            "{'loss': 0.1419, 'learning_rate': 7.000000000000001e-07, 'epoch': 96.5}\n",
            "{'loss': 0.141, 'learning_rate': 6.000000000000001e-07, 'epoch': 97.0}\n",
            " 97% 1940/2000 [7:33:50<11:43, 11.73s/it][INFO|trainer.py:2463] 2022-05-06 21:32:40,891 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:32:40,891 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:32:40,891 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.87s/it]\u001b[A\n",
            "                                         \n",
            " 97% 1940/2000 [7:34:17<11:43, 11.73s/it]\n",
            "100% 3/3 [00:14<00:00,  4.39s/it]\u001b[A\n",
            "                                 \u001b[A{'eval_loss': 0.14505386352539062, 'eval_runtime': 26.552, 'eval_samples_per_second': 5.273, 'eval_steps_per_second': 0.113, 'epoch': 97.0}\n",
            "[INFO|trainer.py:2213] 2022-05-06 21:33:07,445 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1940\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:33:07,446 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1940/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:33:08,014 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1940/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:33:08,014 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1940/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:33:10,043 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1900] due to args.save_total_limit\n",
            "{'loss': 0.1405, 'learning_rate': 5.000000000000001e-07, 'epoch': 97.5}\n",
            "{'loss': 0.1418, 'learning_rate': 4.0000000000000003e-07, 'epoch': 98.0}\n",
            " 98% 1960/2000 [7:38:33<07:48, 11.72s/it][INFO|trainer.py:2463] 2022-05-06 21:37:23,440 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:37:23,440 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:37:23,440 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.86s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.14696939289569855, 'eval_runtime': 26.4003, 'eval_samples_per_second': 5.303, 'eval_steps_per_second': 0.114, 'epoch': 98.0}\n",
            " 98% 1960/2000 [7:38:59<07:48, 11.72s/it]\n",
            "100% 3/3 [00:13<00:00,  4.37s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:37:49,843 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1960\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:37:49,844 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1960/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:37:50,390 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1960/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:37:50,391 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1960/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:37:52,460 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1920] due to args.save_total_limit\n",
            "{'loss': 0.1404, 'learning_rate': 3.0000000000000004e-07, 'epoch': 98.5}\n",
            "{'loss': 0.142, 'learning_rate': 2.0000000000000002e-07, 'epoch': 99.0}\n",
            " 99% 1980/2000 [7:43:15<03:55, 11.77s/it][INFO|trainer.py:2463] 2022-05-06 21:42:05,855 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:42:05,856 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:42:05,856 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.89s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.14740340411663055, 'eval_runtime': 26.6012, 'eval_samples_per_second': 5.263, 'eval_steps_per_second': 0.113, 'epoch': 99.0}\n",
            " 99% 1980/2000 [7:43:42<03:55, 11.77s/it]\n",
            "100% 3/3 [00:14<00:00,  4.41s/it]\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:42:32,459 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-1980\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:42:32,460 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1980/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:42:33,020 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1980/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:42:33,020 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-1980/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:42:34,980 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1940] due to args.save_total_limit\n",
            "                                         {'loss': 0.1404, 'learning_rate': 1.0000000000000001e-07, 'epoch': 99.5}\n",
            "{'loss': 0.1416, 'learning_rate': 0.0, 'epoch': 100.0}\n",
            "100% 2000/2000 [7:47:58<00:00, 11.69s/it][INFO|trainer.py:2463] 2022-05-06 21:46:48,059 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:46:48,059 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:46:48,059 >>   Batch size = 64\n",
            "\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:11<00:05,  5.91s/it]\u001b[A\n",
            "                                         \n",
            "100% 2000/2000 [7:48:24<00:00, 11.69s/it]\n",
            "100% 3/3 [00:14<00:00,  4.40s/it]{'eval_loss': 0.14465276896953583, 'eval_runtime': 26.6001, 'eval_samples_per_second': 5.263, 'eval_steps_per_second': 0.113, 'epoch': 100.0}\n",
            "\u001b[A\n",
            "                                 \u001b[A[INFO|trainer.py:2213] 2022-05-06 21:47:14,662 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim/checkpoint-2000\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:47:14,663 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:47:15,211 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:47:15,211 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/checkpoint-2000/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-06 21:47:17,305 >> Deleting older checkpoint [crop14-small_pretrain_vit-base-mim/checkpoint-1960] due to args.save_total_limit\n",
            "[INFO|trainer.py:1537] 2022-05-06 21:47:17,425 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1602] 2022-05-06 21:47:17,425 >> Loading best model from ./crop14-small_pretrain_vit-base-mim/checkpoint-1840 (score: 0.1436501294374466).\n",
            "                                         {'train_runtime': 28112.5847, 'train_samples_per_second': 4.482, 'train_steps_per_second': 0.071, 'train_loss': 0.16525052320957184, 'epoch': 100.0}\n",
            "100% 2000/2000 [7:48:28<00:00, 14.05s/it]\n",
            "[INFO|trainer.py:2213] 2022-05-06 21:47:18,746 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:47:18,747 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:47:19,568 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:47:19,595 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/preprocessor_config.json\n",
            "[INFO|trainer.py:2213] 2022-05-06 21:47:19,597 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:47:19,598 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:47:20,340 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:47:20,341 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/preprocessor_config.json\n",
            "05/06/2022 21:47:30 - WARNING - huggingface_hub.repository - Several commits (3) will be pushed upstream.\n",
            "Several commits (3) will be pushed upstream.\n",
            "05/06/2022 21:47:30 - WARNING - huggingface_hub.repository - The progress bars may be unreliable.\n",
            "The progress bars may be unreliable.\n",
            "Upload file pytorch_model.bin:   0% 3.34k/330M [00:00<?, ?B/s]\n",
            "Upload file pytorch_model.bin: 100% 329M/330M [04:25<00:00, 1.29MB/s]remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   9b6a28d..24a93db  main -> main\n",
            "\n",
            "05/06/2022 21:52:05 - WARNING - huggingface_hub.repository - remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   9b6a28d..24a93db  main -> main\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 330M/330M [04:28<00:00, 1.29MB/s]\n",
            "\n",
            "Upload file runs/May06_13-58-23_f1d68f6fa2eb/events.out.tfevents.1651845526.f1d68f6fa2eb.1309.0: 100% 60.7k/60.7k [04:28<00:00, 219B/s]\u001b[A\n",
            "Upload file runs/May06_13-58-23_f1d68f6fa2eb/events.out.tfevents.1651845526.f1d68f6fa2eb.1309.0: 100% 60.7k/60.7k [04:28<00:00, 219B/s]\n",
            "[INFO|modelcard.py:460] 2022-05-06 21:52:09,396 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'dataset': {'name': 'crop14', 'type': 'crop14', 'args': 'crop14-small'}}\n",
            "remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   24a93db..97a1f19  main -> main\n",
            "\n",
            "05/06/2022 21:52:15 - WARNING - huggingface_hub.repository - remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   24a93db..97a1f19  main -> main\n",
            "\n",
            "***** train metrics *****\n",
            "  epoch                    =      100.0\n",
            "  train_loss               =     0.1653\n",
            "  train_runtime            = 7:48:32.58\n",
            "  train_samples_per_second =      4.482\n",
            "  train_steps_per_second   =      0.071\n",
            "[INFO|trainer.py:2463] 2022-05-06 21:52:18,277 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-06 21:52:18,278 >>   Num examples = 140\n",
            "[INFO|trainer.py:2468] 2022-05-06 21:52:18,278 >>   Batch size = 64\n",
            "100% 3/3 [00:14<00:00,  4.77s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =      100.0\n",
            "  eval_loss               =     0.1461\n",
            "  eval_runtime            = 0:00:27.35\n",
            "  eval_samples_per_second =      5.118\n",
            "  eval_steps_per_second   =       0.11\n",
            "[INFO|trainer.py:2213] 2022-05-06 21:52:45,673 >> Saving model checkpoint to ./crop14-small_pretrain_vit-base-mim\n",
            "[INFO|configuration_utils.py:446] 2022-05-06 21:52:45,674 >> Configuration saved in ./crop14-small_pretrain_vit-base-mim/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-06 21:52:46,335 >> Model weights saved in ./crop14-small_pretrain_vit-base-mim/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-06 21:52:46,335 >> Feature extractor saved in ./crop14-small_pretrain_vit-base-mim/preprocessor_config.json\n",
            "Upload file runs/May06_13-58-23_f1d68f6fa2eb/events.out.tfevents.1651873965.f1d68f6fa2eb.1309.2: 100% 311/311 [00:00<?, ?B/s]remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   97a1f19..c0986cb  main -> main\n",
            "\n",
            "05/06/2022 21:52:59 - WARNING - huggingface_hub.repository - remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   97a1f19..c0986cb  main -> main\n",
            "\n",
            "Upload file runs/May06_13-58-23_f1d68f6fa2eb/events.out.tfevents.1651873965.f1d68f6fa2eb.1309.2: 100% 311/311 [00:02<?, ?B/s]\n",
            "[INFO|modelcard.py:460] 2022-05-06 21:53:03,351 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'dataset': {'name': 'gary109/crop14-small', 'type': 'crop14', 'args': 'crop14-small'}}\n",
            "remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   c0986cb..a530532  main -> main\n",
            "\n",
            "05/06/2022 21:53:10 - WARNING - huggingface_hub.repository - remote: Enforcing permissions...        \n",
            "remote: Allowed refs: all        \n",
            "To https://huggingface.co/gary109/crop14-small_pretrain_vit-base-mim\n",
            "   c0986cb..a530532  main -> main\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.14611\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 27.3564\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 5.118\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 100.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.1416\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 9.831111944306688e+18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.16525\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 28112.5847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 4.482\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m./crop14-small_pretrain_vit-base-mim\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/gary109/huggingface/runs/2qydnhky\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220506_135846-2qydnhky/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !accelerate launch run_mim.py \\\n",
        "#     --dataset_name=\"gary109/crop14-balance\" \\\n",
        "#     --model_name_or_path=\"facebook/vit-mae-base\" \\\n",
        "#     --output_dir=\"./crop14-balance_pretrain_vit-mae-base\" \\\n",
        "#     --remove_unused_columns=\"False\" \\\n",
        "#     --label_names=\"pixel_values\" \\\n",
        "#     --mask_ratio=\"0.75\" \\\n",
        "#     --norm_pix_loss --do_train --do_eval \\\n",
        "#     --base_learning_rate=\"1.5e-4\" \\\n",
        "#     --lr_scheduler_type=\"cosine\" \\\n",
        "#     --weight_decay=\"0.05\" \\\n",
        "#     --num_train_epochs=\"1000\" \\\n",
        "#     --warmup_ratio=\"0.05\" \\\n",
        "#     --per_device_train_batch_size=\"8\" \\\n",
        "#     --per_device_eval_batch_size=\"8\" \\\n",
        "#     --logging_strategy=\"steps\" \\\n",
        "#     --logging_steps=\"10\" \\\n",
        "#     --evaluation_strategy=\"epoch\" \\\n",
        "#     --save_strategy=\"epoch\" \\\n",
        "#     --load_best_model_at_end=\"True\" \\\n",
        "#     --save_total_limit=\"3\" \\\n",
        "#     --overwrite_output_dir \\\n",
        "#     --push_to_hub \\\n",
        "#     --hub_model_id=\"crop14-balance_pretrain_vit-mae-base\" \\\n",
        "#     --hub_token=\"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\" \\\n",
        "#     --seed=\"1337\" \\\n",
        "#     --use_auth_token=\"True\""
      ],
      "metadata": {
        "id": "RUPOguwFm_lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Others\n",
        "---\n",
        "- google/vit-base-patch16-224\n",
        "- google/vit-base-patch16-384\n",
        "- google/vit-base-patch32-384\n",
        "\n",
        "- google/vit-large-patch16-384\n",
        "- google/vit-large-patch16-224\n",
        "- google/vit-large-patch32-384"
      ],
      "metadata": {
        "id": "-7C6-4xPzihE"
      }
    }
  ]
}