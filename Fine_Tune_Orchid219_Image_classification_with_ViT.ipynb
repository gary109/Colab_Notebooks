{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tune Orchid219 Image classification with ViT",
      "provenance": [],
      "collapsed_sections": [
        "2kKsDcHu0hlX",
        "NhO8MiJ41HLI",
        "RcO8DSXZz7W5",
        "MzvQ9zfD34bE",
        "p9t54nRI4B5q",
        "NNvuAbjI4PWH",
        "WJsYvA7u4dLr",
        "qaNA2JF34UPN",
        "Zl3ycpATNA-w"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gary109/Colab_Notebooks/blob/main/Fine_Tune_Orchid219_Image_classification_with_ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FOR TPU needs\n",
        "---"
      ],
      "metadata": {
        "id": "5lYnSRfsvhd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall -y torch\n",
        "!pip install torch==1.8.2+cpu torchvision==0.9.2+cpu -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "94vK4zQPvfGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 是否要掛載 Google Drive\n",
        "---"
      ],
      "metadata": {
        "id": "2kKsDcHu0hlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4aEAQyCz1950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2d3743-f2fc-431c-9152-f5401d08c243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 確認 GPU 類型\n",
        "---"
      ],
      "metadata": {
        "id": "2ozr9xyv0ZMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
        "print(\"device name\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "aDtXj7uU119F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4888bd-66b0-4df1-ce89-c65080e322d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device name Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安裝 transformers,datastes,... 相依套件\n",
        "---"
      ],
      "metadata": {
        "id": "1O9n-3Ak0rik"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9T850192NHC"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/huggingface/datasets.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install soundfile\n",
        "!pip install jiwer\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!apt install git-lfs\n",
        "!git config --global user.email \"gary109@gmail.com\"\n",
        "!git config --global user.name \"GARY\"\n",
        "!git config --global credential.helper store\n",
        "!pip install wandb "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 2cf656515a3b158f4f603aeba63181236de2fc1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQrdzk_L9N01",
        "outputId": "9dd6e4ee-4cf9-4d76-e1a2-23404b775722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 登入 huggingface \n",
        "---"
      ],
      "metadata": {
        "id": "A1JcSRcJ0_uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login\n",
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd123f44-38df-4a44-9146-de29fb7f9c66",
        "id": "yC1Cp6_e2U77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens.\n",
            "        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n",
            "        \n",
            "Token: \n",
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安裝加速器\n",
        "---"
      ],
      "metadata": {
        "id": "F3AZ8EIyzzir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install accelerate deepspeed"
      ],
      "metadata": {
        "id": "WsDxQ0683W6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJJEgLEi7OBF",
        "outputId": "eebc2b75-2042-403f-905b-bdd8f241eb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0\n",
            "Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU): 0\n",
            "Do you want to run your training on CPU only (even if a GPU is available)? [yes/NO]:\n",
            "Do you want to use DeepSpeed? [yes/NO]: \n",
            "How many processes in total will you use? [1]: \n",
            "Do you wish to use FP16 or BF16 (mixed precision)? [NO/fp16/bf16]: fp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate test"
      ],
      "metadata": {
        "id": "J1EszQTy7JTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 下載 orchid219_classification 程式碼\n",
        "--- "
      ],
      "metadata": {
        "id": "NhO8MiJ41HLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://gary109:Gygy844109109@gitlab.com/gary109/orchid219_classification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfPGSNnqqdLE",
        "outputId": "4346bcf5-effc-4882-f366-f3109d2f7e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'orchid219_classification'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 載入 orchid219 訓練資料集\n",
        "---"
      ],
      "metadata": {
        "id": "RcO8DSXZz7W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"./orchid219_classification/datasets/orchid219.py\", use_auth_token=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "21e29e71a14849a590345644bbe77c12",
            "92ca2a9769f64f7d9136941126af9de5",
            "e9836e9361b24fa499d9dbfdf167d62c",
            "e735b6e2d50b4ff0bc9e068ec9f8b281",
            "791a6d92ba8a4184ae7de36623cdce0b",
            "80b448779bc84556897d5fe1f3085a58",
            "9b7c67bb6af14a97bbabab0d3d85b4ba",
            "84ed12e3496347b4a0474eb5272ca6b4",
            "6772501c9cc342e099402c6a54abd2b2",
            "212f4978f88245a58cf5295cf98ebce9",
            "77515809ffcb4a3e93c3bbee6ff00293",
            "65b2bddcc6f54aaaac41ec3f571a1256",
            "78854db8781d4c5d803be185dde1add6",
            "59b10a26b44a41018bca1501e843c67b",
            "b2c6dd13978f433cbcbf80d181b1ab71",
            "09af7a2b26e74cefb6710271618e4afe",
            "52fec1ebe01148dbb021e10f09604b30",
            "a9721625069e47d8ab353789dc0ad271",
            "181175ee577d43adb97ff38ae124b45b",
            "9da2f2471d54430585f79edd12ff8b9d",
            "411c2cb2d273499ea12aa4359f94a0ff",
            "34d6eb1c9bd347969b70d0b44c903005",
            "aa52d499b79342d6b55b1d347f93b377",
            "a68c652fa64e47f496b51d302f993a65",
            "b1f6d853fd1f4599b76e612b20564bd1",
            "85f547c8b558450085ab8d4cf3f7fea6",
            "583cecceec114c61bb852a78fc85ba3f",
            "3acb0a6652904fe18bef56e26b72c1f3",
            "2be77b553bd045bf9889f6a9ca470c0e",
            "dd35a450779d402e9156a90087d40d60",
            "108f9f7e212a4aac8d1956228f492333",
            "c724687aaef04034a48df3e389194a1d",
            "768e988bb8934475850cdf12e31314db",
            "cd522ecafef04c05abdcd3eaf58b99ee",
            "23b4a6b3cddf43eaa572b8119d7f7054",
            "6e3b05e8aa7b436bad215df0f6a61314",
            "100422bb34f446ecb657fffd52a9f2b7",
            "8de92688689145b39b05e2a125cae85f",
            "45a3002bfeb047a8b5f6a0f7670bff5a",
            "5b1a3e5b4ec44a648a52d7642c0a8cee",
            "47255aecde6545b5a1c7dc73f4dd9c8c",
            "8f1d942292864a5b9c9fd153b06c23eb",
            "73ecb91dc75e4fb1a0204d58279b1d56",
            "b11bcb507c384d7f8a43549c5481221c"
          ]
        },
        "outputId": "387bde46-099d-4f9a-cad0-2283e758a115",
        "id": "U_idZeBF2zie"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset crop14/crop14-small to /root/.cache/huggingface/datasets/crop14/crop14-small/0.0.3/84d7648f2ea0b147531986b7c0c46914c93dc9da31daac0a5ec3c57590c4e99a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21e29e71a14849a590345644bbe77c12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65b2bddcc6f54aaaac41ec3f571a1256"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa52d499b79342d6b55b1d347f93b377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset crop14 downloaded and prepared to /root/.cache/huggingface/datasets/crop14/crop14-small/0.0.3/84d7648f2ea0b147531986b7c0c46914c93dc9da31daac0a5ec3c57590c4e99a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd522ecafef04c05abdcd3eaf58b99ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils.dummy_vision_objects import ImageGPTFeatureExtractor\n",
        "import random\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "\n",
        "def show_examples(ds, seed: int = 1234, examples_per_class: int = 3, size=(100, 100)):\n",
        "\n",
        "    w, h = size\n",
        "    labels = ds['train'].features['category'].names\n",
        "    labels = labels[:9]\n",
        "    grid = Image.new('RGB', size=(examples_per_class * w, len(labels) * h))\n",
        "    draw = ImageDraw.Draw(grid)\n",
        "    font = ImageFont.truetype(\"./fonts/LiberationMono-Bold.ttf\", 24)\n",
        "    for label_id, label in enumerate(labels):\n",
        "\n",
        "        # Filter the dataset by a single label, shuffle it, and grab a few samples\n",
        "        ds_slice = ds['train'].filter(lambda ex: ex['category'] == label_id).shuffle(seed).select(range(examples_per_class))\n",
        "\n",
        "        # Plot this label's examples along a row\n",
        "        for i, example in enumerate(ds_slice):\n",
        "            image = example['image']\n",
        "            idx = examples_per_class * label_id + i\n",
        "            box = (idx % examples_per_class * w, idx // examples_per_class * h)\n",
        "            grid.paste(image.resize(size), box=box)\n",
        "            draw.text(box, str(label), (255, 255, 255), font=font)\n",
        "\n",
        "    return grid\n",
        "\n",
        "show_examples(dataset, seed=random.randint(0, 1337), examples_per_class=3)\n",
        "# dataset['train'][0]['image']"
      ],
      "metadata": {
        "id": "7iNPEbNz2zie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"gary109/orchid219\")"
      ],
      "metadata": {
        "id": "1gymd4g12zif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 開始訓練\n",
        "---"
      ],
      "metadata": {
        "id": "GBQ4LLFm2CJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/transformers/examples/pytorch/image-classification\n",
        "!cp /content/drive/MyDrive/datasets/run_image_classification_ViT-MAE.py /content/"
      ],
      "metadata": {
        "id": "7E5Kms3u0Gx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-base-patch16-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "MzvQ9zfD34bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-base-patch16-224-in21k\" \\\n",
        "    --output_dir=\"./orchid219_vit-base-patch16-224-in21k/\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id orchid219_vit-base-patch16-224-in21k \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --per_device_train_batch_size 8 \\\n",
        "    --per_device_eval_batch_size 8 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337 \\\n",
        "    --cache_dir=\"./cache_orchid219_vit-base-patch16-224-in21k\"\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "tNMZWv7q0G02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-base-patch32-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "p9t54nRI4B5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-base-patch32-224-in21k\" \\\n",
        "    --output_dir ./orchid219_vit-base-patch32-224-in21k/ \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id orchid219_vit-base-patch32-224-in21k \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 80 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "XTWxM4p30G3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-large-patch16-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "NNvuAbjI4PWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-large-patch16-224-in21k\" \\\n",
        "    --output_dir \"./orchid219_vit-large-patch16-224-in21k\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id \"orchid219_vit-large-patch16-224-in21k\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "Xo5w2JgH0G6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-large-patch32-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "WJsYvA7u4dLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-large-patch32-224-in21k\" \\\n",
        "    --output_dir \"./orchid219_vit-large-patch32-224-in21k\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id \"orchid219_vit-large-patch32-224-in21k\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 1 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "c13vuvEg4dlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-huge-patch14-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "qaNA2JF34UPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-huge-patch14-224-in21k\" \\\n",
        "    --output_dir \"./orchid219_vit-huge-patch14-224-in21k\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id \"orchid219_vit-huge-patch14-224-in21k\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 5 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 1 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337 \\\n",
        "    --gradient_accumulation_steps 8 \\\n",
        "    --gradient_checkpointing"
      ],
      "metadata": {
        "id": "Gd5cMkQ9kBjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gary109/orchid219_pretrain_vit-mae-large\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Wnmnj8KB9Whn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch run_image_classification_ViT-MAE.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"gary109/orchid219_pretrain_vit-mae-large\" \\\n",
        "    --output_dir=\"./orchid219_vit-mae-large_ft/\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id=\"orchid219_vit-mae-large\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 100 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337 \n",
        "    # --cache_dir=\"./cache_test/\"\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing\n",
        "\n",
        "# --model_name_or_path \"gary109/orchid219_pretrain_vit-base-patch16-224-in21k-mae\" \\\n",
        "    #orchid219_pretrain_vit-base-patch16-224-in21k-mae\n",
        "    # --model_name_or_path \"gary109/orchid219_vit-base-patch16-224-in21k\" "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q26wxpY9aic",
        "outputId": "d373489c-a342-4a2d-aa82-84c9f0fd7dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/./orchid219_vit-mae-large_ft/ is already a clone of https://huggingface.co/gary109/orchid219_vit-mae-large. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "05/03/2022 22:28:33 - WARNING - huggingface_hub.repository - /content/./orchid219_vit-mae-large_ft/ is already a clone of https://huggingface.co/gary109/orchid219_vit-mae-large. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1294] 2022-05-03 22:28:36,560 >> ***** Running training *****\n",
            "[INFO|trainer.py:1295] 2022-05-03 22:28:36,560 >>   Num examples = 1971\n",
            "[INFO|trainer.py:1296] 2022-05-03 22:28:36,560 >>   Num Epochs = 100\n",
            "[INFO|trainer.py:1297] 2022-05-03 22:28:36,560 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1298] 2022-05-03 22:28:36,560 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1299] 2022-05-03 22:28:36,560 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1300] 2022-05-03 22:28:36,560 >>   Total optimization steps = 12400\n",
            "[INFO|integrations.py:577] 2022-05-03 22:28:36,574 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgary109\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220503_222840-2xthn2ny\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./orchid219_vit-mae-large_ft/\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/gary109/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/gary109/huggingface/runs/2xthn2ny\u001b[0m\n",
            "  0% 10/12400 [00:17<5:50:09,  1.70s/it]{'loss': 5.4033, 'learning_rate': 1.9983870967741937e-05, 'epoch': 0.08}\n",
            "{'loss': 5.3866, 'learning_rate': 1.9967741935483872e-05, 'epoch': 0.16}\n",
            "  0% 30/12400 [00:51<6:00:02,  1.75s/it]{'loss': 5.3936, 'learning_rate': 1.9951612903225808e-05, 'epoch': 0.24}\n",
            "  0% 40/12400 [01:09<6:04:19,  1.77s/it]{'loss': 5.3507, 'learning_rate': 1.9935483870967743e-05, 'epoch': 0.32}\n",
            "  0% 50/12400 [01:27<6:09:07,  1.79s/it]{'loss': 5.3242, 'learning_rate': 1.9919354838709678e-05, 'epoch': 0.4}\n",
            "{'loss': 5.2528, 'learning_rate': 1.9903225806451613e-05, 'epoch': 0.48}\n",
            "{'loss': 5.2362, 'learning_rate': 1.9887096774193552e-05, 'epoch': 0.56}\n",
            "  1% 80/12400 [02:22<6:15:18,  1.83s/it]{'loss': 5.2186, 'learning_rate': 1.9870967741935484e-05, 'epoch': 0.65}\n",
            "{'loss': 5.0841, 'learning_rate': 1.9854838709677423e-05, 'epoch': 0.73}\n",
            "{'loss': 5.0699, 'learning_rate': 1.9838709677419358e-05, 'epoch': 0.81}\n",
            "{'loss': 4.9845, 'learning_rate': 1.982258064516129e-05, 'epoch': 0.89}\n",
            "{'loss': 4.8887, 'learning_rate': 1.980645161290323e-05, 'epoch': 0.97}\n",
            "  1% 124/12400 [03:41<4:49:51,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 22:32:25,302 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:32:25,302 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:32:25,302 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.96it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                         \n",
            "  1% 124/12400 [03:50<4:49:51,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A{'eval_loss': 4.798327445983887, 'eval_accuracy': 0.0821917808219178, 'eval_runtime': 9.1144, 'eval_samples_per_second': 24.028, 'eval_steps_per_second': 1.536, 'epoch': 1.0}\n",
            "[INFO|trainer.py:2213] 2022-05-03 22:32:34,418 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-124\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:32:34,420 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-124/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:32:38,051 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-124/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:32:38,052 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-124/preprocessor_config.json\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:32:52,353 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/preprocessor_config.json\n",
            "                                          {'loss': 4.707, 'learning_rate': 1.9790322580645164e-05, 'epoch': 1.05}\n",
            "{'loss': 4.6647, 'learning_rate': 1.97741935483871e-05, 'epoch': 1.13}\n",
            "{'loss': 4.5363, 'learning_rate': 1.9758064516129035e-05, 'epoch': 1.21}\n",
            "  1% 160/12400 [05:25<6:15:57,  1.84s/it]{'loss': 4.4709, 'learning_rate': 1.974193548387097e-05, 'epoch': 1.29}\n",
            "                                         {'loss': 4.4418, 'learning_rate': 1.9725806451612905e-05, 'epoch': 1.37}\n",
            "  1% 180/12400 [06:02<6:15:10,  1.84s/it]{'loss': 4.3611, 'learning_rate': 1.970967741935484e-05, 'epoch': 1.45}\n",
            "  2% 190/12400 [06:20<6:16:58,  1.85s/it]{'loss': 4.3262, 'learning_rate': 1.9693548387096776e-05, 'epoch': 1.53}\n",
            "  2% 200/12400 [06:39<6:39:40,  1.97s/it]{'loss': 4.359, 'learning_rate': 1.967741935483871e-05, 'epoch': 1.61}\n",
            "{'loss': 4.2518, 'learning_rate': 1.9661290322580647e-05, 'epoch': 1.69}\n",
            "  2% 220/12400 [07:16<6:14:09,  1.84s/it]{'loss': 4.1614, 'learning_rate': 1.9645161290322582e-05, 'epoch': 1.77}\n",
            "{'loss': 4.1464, 'learning_rate': 1.9629032258064517e-05, 'epoch': 1.85}\n",
            "                                         {'loss': 4.0478, 'learning_rate': 1.9612903225806452e-05, 'epoch': 1.94}\n",
            "  2% 248/12400 [08:06<4:49:51,  1.43s/it][INFO|trainer.py:2463] 2022-05-03 22:36:50,948 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:36:50,948 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:36:50,948 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.98it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.09it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.81it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.68it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 50% 7/14 [00:04<00:04,  1.56it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.54it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.52it/s]\u001b[A\n",
            " 71% 10/14 [00:06<00:02,  1.51it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.50it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.50it/s]\u001b[A\n",
            " 93% 13/14 [00:08<00:00,  1.50it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 4.032083034515381, 'eval_accuracy': 0.2648401826484018, 'eval_runtime': 9.2613, 'eval_samples_per_second': 23.647, 'eval_steps_per_second': 1.512, 'epoch': 2.0}\n",
            "  2% 248/12400 [08:16<4:49:51,  1.43s/it]\n",
            "100% 14/14 [00:08<00:00,  1.62it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 22:37:00,212 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-248\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:37:00,214 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-248/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:37:04,016 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-248/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:37:04,017 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-248/preprocessor_config.json\n",
            "{'loss': 3.9303, 'learning_rate': 1.9596774193548388e-05, 'epoch': 2.02}\n",
            "{'loss': 3.8921, 'learning_rate': 1.9580645161290323e-05, 'epoch': 2.1}\n",
            "                                         {'loss': 3.6919, 'learning_rate': 1.9564516129032262e-05, 'epoch': 2.18}\n",
            "{'loss': 3.5869, 'learning_rate': 1.9548387096774194e-05, 'epoch': 2.26}\n",
            "  2% 290/12400 [09:47<6:09:32,  1.83s/it]{'loss': 3.5899, 'learning_rate': 1.953225806451613e-05, 'epoch': 2.34}\n",
            "{'loss': 3.5565, 'learning_rate': 1.9516129032258068e-05, 'epoch': 2.42}\n",
            "{'loss': 3.5862, 'learning_rate': 1.95e-05, 'epoch': 2.5}\n",
            "{'loss': 3.5797, 'learning_rate': 1.948387096774194e-05, 'epoch': 2.58}\n",
            "{'loss': 3.4838, 'learning_rate': 1.9467741935483874e-05, 'epoch': 2.66}\n",
            "{'loss': 3.4869, 'learning_rate': 1.9451612903225806e-05, 'epoch': 2.74}\n",
            "  3% 350/12400 [11:38<6:10:50,  1.85s/it]{'loss': 3.3421, 'learning_rate': 1.9435483870967744e-05, 'epoch': 2.82}\n",
            "{'loss': 3.2583, 'learning_rate': 1.941935483870968e-05, 'epoch': 2.9}\n",
            "{'loss': 3.1242, 'learning_rate': 1.9403225806451615e-05, 'epoch': 2.98}\n",
            "  3% 372/12400 [12:17<4:47:35,  1.43s/it][INFO|trainer.py:2463] 2022-05-03 22:41:01,707 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:41:01,707 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:41:01,707 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.95it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.10it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.82it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.69it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 50% 7/14 [00:04<00:04,  1.57it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.54it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.52it/s]\u001b[A\n",
            " 71% 10/14 [00:06<00:02,  1.51it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:02,  1.50it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.48it/s]\u001b[A\n",
            " 93% 13/14 [00:08<00:00,  1.47it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 3.4228811264038086, 'eval_accuracy': 0.3515981735159817, 'eval_runtime': 9.3035, 'eval_samples_per_second': 23.539, 'eval_steps_per_second': 1.505, 'epoch': 3.0}\n",
            "  3% 372/12400 [12:26<4:47:35,  1.43s/it]\n",
            "100% 14/14 [00:08<00:00,  1.60it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 22:41:11,013 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-372\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:41:11,017 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-372/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:41:14,868 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-372/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:41:14,869 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-372/preprocessor_config.json\n",
            "{'loss': 3.1127, 'learning_rate': 1.938709677419355e-05, 'epoch': 3.06}\n",
            "{'loss': 2.895, 'learning_rate': 1.9370967741935486e-05, 'epoch': 3.15}\n",
            "  3% 400/12400 [13:33<6:38:18,  1.99s/it]{'loss': 2.8718, 'learning_rate': 1.935483870967742e-05, 'epoch': 3.23}\n",
            "{'loss': 2.884, 'learning_rate': 1.9338709677419356e-05, 'epoch': 3.31}\n",
            "{'loss': 2.948, 'learning_rate': 1.932258064516129e-05, 'epoch': 3.39}\n",
            "{'loss': 2.8545, 'learning_rate': 1.9306451612903227e-05, 'epoch': 3.47}\n",
            "{'loss': 2.7324, 'learning_rate': 1.9290322580645162e-05, 'epoch': 3.55}\n",
            "  4% 450/12400 [15:05<6:06:57,  1.84s/it]{'loss': 2.8369, 'learning_rate': 1.9274193548387097e-05, 'epoch': 3.63}\n",
            "  4% 460/12400 [15:23<6:04:25,  1.83s/it]{'loss': 2.808, 'learning_rate': 1.9258064516129033e-05, 'epoch': 3.71}\n",
            "{'loss': 2.6163, 'learning_rate': 1.9241935483870968e-05, 'epoch': 3.79}\n",
            "{'loss': 2.6907, 'learning_rate': 1.9225806451612907e-05, 'epoch': 3.87}\n",
            "{'loss': 2.6224, 'learning_rate': 1.920967741935484e-05, 'epoch': 3.95}\n",
            "  4% 496/12400 [16:28<4:44:01,  1.43s/it][INFO|trainer.py:2463] 2022-05-03 22:45:12,837 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:45:12,838 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:45:12,838 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.92it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.08it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.81it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.68it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 50% 7/14 [00:04<00:04,  1.56it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.54it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.52it/s]\u001b[A\n",
            " 71% 10/14 [00:06<00:02,  1.50it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:02,  1.49it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.49it/s]\u001b[A\n",
            " 93% 13/14 [00:08<00:00,  1.48it/s]\u001b[A\n",
            "{'eval_loss': 2.846787214279175, 'eval_accuracy': 0.4703196347031963, 'eval_runtime': 9.3261, 'eval_samples_per_second': 23.482, 'eval_steps_per_second': 1.501, 'epoch': 4.0}\n",
            "\n",
            "  4% 496/12400 [16:38<4:44:01,  1.43s/it]\n",
            "100% 14/14 [00:08<00:00,  1.60it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 22:45:22,166 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-496\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:45:22,170 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-496/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:45:26,086 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-496/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:45:26,087 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-496/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 22:45:35,746 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-124] due to args.save_total_limit\n",
            "{'loss': 2.4691, 'learning_rate': 1.9193548387096777e-05, 'epoch': 4.03}\n",
            "{'loss': 2.3231, 'learning_rate': 1.9177419354838713e-05, 'epoch': 4.11}\n",
            "{'loss': 2.4635, 'learning_rate': 1.9161290322580645e-05, 'epoch': 4.19}\n",
            "{'loss': 2.3535, 'learning_rate': 1.9145161290322583e-05, 'epoch': 4.27}\n",
            "  4% 540/12400 [18:14<6:02:27,  1.83s/it]{'loss': 2.3722, 'learning_rate': 1.912903225806452e-05, 'epoch': 4.35}\n",
            "{'loss': 2.2412, 'learning_rate': 1.9112903225806454e-05, 'epoch': 4.44}\n",
            "{'loss': 2.0637, 'learning_rate': 1.909677419354839e-05, 'epoch': 4.52}\n",
            "  5% 570/12400 [19:09<6:03:57,  1.85s/it]{'loss': 1.9919, 'learning_rate': 1.9080645161290324e-05, 'epoch': 4.6}\n",
            "{'loss': 2.2316, 'learning_rate': 1.906451612903226e-05, 'epoch': 4.68}\n",
            "                                         {'loss': 2.1454, 'learning_rate': 1.9048387096774195e-05, 'epoch': 4.76}\n",
            "{'loss': 2.1278, 'learning_rate': 1.903225806451613e-05, 'epoch': 4.84}\n",
            "  5% 610/12400 [20:23<6:03:23,  1.85s/it]{'loss': 2.0756, 'learning_rate': 1.9016129032258066e-05, 'epoch': 4.92}\n",
            "{'loss': 2.2848, 'learning_rate': 1.9e-05, 'epoch': 5.0}\n",
            "  5% 620/12400 [20:40<4:38:08,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 22:49:24,748 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:49:24,748 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:49:24,748 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.3879482746124268, 'eval_accuracy': 0.5662100456621004, 'eval_runtime': 9.1028, 'eval_samples_per_second': 24.058, 'eval_steps_per_second': 1.538, 'epoch': 5.0}\n",
            "  5% 620/12400 [20:49<4:38:08,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 22:49:33,853 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-620\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:49:33,855 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-620/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:49:37,340 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-620/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:49:37,341 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-620/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 22:49:46,952 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-248] due to args.save_total_limit\n",
            "  5% 630/12400 [21:21<6:47:37,  2.08s/it]{'loss': 1.7906, 'learning_rate': 1.8983870967741936e-05, 'epoch': 5.08}\n",
            "  5% 640/12400 [21:39<6:05:56,  1.87s/it]{'loss': 1.9735, 'learning_rate': 1.896774193548387e-05, 'epoch': 5.16}\n",
            "{'loss': 1.8409, 'learning_rate': 1.895161290322581e-05, 'epoch': 5.24}\n",
            "  5% 660/12400 [22:16<5:54:01,  1.81s/it]{'loss': 1.9365, 'learning_rate': 1.8935483870967742e-05, 'epoch': 5.32}\n",
            "                                         {'loss': 1.7556, 'learning_rate': 1.8919354838709678e-05, 'epoch': 5.4}\n",
            "{'loss': 1.7257, 'learning_rate': 1.8903225806451616e-05, 'epoch': 5.48}\n",
            "{'loss': 1.7369, 'learning_rate': 1.8887096774193548e-05, 'epoch': 5.56}\n",
            "{'loss': 1.7004, 'learning_rate': 1.8870967741935487e-05, 'epoch': 5.65}\n",
            "  6% 710/12400 [23:47<5:54:31,  1.82s/it]{'loss': 1.8117, 'learning_rate': 1.8854838709677422e-05, 'epoch': 5.73}\n",
            "  6% 720/12400 [24:05<5:54:05,  1.82s/it]{'loss': 1.7263, 'learning_rate': 1.8838709677419354e-05, 'epoch': 5.81}\n",
            "{'loss': 1.7467, 'learning_rate': 1.8822580645161293e-05, 'epoch': 5.89}\n",
            "{'loss': 1.717, 'learning_rate': 1.8806451612903228e-05, 'epoch': 5.97}\n",
            "  6% 744/12400 [24:48<4:34:50,  1.41s/it][INFO|trainer.py:2463] 2022-05-03 22:53:32,294 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:53:32,294 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:53:32,294 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                         \n",
            "{'eval_loss': 2.0132148265838623, 'eval_accuracy': 0.6210045662100456, 'eval_runtime': 9.0634, 'eval_samples_per_second': 24.163, 'eval_steps_per_second': 1.545, 'epoch': 6.0}\n",
            "  6% 744/12400 [24:57<4:34:50,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 22:53:41,360 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-744\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:53:41,363 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-744/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:53:44,775 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-744/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:53:44,776 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-744/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 22:53:54,530 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-372] due to args.save_total_limit\n",
            "{'loss': 1.6899, 'learning_rate': 1.8790322580645163e-05, 'epoch': 6.05}\n",
            "{'loss': 1.5434, 'learning_rate': 1.87741935483871e-05, 'epoch': 6.13}\n",
            "{'loss': 1.46, 'learning_rate': 1.8758064516129034e-05, 'epoch': 6.21}\n",
            "{'loss': 1.4758, 'learning_rate': 1.874193548387097e-05, 'epoch': 6.29}\n",
            "{'loss': 1.3918, 'learning_rate': 1.8725806451612905e-05, 'epoch': 6.37}\n",
            "{'loss': 1.4839, 'learning_rate': 1.870967741935484e-05, 'epoch': 6.45}\n",
            "{'loss': 1.4647, 'learning_rate': 1.8693548387096775e-05, 'epoch': 6.53}\n",
            "{'loss': 1.3874, 'learning_rate': 1.867741935483871e-05, 'epoch': 6.61}\n",
            "{'loss': 1.2912, 'learning_rate': 1.8661290322580646e-05, 'epoch': 6.69}\n",
            "  7% 840/12400 [28:06<5:50:29,  1.82s/it]{'loss': 1.3074, 'learning_rate': 1.864516129032258e-05, 'epoch': 6.77}\n",
            "{'loss': 1.414, 'learning_rate': 1.8629032258064517e-05, 'epoch': 6.85}\n",
            "{'loss': 1.4214, 'learning_rate': 1.8612903225806452e-05, 'epoch': 6.94}\n",
            "  7% 868/12400 [28:55<4:32:05,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 22:57:39,944 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 22:57:39,944 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 22:57:39,944 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                         \n",
            "{'eval_loss': 1.7563623189926147, 'eval_accuracy': 0.6712328767123288, 'eval_runtime': 9.1098, 'eval_samples_per_second': 24.04, 'eval_steps_per_second': 1.537, 'epoch': 7.0}\n",
            "  7% 868/12400 [29:04<4:32:05,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 22:57:49,056 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-868\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 22:57:49,059 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-868/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 22:57:52,468 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-868/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 22:57:52,469 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-868/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 22:58:02,190 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-496] due to args.save_total_limit\n",
            "  7% 870/12400 [29:21<20:12:31,  6.31s/it]{'loss': 1.3238, 'learning_rate': 1.8596774193548387e-05, 'epoch': 7.02}\n",
            "{'loss': 1.1885, 'learning_rate': 1.8580645161290326e-05, 'epoch': 7.1}\n",
            "{'loss': 1.1991, 'learning_rate': 1.856451612903226e-05, 'epoch': 7.18}\n",
            "  7% 900/12400 [30:17<6:11:39,  1.94s/it]{'loss': 1.1053, 'learning_rate': 1.8548387096774193e-05, 'epoch': 7.26}\n",
            "  7% 910/12400 [30:35<5:47:00,  1.81s/it]{'loss': 1.0611, 'learning_rate': 1.8532258064516132e-05, 'epoch': 7.34}\n",
            "  7% 920/12400 [30:53<5:48:10,  1.82s/it]{'loss': 1.2038, 'learning_rate': 1.8516129032258067e-05, 'epoch': 7.42}\n",
            "  8% 930/12400 [31:11<5:48:21,  1.82s/it]{'loss': 1.2397, 'learning_rate': 1.8500000000000002e-05, 'epoch': 7.5}\n",
            "  8% 940/12400 [31:30<5:48:20,  1.82s/it]{'loss': 1.0918, 'learning_rate': 1.8483870967741938e-05, 'epoch': 7.58}\n",
            "  8% 950/12400 [31:48<5:47:01,  1.82s/it]{'loss': 1.1943, 'learning_rate': 1.8467741935483873e-05, 'epoch': 7.66}\n",
            "{'loss': 1.1095, 'learning_rate': 1.845161290322581e-05, 'epoch': 7.74}\n",
            "  8% 970/12400 [32:24<5:45:57,  1.82s/it]{'loss': 1.1311, 'learning_rate': 1.8435483870967744e-05, 'epoch': 7.82}\n",
            "{'loss': 1.0222, 'learning_rate': 1.841935483870968e-05, 'epoch': 7.9}\n",
            "  8% 990/12400 [33:01<5:46:38,  1.82s/it]{'loss': 1.0932, 'learning_rate': 1.8403225806451614e-05, 'epoch': 7.98}\n",
            "  8% 992/12400 [33:03<4:30:09,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:01:47,561 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:01:47,561 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:01:47,562 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                         \n",
            "  8% 992/12400 [33:12<4:30:09,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   {'eval_loss': 1.4958688020706177, 'eval_accuracy': 0.7214611872146118, 'eval_runtime': 9.0885, 'eval_samples_per_second': 24.096, 'eval_steps_per_second': 1.54, 'epoch': 8.0}\n",
            "\u001b[A[INFO|trainer.py:2213] 2022-05-03 23:01:56,652 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-992\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:01:56,655 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-992/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:02:00,113 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-992/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:02:00,114 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-992/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:02:09,744 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-620] due to args.save_total_limit\n",
            "  8% 1000/12400 [33:40<7:46:52,  2.46s/it]{'loss': 1.051, 'learning_rate': 1.838709677419355e-05, 'epoch': 8.06}\n",
            "{'loss': 0.9952, 'learning_rate': 1.8370967741935485e-05, 'epoch': 8.15}\n",
            "{'loss': 1.1303, 'learning_rate': 1.835483870967742e-05, 'epoch': 8.23}\n",
            "  8% 1030/12400 [34:35<5:43:07,  1.81s/it]{'loss': 0.9744, 'learning_rate': 1.833870967741936e-05, 'epoch': 8.31}\n",
            "{'loss': 0.9535, 'learning_rate': 1.832258064516129e-05, 'epoch': 8.39}\n",
            "  8% 1050/12400 [35:11<5:44:40,  1.82s/it]{'loss': 0.9424, 'learning_rate': 1.8306451612903226e-05, 'epoch': 8.47}\n",
            "  9% 1060/12400 [35:30<5:44:58,  1.83s/it]{'loss': 0.8909, 'learning_rate': 1.8290322580645165e-05, 'epoch': 8.55}\n",
            "  9% 1070/12400 [35:48<5:44:00,  1.82s/it]{'loss': 0.9478, 'learning_rate': 1.8274193548387097e-05, 'epoch': 8.63}\n",
            "  9% 1080/12400 [36:06<5:41:57,  1.81s/it]{'loss': 0.9089, 'learning_rate': 1.8258064516129035e-05, 'epoch': 8.71}\n",
            "{'loss': 0.8211, 'learning_rate': 1.824193548387097e-05, 'epoch': 8.79}\n",
            "{'loss': 0.8976, 'learning_rate': 1.8225806451612903e-05, 'epoch': 8.87}\n",
            "{'loss': 0.9892, 'learning_rate': 1.820967741935484e-05, 'epoch': 8.95}\n",
            "  9% 1116/12400 [37:11<4:26:18,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:05:55,494 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:05:55,494 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:05:55,495 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 1.3081014156341553, 'eval_accuracy': 0.7671232876712328, 'eval_runtime': 9.0894, 'eval_samples_per_second': 24.094, 'eval_steps_per_second': 1.54, 'epoch': 9.0}\n",
            "  9% 1116/12400 [37:20<4:26:18,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:06:04,586 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1116\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:06:04,588 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1116/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:06:08,044 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1116/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:06:08,045 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1116/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:06:17,783 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-744] due to args.save_total_limit\n",
            "{'loss': 0.7896, 'learning_rate': 1.8193548387096777e-05, 'epoch': 9.03}\n",
            "  9% 1130/12400 [37:59<5:57:26,  1.90s/it]{'loss': 0.7546, 'learning_rate': 1.817741935483871e-05, 'epoch': 9.11}\n",
            "{'loss': 0.8178, 'learning_rate': 1.8161290322580647e-05, 'epoch': 9.19}\n",
            "{'loss': 0.9178, 'learning_rate': 1.8145161290322583e-05, 'epoch': 9.27}\n",
            "{'loss': 0.804, 'learning_rate': 1.8129032258064518e-05, 'epoch': 9.35}\n",
            "{'loss': 0.8, 'learning_rate': 1.8112903225806453e-05, 'epoch': 9.44}\n",
            " 10% 1180/12400 [39:30<5:41:27,  1.83s/it]{'loss': 0.7142, 'learning_rate': 1.809677419354839e-05, 'epoch': 9.52}\n",
            "{'loss': 0.7214, 'learning_rate': 1.8080645161290324e-05, 'epoch': 9.6}\n",
            "{'loss': 0.7469, 'learning_rate': 1.806451612903226e-05, 'epoch': 9.68}\n",
            "{'loss': 0.7426, 'learning_rate': 1.8048387096774195e-05, 'epoch': 9.76}\n",
            "{'loss': 0.7364, 'learning_rate': 1.803225806451613e-05, 'epoch': 9.84}\n",
            " 10% 1230/12400 [41:02<5:39:01,  1.82s/it]{'loss': 0.7406, 'learning_rate': 1.8016129032258065e-05, 'epoch': 9.92}\n",
            "{'loss': 0.6826, 'learning_rate': 1.8e-05, 'epoch': 10.0}\n",
            " 10% 1240/12400 [41:19<4:23:01,  1.41s/it][INFO|trainer.py:2463] 2022-05-03 23:10:03,438 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:10:03,438 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:10:03,438 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 1.171581506729126, 'eval_accuracy': 0.7397260273972602, 'eval_runtime': 9.0949, 'eval_samples_per_second': 24.079, 'eval_steps_per_second': 1.539, 'epoch': 10.0}\n",
            " 10% 1240/12400 [41:28<4:23:01,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:10:12,535 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1240\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:10:12,537 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1240/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:10:16,003 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1240/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:10:16,004 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1240/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:10:25,621 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-868] due to args.save_total_limit\n",
            "{'loss': 0.5991, 'learning_rate': 1.7983870967741936e-05, 'epoch': 10.08}\n",
            " 10% 1260/12400 [42:18<5:46:53,  1.87s/it]{'loss': 0.604, 'learning_rate': 1.7967741935483874e-05, 'epoch': 10.16}\n",
            " 10% 1270/12400 [42:36<5:38:41,  1.83s/it]{'loss': 0.6805, 'learning_rate': 1.7951612903225806e-05, 'epoch': 10.24}\n",
            " 10% 1280/12400 [42:54<5:35:28,  1.81s/it]{'loss': 0.5844, 'learning_rate': 1.7935483870967742e-05, 'epoch': 10.32}\n",
            "                                          {'loss': 0.6187, 'learning_rate': 1.791935483870968e-05, 'epoch': 10.4}\n",
            " 10% 1300/12400 [43:31<5:59:15,  1.94s/it]{'loss': 0.6754, 'learning_rate': 1.7903225806451612e-05, 'epoch': 10.48}\n",
            "{'loss': 0.6353, 'learning_rate': 1.788709677419355e-05, 'epoch': 10.56}\n",
            "{'loss': 0.5813, 'learning_rate': 1.7870967741935486e-05, 'epoch': 10.65}\n",
            "{'loss': 0.4748, 'learning_rate': 1.785483870967742e-05, 'epoch': 10.73}\n",
            "{'loss': 0.7311, 'learning_rate': 1.7838709677419357e-05, 'epoch': 10.81}\n",
            "{'loss': 0.6509, 'learning_rate': 1.7822580645161292e-05, 'epoch': 10.89}\n",
            "{'loss': 0.6162, 'learning_rate': 1.7806451612903228e-05, 'epoch': 10.97}\n",
            " 11% 1364/12400 [45:26<4:20:37,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:14:11,046 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:14:11,046 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:14:11,046 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                          \n",
            " 11% 1364/12400 [45:35<4:20:37,  1.42s/it]\n",
            "{'eval_loss': 1.006087064743042, 'eval_accuracy': 0.8036529680365296, 'eval_runtime': 9.0916, 'eval_samples_per_second': 24.088, 'eval_steps_per_second': 1.54, 'epoch': 11.0}\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:14:20,139 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1364\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:14:20,141 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1364/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:14:23,528 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1364/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:14:23,530 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1364/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:14:33,284 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-992] due to args.save_total_limit\n",
            "{'loss': 0.5289, 'learning_rate': 1.7790322580645163e-05, 'epoch': 11.05}\n",
            "{'loss': 0.4985, 'learning_rate': 1.7774193548387098e-05, 'epoch': 11.13}\n",
            " 11% 1390/12400 [46:36<5:38:11,  1.84s/it]{'loss': 0.4717, 'learning_rate': 1.7758064516129034e-05, 'epoch': 11.21}\n",
            " 11% 1400/12400 [46:55<5:53:47,  1.93s/it]{'loss': 0.6116, 'learning_rate': 1.774193548387097e-05, 'epoch': 11.29}\n",
            " 11% 1410/12400 [47:13<5:32:23,  1.81s/it]{'loss': 0.545, 'learning_rate': 1.7725806451612904e-05, 'epoch': 11.37}\n",
            " 11% 1420/12400 [47:31<5:33:01,  1.82s/it]{'loss': 0.51, 'learning_rate': 1.770967741935484e-05, 'epoch': 11.45}\n",
            "{'loss': 0.5088, 'learning_rate': 1.7693548387096775e-05, 'epoch': 11.53}\n",
            " 12% 1440/12400 [48:08<5:32:04,  1.82s/it]{'loss': 0.4659, 'learning_rate': 1.7677419354838713e-05, 'epoch': 11.61}\n",
            " 12% 1450/12400 [48:26<5:31:21,  1.82s/it]{'loss': 0.5179, 'learning_rate': 1.7661290322580645e-05, 'epoch': 11.69}\n",
            "{'loss': 0.5576, 'learning_rate': 1.764516129032258e-05, 'epoch': 11.77}\n",
            "{'loss': 0.4922, 'learning_rate': 1.762903225806452e-05, 'epoch': 11.85}\n",
            "                                          {'loss': 0.515, 'learning_rate': 1.761290322580645e-05, 'epoch': 11.94}\n",
            " 12% 1488/12400 [49:34<4:17:29,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:18:18,531 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:18:18,531 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:18:18,532 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.95it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.9591519832611084, 'eval_accuracy': 0.776255707762557, 'eval_runtime': 9.1272, 'eval_samples_per_second': 23.994, 'eval_steps_per_second': 1.534, 'epoch': 12.0}\n",
            " 12% 1488/12400 [49:43<4:17:29,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:18:27,661 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1488\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:18:27,662 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1488/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:18:31,115 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1488/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:18:31,116 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1488/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:18:41,036 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1116] due to args.save_total_limit\n",
            "{'loss': 0.5251, 'learning_rate': 1.759677419354839e-05, 'epoch': 12.02}\n",
            " 12% 1500/12400 [50:19<6:16:38,  2.07s/it]{'loss': 0.4514, 'learning_rate': 1.7580645161290325e-05, 'epoch': 12.1}\n",
            " 12% 1510/12400 [50:37<5:38:01,  1.86s/it]{'loss': 0.4502, 'learning_rate': 1.7564516129032257e-05, 'epoch': 12.18}\n",
            "{'loss': 0.3635, 'learning_rate': 1.7548387096774196e-05, 'epoch': 12.26}\n",
            "{'loss': 0.505, 'learning_rate': 1.753225806451613e-05, 'epoch': 12.34}\n",
            "{'loss': 0.4877, 'learning_rate': 1.7516129032258067e-05, 'epoch': 12.42}\n",
            "{'loss': 0.4724, 'learning_rate': 1.7500000000000002e-05, 'epoch': 12.5}\n",
            "{'loss': 0.5321, 'learning_rate': 1.7483870967741937e-05, 'epoch': 12.58}\n",
            "{'loss': 0.365, 'learning_rate': 1.7467741935483872e-05, 'epoch': 12.66}\n",
            "{'loss': 0.3628, 'learning_rate': 1.7451612903225808e-05, 'epoch': 12.74}\n",
            "{'loss': 0.437, 'learning_rate': 1.7435483870967743e-05, 'epoch': 12.82}\n",
            " 13% 1600/12400 [53:22<5:49:22,  1.94s/it]{'loss': 0.4884, 'learning_rate': 1.741935483870968e-05, 'epoch': 12.9}\n",
            "{'loss': 0.5316, 'learning_rate': 1.7403225806451614e-05, 'epoch': 12.98}\n",
            " 13% 1612/12400 [53:42<4:16:01,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:22:26,876 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:22:26,876 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:22:26,876 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:04<00:04,  1.58it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.55it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.54it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.51it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.51it/s]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.9025814533233643, 'eval_accuracy': 0.7899543378995434, 'eval_runtime': 9.1811, 'eval_samples_per_second': 23.853, 'eval_steps_per_second': 1.525, 'epoch': 13.0}\n",
            " 13% 1612/12400 [53:51<4:16:01,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.62it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:22:36,059 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1612\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:22:36,061 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1612/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:22:39,758 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1612/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:22:39,759 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1612/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:22:49,119 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1240] due to args.save_total_limit\n",
            " 13% 1620/12400 [54:21<7:08:27,  2.38s/it]{'loss': 0.4908, 'learning_rate': 1.738709677419355e-05, 'epoch': 13.06}\n",
            "{'loss': 0.4808, 'learning_rate': 1.7370967741935484e-05, 'epoch': 13.15}\n",
            "{'loss': 0.422, 'learning_rate': 1.7354838709677423e-05, 'epoch': 13.23}\n",
            " 13% 1650/12400 [55:16<5:24:55,  1.81s/it]{'loss': 0.4564, 'learning_rate': 1.7338709677419355e-05, 'epoch': 13.31}\n",
            "{'loss': 0.3602, 'learning_rate': 1.732258064516129e-05, 'epoch': 13.39}\n",
            "{'loss': 0.3756, 'learning_rate': 1.730645161290323e-05, 'epoch': 13.47}\n",
            " 14% 1680/12400 [56:10<5:25:29,  1.82s/it]{'loss': 0.393, 'learning_rate': 1.729032258064516e-05, 'epoch': 13.55}\n",
            "{'loss': 0.4887, 'learning_rate': 1.72741935483871e-05, 'epoch': 13.63}\n",
            "{'loss': 0.4085, 'learning_rate': 1.7258064516129035e-05, 'epoch': 13.71}\n",
            "{'loss': 0.3917, 'learning_rate': 1.7241935483870967e-05, 'epoch': 13.79}\n",
            "                                          {'loss': 0.398, 'learning_rate': 1.7225806451612906e-05, 'epoch': 13.87}\n",
            " 14% 1730/12400 [57:42<5:23:45,  1.82s/it]{'loss': 0.3662, 'learning_rate': 1.720967741935484e-05, 'epoch': 13.95}\n",
            " 14% 1736/12400 [57:52<4:11:38,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:26:36,238 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:26:36,238 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:26:36,238 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.797383189201355, 'eval_accuracy': 0.821917808219178, 'eval_runtime': 9.1476, 'eval_samples_per_second': 23.941, 'eval_steps_per_second': 1.53, 'epoch': 14.0}\n",
            " 14% 1736/12400 [58:01<4:11:38,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:26:45,388 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1736\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:26:45,391 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1736/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:26:49,214 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1736/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:26:49,215 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1736/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:26:58,604 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1364] due to args.save_total_limit\n",
            " 14% 1740/12400 [58:21<11:55:46,  4.03s/it]{'loss': 0.3659, 'learning_rate': 1.7193548387096776e-05, 'epoch': 14.03}\n",
            "{'loss': 0.4255, 'learning_rate': 1.717741935483871e-05, 'epoch': 14.11}\n",
            " 14% 1760/12400 [58:58<5:28:50,  1.85s/it]{'loss': 0.4225, 'learning_rate': 1.7161290322580647e-05, 'epoch': 14.19}\n",
            "{'loss': 0.3723, 'learning_rate': 1.7145161290322582e-05, 'epoch': 14.27}\n",
            "{'loss': 0.485, 'learning_rate': 1.7129032258064517e-05, 'epoch': 14.35}\n",
            "{'loss': 0.3071, 'learning_rate': 1.7112903225806453e-05, 'epoch': 14.44}\n",
            " 15% 1800/12400 [1:00:11<5:43:00,  1.94s/it]{'loss': 0.2876, 'learning_rate': 1.7096774193548388e-05, 'epoch': 14.52}\n",
            "{'loss': 0.4877, 'learning_rate': 1.7080645161290323e-05, 'epoch': 14.6}\n",
            "{'loss': 0.318, 'learning_rate': 1.706451612903226e-05, 'epoch': 14.68}\n",
            "{'loss': 0.3063, 'learning_rate': 1.7048387096774194e-05, 'epoch': 14.76}\n",
            " 15% 1840/12400 [1:01:24<5:20:38,  1.82s/it]{'loss': 0.3158, 'learning_rate': 1.703225806451613e-05, 'epoch': 14.84}\n",
            " 15% 1850/12400 [1:01:42<5:19:53,  1.82s/it]{'loss': 0.4197, 'learning_rate': 1.7016129032258068e-05, 'epoch': 14.92}\n",
            " 15% 1860/12400 [1:01:59<4:08:11,  1.41s/it]{'loss': 0.3577, 'learning_rate': 1.7e-05, 'epoch': 15.0}\n",
            " 15% 1860/12400 [1:01:59<4:08:11,  1.41s/it][INFO|trainer.py:2463] 2022-05-03 23:30:44,030 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:30:44,030 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:30:44,030 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.7851054072380066, 'eval_accuracy': 0.8127853881278538, 'eval_runtime': 9.0981, 'eval_samples_per_second': 24.071, 'eval_steps_per_second': 1.539, 'epoch': 15.0}\n",
            " 15% 1860/12400 [1:02:08<4:08:11,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:30:53,130 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1860\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:30:53,132 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1860/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:30:56,820 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1860/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:30:56,821 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1860/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:31:06,598 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1488] due to args.save_total_limit\n",
            "{'loss': 0.281, 'learning_rate': 1.698387096774194e-05, 'epoch': 15.08}\n",
            "{'loss': 0.255, 'learning_rate': 1.6967741935483874e-05, 'epoch': 15.16}\n",
            "{'loss': 0.3923, 'learning_rate': 1.6951612903225806e-05, 'epoch': 15.24}\n",
            " 15% 1900/12400 [1:03:36<5:36:43,  1.92s/it]{'loss': 0.3015, 'learning_rate': 1.6935483870967744e-05, 'epoch': 15.32}\n",
            "{'loss': 0.2788, 'learning_rate': 1.691935483870968e-05, 'epoch': 15.4}\n",
            "{'loss': 0.3174, 'learning_rate': 1.6903225806451615e-05, 'epoch': 15.48}\n",
            "{'loss': 0.359, 'learning_rate': 1.688709677419355e-05, 'epoch': 15.56}\n",
            " 16% 1940/12400 [1:04:48<5:16:29,  1.82s/it]{'loss': 0.2394, 'learning_rate': 1.6870967741935486e-05, 'epoch': 15.65}\n",
            "{'loss': 0.2972, 'learning_rate': 1.685483870967742e-05, 'epoch': 15.73}\n",
            "{'loss': 0.2662, 'learning_rate': 1.6838709677419356e-05, 'epoch': 15.81}\n",
            " 16% 1970/12400 [1:05:43<5:16:49,  1.82s/it]{'loss': 0.3322, 'learning_rate': 1.682258064516129e-05, 'epoch': 15.89}\n",
            "{'loss': 0.3423, 'learning_rate': 1.6806451612903227e-05, 'epoch': 15.97}\n",
            " 16% 1984/12400 [1:06:07<4:04:47,  1.41s/it][INFO|trainer.py:2463] 2022-05-03 23:34:51,839 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:34:51,839 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:34:51,839 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.06it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 16% 1984/12400 [1:06:16<4:04:47,  1.41s/it]\n",
            "{'eval_loss': 0.8039847612380981, 'eval_accuracy': 0.7990867579908676, 'eval_runtime': 9.0836, 'eval_samples_per_second': 24.109, 'eval_steps_per_second': 1.541, 'epoch': 16.0}\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:35:00,925 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-1984\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:35:00,928 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-1984/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:35:04,604 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-1984/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:35:04,605 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-1984/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:35:14,096 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1612] due to args.save_total_limit\n",
            " 16% 1990/12400 [1:06:40<8:21:00,  2.89s/it]{'loss': 0.3614, 'learning_rate': 1.6790322580645162e-05, 'epoch': 16.05}\n",
            " 16% 2000/12400 [1:06:59<5:44:13,  1.99s/it]{'loss': 0.2465, 'learning_rate': 1.6774193548387098e-05, 'epoch': 16.13}\n",
            "                                            {'loss': 0.3709, 'learning_rate': 1.6758064516129033e-05, 'epoch': 16.21}\n",
            "{'loss': 0.3363, 'learning_rate': 1.6741935483870968e-05, 'epoch': 16.29}\n",
            " 16% 2030/12400 [1:07:54<5:12:24,  1.81s/it]{'loss': 0.3564, 'learning_rate': 1.6725806451612904e-05, 'epoch': 16.37}\n",
            "                                            {'loss': 0.2386, 'learning_rate': 1.670967741935484e-05, 'epoch': 16.45}\n",
            "                                            {'loss': 0.242, 'learning_rate': 1.6693548387096778e-05, 'epoch': 16.53}\n",
            "{'loss': 0.2757, 'learning_rate': 1.667741935483871e-05, 'epoch': 16.61}\n",
            " 17% 2070/12400 [1:09:07<5:12:48,  1.82s/it]{'loss': 0.2806, 'learning_rate': 1.6661290322580645e-05, 'epoch': 16.69}\n",
            " 17% 2080/12400 [1:09:25<5:13:05,  1.82s/it]{'loss': 0.294, 'learning_rate': 1.6645161290322583e-05, 'epoch': 16.77}\n",
            " 17% 2090/12400 [1:09:43<5:12:35,  1.82s/it]{'loss': 0.2932, 'learning_rate': 1.6629032258064515e-05, 'epoch': 16.85}\n",
            " 17% 2100/12400 [1:10:02<5:32:50,  1.94s/it]{'loss': 0.2209, 'learning_rate': 1.6612903225806454e-05, 'epoch': 16.94}\n",
            " 17% 2108/12400 [1:10:15<4:03:36,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:38:59,723 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:38:59,723 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:38:59,724 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.7779738903045654, 'eval_accuracy': 0.7990867579908676, 'eval_runtime': 9.0634, 'eval_samples_per_second': 24.163, 'eval_steps_per_second': 1.545, 'epoch': 17.0}\n",
            " 17% 2108/12400 [1:10:24<4:03:36,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:39:08,789 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2108\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:39:08,791 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2108/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:39:12,695 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2108/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:39:12,696 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2108/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:39:21,795 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1736] due to args.save_total_limit\n",
            "{'loss': 0.2526, 'learning_rate': 1.659677419354839e-05, 'epoch': 17.02}\n",
            " 17% 2120/12400 [1:10:59<5:34:45,  1.95s/it]{'loss': 0.2726, 'learning_rate': 1.658064516129032e-05, 'epoch': 17.1}\n",
            " 17% 2130/12400 [1:11:18<5:18:54,  1.86s/it]{'loss': 0.2298, 'learning_rate': 1.656451612903226e-05, 'epoch': 17.18}\n",
            "{'loss': 0.3193, 'learning_rate': 1.6548387096774195e-05, 'epoch': 17.26}\n",
            " 17% 2150/12400 [1:11:54<5:09:20,  1.81s/it]{'loss': 0.3482, 'learning_rate': 1.653225806451613e-05, 'epoch': 17.34}\n",
            "{'loss': 0.2795, 'learning_rate': 1.6516129032258066e-05, 'epoch': 17.42}\n",
            "{'loss': 0.2245, 'learning_rate': 1.65e-05, 'epoch': 17.5}\n",
            "{'loss': 0.2694, 'learning_rate': 1.6483870967741937e-05, 'epoch': 17.58}\n",
            "{'loss': 0.2189, 'learning_rate': 1.6467741935483872e-05, 'epoch': 17.66}\n",
            "{'loss': 0.322, 'learning_rate': 1.6451612903225807e-05, 'epoch': 17.74}\n",
            "{'loss': 0.2643, 'learning_rate': 1.6435483870967743e-05, 'epoch': 17.82}\n",
            "{'loss': 0.2804, 'learning_rate': 1.6419354838709678e-05, 'epoch': 17.9}\n",
            "{'loss': 0.2698, 'learning_rate': 1.6403225806451613e-05, 'epoch': 17.98}\n",
            " 18% 2232/12400 [1:14:23<4:00:56,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:43:07,272 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:43:07,272 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:43:07,272 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 18% 2232/12400 [1:14:32<4:00:56,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A{'eval_loss': 0.8075841665267944, 'eval_accuracy': 0.7808219178082192, 'eval_runtime': 9.1044, 'eval_samples_per_second': 24.054, 'eval_steps_per_second': 1.538, 'epoch': 18.0}\n",
            "[INFO|trainer.py:2213] 2022-05-03 23:43:16,379 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2232\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:43:16,382 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2232/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:43:19,840 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2232/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:43:19,841 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2232/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:43:29,527 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1860] due to args.save_total_limit\n",
            " 18% 2240/12400 [1:14:59<6:37:30,  2.35s/it]{'loss': 0.1875, 'learning_rate': 1.638709677419355e-05, 'epoch': 18.06}\n",
            " 18% 2250/12400 [1:15:18<5:16:21,  1.87s/it]{'loss': 0.1971, 'learning_rate': 1.6370967741935487e-05, 'epoch': 18.15}\n",
            "{'loss': 0.2204, 'learning_rate': 1.6354838709677422e-05, 'epoch': 18.23}\n",
            "{'loss': 0.2515, 'learning_rate': 1.6338709677419354e-05, 'epoch': 18.31}\n",
            " 18% 2280/12400 [1:16:13<5:05:59,  1.81s/it]{'loss': 0.2365, 'learning_rate': 1.6322580645161293e-05, 'epoch': 18.39}\n",
            " 18% 2290/12400 [1:16:31<5:06:47,  1.82s/it]{'loss': 0.2648, 'learning_rate': 1.630645161290323e-05, 'epoch': 18.47}\n",
            " 19% 2300/12400 [1:16:50<5:26:00,  1.94s/it]{'loss': 0.3256, 'learning_rate': 1.6290322580645164e-05, 'epoch': 18.55}\n",
            " 19% 2310/12400 [1:17:08<5:06:38,  1.82s/it]{'loss': 0.2718, 'learning_rate': 1.62741935483871e-05, 'epoch': 18.63}\n",
            "{'loss': 0.2439, 'learning_rate': 1.6258064516129034e-05, 'epoch': 18.71}\n",
            " 19% 2330/12400 [1:17:44<5:05:49,  1.82s/it]{'loss': 0.2333, 'learning_rate': 1.624193548387097e-05, 'epoch': 18.79}\n",
            " 19% 2340/12400 [1:18:02<5:05:38,  1.82s/it]{'loss': 0.4115, 'learning_rate': 1.6225806451612905e-05, 'epoch': 18.87}\n",
            "{'loss': 0.3426, 'learning_rate': 1.620967741935484e-05, 'epoch': 18.95}\n",
            " 19% 2356/12400 [1:18:30<3:57:18,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:47:14,877 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:47:14,877 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:47:14,877 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6864480376243591, 'eval_accuracy': 0.8127853881278538, 'eval_runtime': 9.1019, 'eval_samples_per_second': 24.061, 'eval_steps_per_second': 1.538, 'epoch': 19.0}\n",
            " 19% 2356/12400 [1:18:39<3:57:18,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:47:23,981 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2356\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:47:23,983 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2356/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:47:27,438 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2356/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:47:27,439 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2356/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:47:37,133 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-1984] due to args.save_total_limit\n",
            "{'loss': 0.2067, 'learning_rate': 1.6193548387096776e-05, 'epoch': 19.03}\n",
            " 19% 2370/12400 [1:19:18<5:17:35,  1.90s/it]{'loss': 0.263, 'learning_rate': 1.617741935483871e-05, 'epoch': 19.11}\n",
            "{'loss': 0.2567, 'learning_rate': 1.6161290322580646e-05, 'epoch': 19.19}\n",
            " 19% 2390/12400 [1:19:55<5:03:02,  1.82s/it]{'loss': 0.2488, 'learning_rate': 1.614516129032258e-05, 'epoch': 19.27}\n",
            " 19% 2400/12400 [1:20:14<5:20:55,  1.93s/it]{'loss': 0.291, 'learning_rate': 1.6129032258064517e-05, 'epoch': 19.35}\n",
            " 19% 2410/12400 [1:20:32<5:03:21,  1.82s/it]{'loss': 0.2245, 'learning_rate': 1.6112903225806452e-05, 'epoch': 19.44}\n",
            " 20% 2420/12400 [1:20:50<5:03:30,  1.82s/it]{'loss': 0.2031, 'learning_rate': 1.6096774193548387e-05, 'epoch': 19.52}\n",
            "{'loss': 0.2166, 'learning_rate': 1.6080645161290326e-05, 'epoch': 19.6}\n",
            " 20% 2440/12400 [1:21:26<5:02:20,  1.82s/it]{'loss': 0.2065, 'learning_rate': 1.6064516129032258e-05, 'epoch': 19.68}\n",
            " 20% 2450/12400 [1:21:45<5:01:43,  1.82s/it]{'loss': 0.137, 'learning_rate': 1.6048387096774193e-05, 'epoch': 19.76}\n",
            " 20% 2460/12400 [1:22:03<5:01:56,  1.82s/it]{'loss': 0.2402, 'learning_rate': 1.6032258064516132e-05, 'epoch': 19.84}\n",
            " 20% 2470/12400 [1:22:21<5:01:37,  1.82s/it]{'loss': 0.2191, 'learning_rate': 1.6016129032258064e-05, 'epoch': 19.92}\n",
            " 20% 2480/12400 [1:22:38<3:53:59,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:51:22,669 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:51:22,669 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:51:22,669 >>   Batch size = 16\n",
            "{'loss': 0.1338, 'learning_rate': 1.6000000000000003e-05, 'epoch': 20.0}\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 20% 2480/12400 [1:22:47<3:53:59,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A{'eval_loss': 0.6719928979873657, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.1182, 'eval_samples_per_second': 24.018, 'eval_steps_per_second': 1.535, 'epoch': 20.0}\n",
            "\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:51:31,790 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2480\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:51:31,793 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2480/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:51:35,358 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2480/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:51:35,359 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2480/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:51:44,798 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2108] due to args.save_total_limit\n",
            " 20% 2490/12400 [1:23:18<5:43:20,  2.08s/it]{'loss': 0.1491, 'learning_rate': 1.5983870967741938e-05, 'epoch': 20.08}\n",
            " 20% 2500/12400 [1:23:37<5:27:00,  1.98s/it]{'loss': 0.2305, 'learning_rate': 1.596774193548387e-05, 'epoch': 20.16}\n",
            "{'loss': 0.2212, 'learning_rate': 1.595161290322581e-05, 'epoch': 20.24}\n",
            " 20% 2520/12400 [1:24:14<4:58:28,  1.81s/it]{'loss': 0.1206, 'learning_rate': 1.5935483870967744e-05, 'epoch': 20.32}\n",
            "{'loss': 0.235, 'learning_rate': 1.591935483870968e-05, 'epoch': 20.4}\n",
            " 20% 2540/12400 [1:24:50<5:01:04,  1.83s/it]{'loss': 0.1957, 'learning_rate': 1.5903225806451615e-05, 'epoch': 20.48}\n",
            " 21% 2550/12400 [1:25:09<4:59:23,  1.82s/it]{'loss': 0.1832, 'learning_rate': 1.588709677419355e-05, 'epoch': 20.56}\n",
            "{'loss': 0.1512, 'learning_rate': 1.5870967741935485e-05, 'epoch': 20.65}\n",
            " 21% 2570/12400 [1:25:45<4:57:16,  1.81s/it]{'loss': 0.2214, 'learning_rate': 1.585483870967742e-05, 'epoch': 20.73}\n",
            " 21% 2580/12400 [1:26:03<4:58:06,  1.82s/it]{'loss': 0.2445, 'learning_rate': 1.5838709677419356e-05, 'epoch': 20.81}\n",
            " 21% 2590/12400 [1:26:21<4:57:49,  1.82s/it]{'loss': 0.249, 'learning_rate': 1.582258064516129e-05, 'epoch': 20.89}\n",
            "{'loss': 0.1805, 'learning_rate': 1.5806451612903226e-05, 'epoch': 20.97}\n",
            " 21% 2604/12400 [1:26:46<3:55:55,  1.45s/it][INFO|trainer.py:2463] 2022-05-03 23:55:30,712 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:55:30,712 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:55:30,712 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "                                   {'eval_loss': 0.6589866280555725, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.1108, 'eval_samples_per_second': 24.037, 'eval_steps_per_second': 1.537, 'epoch': 21.0}\n",
            " 21% 2604/12400 [1:26:55<3:55:55,  1.45s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:55:39,825 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2604\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:55:39,827 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2604/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:55:43,560 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2604/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:55:43,561 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2604/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-03 23:55:53,005 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2232] due to args.save_total_limit\n",
            "{'loss': 0.2304, 'learning_rate': 1.5790322580645162e-05, 'epoch': 21.05}\n",
            "{'loss': 0.2198, 'learning_rate': 1.5774193548387097e-05, 'epoch': 21.13}\n",
            " 21% 2630/12400 [1:27:56<5:00:27,  1.85s/it]{'loss': 0.2233, 'learning_rate': 1.5758064516129036e-05, 'epoch': 21.21}\n",
            " 21% 2640/12400 [1:28:14<4:55:53,  1.82s/it]{'loss': 0.1985, 'learning_rate': 1.5741935483870968e-05, 'epoch': 21.29}\n",
            " 21% 2646/12400 [1:28:25<4:54:56,  1.81s/it]\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
            " 21% 2650/12400 [1:28:33<4:53:50,  1.81s/it]{'loss': 0.205, 'learning_rate': 1.5725806451612903e-05, 'epoch': 21.37}\n",
            " 21% 2660/12400 [1:28:51<4:55:19,  1.82s/it]{'loss': 0.2018, 'learning_rate': 1.570967741935484e-05, 'epoch': 21.45}\n",
            "{'loss': 0.207, 'learning_rate': 1.5693548387096777e-05, 'epoch': 21.53}\n",
            "{'loss': 0.1648, 'learning_rate': 1.567741935483871e-05, 'epoch': 21.61}\n",
            "{'loss': 0.1639, 'learning_rate': 1.5661290322580648e-05, 'epoch': 21.69}\n",
            " 22% 2700/12400 [1:30:04<5:13:34,  1.94s/it]{'loss': 0.2534, 'learning_rate': 1.5645161290322583e-05, 'epoch': 21.77}\n",
            "{'loss': 0.1585, 'learning_rate': 1.5629032258064518e-05, 'epoch': 21.85}\n",
            "{'loss': 0.2081, 'learning_rate': 1.5612903225806454e-05, 'epoch': 21.94}\n",
            " 22% 2728/12400 [1:30:54<3:48:13,  1.42s/it][INFO|trainer.py:2463] 2022-05-03 23:59:38,413 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-03 23:59:38,413 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-03 23:59:38,413 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6288037300109863, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1048, 'eval_samples_per_second': 24.053, 'eval_steps_per_second': 1.538, 'epoch': 22.0}\n",
            " 22% 2728/12400 [1:31:03<3:48:13,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-03 23:59:47,520 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2728\n",
            "[INFO|configuration_utils.py:446] 2022-05-03 23:59:47,522 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2728/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-03 23:59:50,935 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2728/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-03 23:59:50,936 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2728/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:00:00,538 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2356] due to args.save_total_limit\n",
            " 22% 2730/12400 [1:31:20<16:53:53,  6.29s/it]{'loss': 0.1737, 'learning_rate': 1.559677419354839e-05, 'epoch': 22.02}\n",
            " 22% 2740/12400 [1:31:38<5:14:15,  1.95s/it]{'loss': 0.2775, 'learning_rate': 1.5580645161290324e-05, 'epoch': 22.1}\n",
            "{'loss': 0.148, 'learning_rate': 1.556451612903226e-05, 'epoch': 22.18}\n",
            "{'loss': 0.2032, 'learning_rate': 1.5548387096774195e-05, 'epoch': 22.26}\n",
            "{'loss': 0.2002, 'learning_rate': 1.553225806451613e-05, 'epoch': 22.34}\n",
            "{'loss': 0.1669, 'learning_rate': 1.5516129032258065e-05, 'epoch': 22.42}\n",
            " 22% 2790/12400 [1:33:09<4:51:59,  1.82s/it]{'loss': 0.1611, 'learning_rate': 1.55e-05, 'epoch': 22.5}\n",
            "{'loss': 0.1414, 'learning_rate': 1.5483870967741936e-05, 'epoch': 22.58}\n",
            " 23% 2810/12400 [1:33:46<4:51:16,  1.82s/it]{'loss': 0.165, 'learning_rate': 1.5467741935483875e-05, 'epoch': 22.66}\n",
            " 23% 2820/12400 [1:34:04<4:50:14,  1.82s/it]{'loss': 0.1798, 'learning_rate': 1.5451612903225807e-05, 'epoch': 22.74}\n",
            "{'loss': 0.2169, 'learning_rate': 1.5435483870967742e-05, 'epoch': 22.82}\n",
            "{'loss': 0.2129, 'learning_rate': 1.541935483870968e-05, 'epoch': 22.9}\n",
            "{'loss': 0.2046, 'learning_rate': 1.5403225806451613e-05, 'epoch': 22.98}\n",
            " 23% 2852/12400 [1:35:01<3:46:00,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:03:45,959 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:03:45,959 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:03:45,959 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "{'eval_loss': 0.6702011227607727, 'eval_accuracy': 0.821917808219178, 'eval_runtime': 9.1096, 'eval_samples_per_second': 24.041, 'eval_steps_per_second': 1.537, 'epoch': 23.0}\n",
            " 23% 2852/12400 [1:35:10<3:46:00,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:03:55,071 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2852\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:03:55,072 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2852/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:03:58,555 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2852/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:03:58,556 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2852/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:04:08,243 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2480] due to args.save_total_limit\n",
            " 23% 2860/12400 [1:35:38<6:12:58,  2.35s/it]{'loss': 0.1568, 'learning_rate': 1.538709677419355e-05, 'epoch': 23.06}\n",
            " 23% 2870/12400 [1:35:57<4:56:27,  1.87s/it]{'loss': 0.2094, 'learning_rate': 1.5370967741935487e-05, 'epoch': 23.15}\n",
            "{'loss': 0.2031, 'learning_rate': 1.535483870967742e-05, 'epoch': 23.23}\n",
            "                                            {'loss': 0.1871, 'learning_rate': 1.5338709677419357e-05, 'epoch': 23.31}\n",
            " 23% 2900/12400 [1:36:52<5:05:10,  1.93s/it]{'loss': 0.0831, 'learning_rate': 1.5322580645161292e-05, 'epoch': 23.39}\n",
            "{'loss': 0.1623, 'learning_rate': 1.5306451612903228e-05, 'epoch': 23.47}\n",
            "{'loss': 0.185, 'learning_rate': 1.5290322580645163e-05, 'epoch': 23.55}\n",
            "{'loss': 0.2062, 'learning_rate': 1.52741935483871e-05, 'epoch': 23.63}\n",
            " 24% 2940/12400 [1:38:05<4:46:16,  1.82s/it]{'loss': 0.2107, 'learning_rate': 1.5258064516129034e-05, 'epoch': 23.71}\n",
            "{'loss': 0.1666, 'learning_rate': 1.5241935483870969e-05, 'epoch': 23.79}\n",
            "{'loss': 0.1465, 'learning_rate': 1.5225806451612903e-05, 'epoch': 23.87}\n",
            "{'loss': 0.1919, 'learning_rate': 1.520967741935484e-05, 'epoch': 23.95}\n",
            " 24% 2976/12400 [1:39:09<3:42:50,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:07:53,716 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:07:53,716 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:07:53,716 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.98it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            " 24% 2976/12400 [1:39:18<3:42:50,  1.42s/it]\n",
            "{'eval_loss': 0.6021037101745605, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1053, 'eval_samples_per_second': 24.052, 'eval_steps_per_second': 1.538, 'epoch': 24.0}\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:08:02,823 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-2976\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:08:02,825 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-2976/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:08:06,185 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-2976/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:08:06,186 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-2976/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:08:15,855 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2604] due to args.save_total_limit\n",
            "{'loss': 0.1207, 'learning_rate': 1.5193548387096775e-05, 'epoch': 24.03}\n",
            "{'loss': 0.1676, 'learning_rate': 1.5177419354838712e-05, 'epoch': 24.11}\n",
            "                                            {'loss': 0.1551, 'learning_rate': 1.5161290322580646e-05, 'epoch': 24.19}\n",
            "{'loss': 0.1459, 'learning_rate': 1.5145161290322581e-05, 'epoch': 24.27}\n",
            "{'loss': 0.2518, 'learning_rate': 1.5129032258064518e-05, 'epoch': 24.35}\n",
            "{'loss': 0.1548, 'learning_rate': 1.5112903225806452e-05, 'epoch': 24.44}\n",
            "{'loss': 0.1507, 'learning_rate': 1.5096774193548389e-05, 'epoch': 24.52}\n",
            "{'loss': 0.1568, 'learning_rate': 1.5080645161290324e-05, 'epoch': 24.6}\n",
            " 25% 3060/12400 [1:42:05<4:42:29,  1.81s/it]{'loss': 0.2221, 'learning_rate': 1.5064516129032259e-05, 'epoch': 24.68}\n",
            " 25% 3070/12400 [1:42:23<4:42:45,  1.82s/it]{'loss': 0.0923, 'learning_rate': 1.5048387096774194e-05, 'epoch': 24.76}\n",
            "{'loss': 0.2223, 'learning_rate': 1.503225806451613e-05, 'epoch': 24.84}\n",
            " 25% 3090/12400 [1:43:00<4:42:40,  1.82s/it]{'loss': 0.13, 'learning_rate': 1.5016129032258067e-05, 'epoch': 24.92}\n",
            " 25% 3100/12400 [1:43:17<4:00:16,  1.55s/it]{'loss': 0.0981, 'learning_rate': 1.5000000000000002e-05, 'epoch': 25.0}\n",
            "[INFO|trainer.py:2463] 2022-05-04 00:12:01,693 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:12:01,693 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:12:01,693 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "{'eval_loss': 0.6716633439064026, 'eval_accuracy': 0.8310502283105022, 'eval_runtime': 9.1556, 'eval_samples_per_second': 23.92, 'eval_steps_per_second': 1.529, 'epoch': 25.0}\n",
            "\n",
            " 25% 3100/12400 [1:43:26<4:00:16,  1.55s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:12:10,851 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3100\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:12:10,853 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3100/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:12:14,700 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3100/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:12:14,701 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3100/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:12:24,073 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2728] due to args.save_total_limit\n",
            "{'loss': 0.0832, 'learning_rate': 1.4983870967741936e-05, 'epoch': 25.08}\n",
            " 25% 3120/12400 [1:44:16<4:48:17,  1.86s/it]{'loss': 0.1531, 'learning_rate': 1.4967741935483873e-05, 'epoch': 25.16}\n",
            "{'loss': 0.1183, 'learning_rate': 1.4951612903225808e-05, 'epoch': 25.24}\n",
            "{'loss': 0.115, 'learning_rate': 1.4935483870967743e-05, 'epoch': 25.32}\n",
            " 25% 3150/12400 [1:45:11<4:38:52,  1.81s/it]{'loss': 0.1086, 'learning_rate': 1.4919354838709679e-05, 'epoch': 25.4}\n",
            "{'loss': 0.1587, 'learning_rate': 1.4903225806451614e-05, 'epoch': 25.48}\n",
            " 26% 3170/12400 [1:45:47<4:40:36,  1.82s/it]{'loss': 0.2324, 'learning_rate': 1.4887096774193551e-05, 'epoch': 25.56}\n",
            "{'loss': 0.1743, 'learning_rate': 1.4870967741935485e-05, 'epoch': 25.65}\n",
            " 26% 3190/12400 [1:46:24<4:38:18,  1.81s/it]{'loss': 0.1367, 'learning_rate': 1.4854838709677422e-05, 'epoch': 25.73}\n",
            "{'loss': 0.1947, 'learning_rate': 1.4838709677419357e-05, 'epoch': 25.81}\n",
            " 26% 3210/12400 [1:47:01<4:40:19,  1.83s/it]{'loss': 0.1274, 'learning_rate': 1.482258064516129e-05, 'epoch': 25.89}\n",
            " 26% 3220/12400 [1:47:19<4:38:50,  1.82s/it]{'loss': 0.1139, 'learning_rate': 1.4806451612903227e-05, 'epoch': 25.97}\n",
            " 26% 3224/12400 [1:47:25<3:37:27,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:16:09,681 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:16:09,681 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:16:09,681 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.99it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.10it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.54it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "                                   {'eval_loss': 0.6903749108314514, 'eval_accuracy': 0.8082191780821918, 'eval_runtime': 9.1453, 'eval_samples_per_second': 23.947, 'eval_steps_per_second': 1.531, 'epoch': 26.0}\n",
            " 26% 3224/12400 [1:47:34<3:37:27,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:16:18,828 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3224\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:16:18,830 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3224/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:16:22,315 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3224/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:16:22,315 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3224/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:16:32,040 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2852] due to args.save_total_limit\n",
            " 26% 3230/12400 [1:47:58<7:22:55,  2.90s/it]{'loss': 0.0756, 'learning_rate': 1.4790322580645163e-05, 'epoch': 26.05}\n",
            "{'loss': 0.2238, 'learning_rate': 1.47741935483871e-05, 'epoch': 26.13}\n",
            "{'loss': 0.1463, 'learning_rate': 1.4758064516129033e-05, 'epoch': 26.21}\n",
            " 26% 3260/12400 [1:48:53<4:36:32,  1.82s/it]{'loss': 0.0913, 'learning_rate': 1.4741935483870969e-05, 'epoch': 26.29}\n",
            "{'loss': 0.2074, 'learning_rate': 1.4725806451612906e-05, 'epoch': 26.37}\n",
            " 26% 3280/12400 [1:49:30<4:37:07,  1.82s/it]{'loss': 0.1168, 'learning_rate': 1.470967741935484e-05, 'epoch': 26.45}\n",
            "{'loss': 0.1154, 'learning_rate': 1.4693548387096775e-05, 'epoch': 26.53}\n",
            " 27% 3300/12400 [1:50:07<4:53:46,  1.94s/it]{'loss': 0.257, 'learning_rate': 1.4677419354838712e-05, 'epoch': 26.61}\n",
            "{'loss': 0.1685, 'learning_rate': 1.4661290322580645e-05, 'epoch': 26.69}\n",
            "{'loss': 0.1908, 'learning_rate': 1.4645161290322582e-05, 'epoch': 26.77}\n",
            " 27% 3330/12400 [1:51:01<4:34:57,  1.82s/it]{'loss': 0.1794, 'learning_rate': 1.4629032258064518e-05, 'epoch': 26.85}\n",
            "{'loss': 0.1039, 'learning_rate': 1.4612903225806451e-05, 'epoch': 26.94}\n",
            " 27% 3348/12400 [1:51:33<3:33:34,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:20:17,479 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:20:17,480 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:20:17,480 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.51it/s]\u001b[A\n",
            "{'eval_loss': 0.6154649257659912, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.1063, 'eval_samples_per_second': 24.049, 'eval_steps_per_second': 1.537, 'epoch': 27.0}\n",
            "\n",
            " 27% 3348/12400 [1:51:42<3:33:34,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:20:26,588 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3348\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:20:26,590 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3348/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:20:30,000 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3348/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:20:30,001 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3348/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:20:40,045 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3100] due to args.save_total_limit\n",
            "{'loss': 0.0908, 'learning_rate': 1.4596774193548388e-05, 'epoch': 27.02}\n",
            " 27% 3360/12400 [1:52:18<4:55:22,  1.96s/it]{'loss': 0.1305, 'learning_rate': 1.4580645161290324e-05, 'epoch': 27.1}\n",
            " 27% 3370/12400 [1:52:36<4:41:14,  1.87s/it]{'loss': 0.1427, 'learning_rate': 1.456451612903226e-05, 'epoch': 27.18}\n",
            "{'loss': 0.1381, 'learning_rate': 1.4548387096774194e-05, 'epoch': 27.26}\n",
            "{'loss': 0.1493, 'learning_rate': 1.453225806451613e-05, 'epoch': 27.34}\n",
            "{'loss': 0.227, 'learning_rate': 1.4516129032258066e-05, 'epoch': 27.42}\n",
            "{'loss': 0.204, 'learning_rate': 1.45e-05, 'epoch': 27.5}\n",
            "{'loss': 0.0942, 'learning_rate': 1.4483870967741937e-05, 'epoch': 27.58}\n",
            " 28% 3430/12400 [1:54:26<4:32:20,  1.82s/it]{'loss': 0.1022, 'learning_rate': 1.4467741935483872e-05, 'epoch': 27.66}\n",
            " 28% 3440/12400 [1:54:44<4:31:17,  1.82s/it]{'loss': 0.1619, 'learning_rate': 1.4451612903225806e-05, 'epoch': 27.74}\n",
            "{'loss': 0.1248, 'learning_rate': 1.4435483870967743e-05, 'epoch': 27.82}\n",
            "                                            {'loss': 0.0714, 'learning_rate': 1.4419354838709678e-05, 'epoch': 27.9}\n",
            "{'loss': 0.0977, 'learning_rate': 1.4403225806451615e-05, 'epoch': 27.98}\n",
            " 28% 3472/12400 [1:55:41<3:30:55,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:24:25,634 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:24:25,634 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:24:25,634 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.54it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6035921573638916, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.0884, 'eval_samples_per_second': 24.097, 'eval_steps_per_second': 1.54, 'epoch': 28.0}\n",
            " 28% 3472/12400 [1:55:50<3:30:55,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:24:34,724 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3472\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:24:34,726 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3472/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:24:38,114 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3472/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:24:38,115 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3472/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:24:47,925 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3224] due to args.save_total_limit\n",
            "{'loss': 0.1239, 'learning_rate': 1.4387096774193549e-05, 'epoch': 28.06}\n",
            " 28% 3490/12400 [1:56:36<4:36:54,  1.86s/it]{'loss': 0.1586, 'learning_rate': 1.4370967741935484e-05, 'epoch': 28.15}\n",
            " 28% 3500/12400 [1:56:55<4:50:00,  1.96s/it]{'loss': 0.1739, 'learning_rate': 1.4354838709677421e-05, 'epoch': 28.23}\n",
            "{'loss': 0.31, 'learning_rate': 1.4338709677419355e-05, 'epoch': 28.31}\n",
            " 28% 3520/12400 [1:57:32<4:28:09,  1.81s/it]{'loss': 0.1272, 'learning_rate': 1.4322580645161292e-05, 'epoch': 28.39}\n",
            " 28% 3530/12400 [1:57:50<4:29:50,  1.83s/it]{'loss': 0.1408, 'learning_rate': 1.4306451612903227e-05, 'epoch': 28.47}\n",
            " 29% 3540/12400 [1:58:08<4:29:25,  1.82s/it]{'loss': 0.1781, 'learning_rate': 1.4290322580645163e-05, 'epoch': 28.55}\n",
            "{'loss': 0.112, 'learning_rate': 1.4274193548387098e-05, 'epoch': 28.63}\n",
            "{'loss': 0.0919, 'learning_rate': 1.4258064516129033e-05, 'epoch': 28.71}\n",
            " 29% 3570/12400 [1:59:03<4:27:40,  1.82s/it]{'loss': 0.1411, 'learning_rate': 1.4241935483870968e-05, 'epoch': 28.79}\n",
            " 29% 3580/12400 [1:59:21<4:28:11,  1.82s/it]{'loss': 0.1629, 'learning_rate': 1.4225806451612905e-05, 'epoch': 28.87}\n",
            "{'loss': 0.1111, 'learning_rate': 1.4209677419354839e-05, 'epoch': 28.95}\n",
            " 29% 3596/12400 [1:59:49<3:27:55,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:28:33,570 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:28:33,570 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:28:33,570 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6287453174591064, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1022, 'eval_samples_per_second': 24.06, 'eval_steps_per_second': 1.538, 'epoch': 29.0}\n",
            " 29% 3596/12400 [1:59:58<3:27:55,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:28:42,675 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3596\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:28:42,678 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3596/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:28:46,074 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3596/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:28:46,074 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3596/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:28:55,794 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3348] due to args.save_total_limit\n",
            " 29% 3600/12400 [2:00:19<10:05:49,  4.13s/it]{'loss': 0.1582, 'learning_rate': 1.4193548387096776e-05, 'epoch': 29.03}\n",
            " 29% 3610/12400 [2:00:37<4:38:12,  1.90s/it]{'loss': 0.0901, 'learning_rate': 1.4177419354838711e-05, 'epoch': 29.11}\n",
            "{'loss': 0.1838, 'learning_rate': 1.4161290322580645e-05, 'epoch': 29.19}\n",
            "{'loss': 0.1536, 'learning_rate': 1.4145161290322582e-05, 'epoch': 29.27}\n",
            " 29% 3640/12400 [2:01:32<4:23:49,  1.81s/it]{'loss': 0.1951, 'learning_rate': 1.4129032258064517e-05, 'epoch': 29.35}\n",
            " 29% 3650/12400 [2:01:50<4:25:19,  1.82s/it]{'loss': 0.1263, 'learning_rate': 1.4112903225806454e-05, 'epoch': 29.44}\n",
            " 30% 3660/12400 [2:02:09<4:26:07,  1.83s/it]{'loss': 0.1488, 'learning_rate': 1.4096774193548388e-05, 'epoch': 29.52}\n",
            "{'loss': 0.1839, 'learning_rate': 1.4080645161290323e-05, 'epoch': 29.6}\n",
            "{'loss': 0.0848, 'learning_rate': 1.406451612903226e-05, 'epoch': 29.68}\n",
            "{'loss': 0.1883, 'learning_rate': 1.4048387096774194e-05, 'epoch': 29.76}\n",
            " 30% 3700/12400 [2:03:22<4:41:33,  1.94s/it]{'loss': 0.1325, 'learning_rate': 1.4032258064516131e-05, 'epoch': 29.84}\n",
            "{'loss': 0.0899, 'learning_rate': 1.4016129032258066e-05, 'epoch': 29.92}\n",
            " 30% 3720/12400 [2:03:57<3:24:52,  1.42s/it]{'loss': 0.1857, 'learning_rate': 1.4e-05, 'epoch': 30.0}\n",
            " 30% 3720/12400 [2:03:57<3:24:52,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:32:41,728 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:32:41,728 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:32:41,728 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 30% 3720/12400 [2:04:06<3:24:52,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "{'eval_loss': 0.630782961845398, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.1124, 'eval_samples_per_second': 24.033, 'eval_steps_per_second': 1.536, 'epoch': 30.0}\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:32:50,843 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3720\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:32:50,845 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3720/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:32:54,519 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3720/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:32:54,520 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3720/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:33:04,231 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3472] due to args.save_total_limit\n",
            " 30% 3730/12400 [2:04:38<5:01:20,  2.09s/it]{'loss': 0.1027, 'learning_rate': 1.3983870967741937e-05, 'epoch': 30.08}\n",
            "{'loss': 0.1983, 'learning_rate': 1.3967741935483872e-05, 'epoch': 30.16}\n",
            " 30% 3750/12400 [2:05:15<4:23:55,  1.83s/it]{'loss': 0.1301, 'learning_rate': 1.3951612903225809e-05, 'epoch': 30.24}\n",
            " 30% 3760/12400 [2:05:33<4:20:31,  1.81s/it]{'loss': 0.1224, 'learning_rate': 1.3935483870967743e-05, 'epoch': 30.32}\n",
            "{'loss': 0.0625, 'learning_rate': 1.3919354838709678e-05, 'epoch': 30.4}\n",
            "{'loss': 0.108, 'learning_rate': 1.3903225806451615e-05, 'epoch': 30.48}\n",
            "{'loss': 0.1292, 'learning_rate': 1.3887096774193549e-05, 'epoch': 30.56}\n",
            "{'loss': 0.0838, 'learning_rate': 1.3870967741935486e-05, 'epoch': 30.65}\n",
            "{'loss': 0.1863, 'learning_rate': 1.3854838709677421e-05, 'epoch': 30.73}\n",
            "{'loss': 0.1205, 'learning_rate': 1.3838709677419355e-05, 'epoch': 30.81}\n",
            " 31% 3830/12400 [2:07:41<4:20:33,  1.82s/it]{'loss': 0.0704, 'learning_rate': 1.3822580645161292e-05, 'epoch': 30.89}\n",
            " 31% 3840/12400 [2:07:59<4:20:13,  1.82s/it]{'loss': 0.1366, 'learning_rate': 1.3806451612903227e-05, 'epoch': 30.97}\n",
            " 31% 3844/12400 [2:08:05<3:22:12,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:36:49,745 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:36:49,746 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:36:49,746 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 31% 3844/12400 [2:08:14<3:22:12,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   {'eval_loss': 0.6408676505088806, 'eval_accuracy': 0.8264840182648402, 'eval_runtime': 9.1075, 'eval_samples_per_second': 24.046, 'eval_steps_per_second': 1.537, 'epoch': 31.0}\n",
            "\u001b[A[INFO|trainer.py:2213] 2022-05-04 00:36:58,855 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3844\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:36:58,858 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3844/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:37:02,266 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3844/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:37:02,266 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3844/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:37:12,113 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3596] due to args.save_total_limit\n",
            "{'loss': 0.176, 'learning_rate': 1.3790322580645164e-05, 'epoch': 31.05}\n",
            " 31% 3860/12400 [2:08:57<4:28:24,  1.89s/it]{'loss': 0.1433, 'learning_rate': 1.3774193548387098e-05, 'epoch': 31.13}\n",
            "{'loss': 0.1461, 'learning_rate': 1.3758064516129033e-05, 'epoch': 31.21}\n",
            "{'loss': 0.0664, 'learning_rate': 1.374193548387097e-05, 'epoch': 31.29}\n",
            "{'loss': 0.1058, 'learning_rate': 1.3725806451612903e-05, 'epoch': 31.37}\n",
            " 31% 3900/12400 [2:10:10<4:35:33,  1.95s/it]{'loss': 0.1129, 'learning_rate': 1.3709677419354839e-05, 'epoch': 31.45}\n",
            "{'loss': 0.0897, 'learning_rate': 1.3693548387096776e-05, 'epoch': 31.53}\n",
            "{'loss': 0.0757, 'learning_rate': 1.367741935483871e-05, 'epoch': 31.61}\n",
            " 32% 3930/12400 [2:11:05<4:16:03,  1.81s/it]{'loss': 0.1437, 'learning_rate': 1.3661290322580646e-05, 'epoch': 31.69}\n",
            "{'loss': 0.0996, 'learning_rate': 1.3645161290322582e-05, 'epoch': 31.77}\n",
            " 32% 3950/12400 [2:11:42<4:17:01,  1.82s/it]{'loss': 0.091, 'learning_rate': 1.3629032258064517e-05, 'epoch': 31.85}\n",
            " 32% 3960/12400 [2:12:00<4:16:51,  1.83s/it]{'loss': 0.1054, 'learning_rate': 1.3612903225806452e-05, 'epoch': 31.94}\n",
            " 32% 3968/12400 [2:12:13<3:19:00,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:40:57,687 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:40:57,687 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:40:57,687 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6027926802635193, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.0919, 'eval_samples_per_second': 24.087, 'eval_steps_per_second': 1.54, 'epoch': 32.0}\n",
            " 32% 3968/12400 [2:12:22<3:19:00,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:41:06,781 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-3968\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:41:06,783 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-3968/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:41:10,572 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-3968/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:41:10,573 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-3968/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:41:19,932 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3720] due to args.save_total_limit\n",
            " 32% 3970/12400 [2:12:39<14:49:03,  6.33s/it]{'loss': 0.1583, 'learning_rate': 1.3596774193548388e-05, 'epoch': 32.02}\n",
            "{'loss': 0.1286, 'learning_rate': 1.3580645161290325e-05, 'epoch': 32.1}\n",
            " 32% 3990/12400 [2:13:16<4:20:56,  1.86s/it]{'loss': 0.0497, 'learning_rate': 1.356451612903226e-05, 'epoch': 32.18}\n",
            " 32% 4000/12400 [2:13:35<4:32:17,  1.94s/it]{'loss': 0.11, 'learning_rate': 1.3548387096774194e-05, 'epoch': 32.26}\n",
            " 32% 4010/12400 [2:13:53<4:13:21,  1.81s/it]{'loss': 0.1291, 'learning_rate': 1.353225806451613e-05, 'epoch': 32.34}\n",
            " 32% 4020/12400 [2:14:11<4:13:31,  1.82s/it]{'loss': 0.1655, 'learning_rate': 1.3516129032258066e-05, 'epoch': 32.42}\n",
            "{'loss': 0.0285, 'learning_rate': 1.3500000000000001e-05, 'epoch': 32.5}\n",
            " 33% 4040/12400 [2:14:47<4:13:55,  1.82s/it]{'loss': 0.2055, 'learning_rate': 1.3483870967741936e-05, 'epoch': 32.58}\n",
            "{'loss': 0.2096, 'learning_rate': 1.3467741935483872e-05, 'epoch': 32.66}\n",
            "{'loss': 0.1352, 'learning_rate': 1.3451612903225809e-05, 'epoch': 32.74}\n",
            "{'loss': 0.1594, 'learning_rate': 1.3435483870967742e-05, 'epoch': 32.82}\n",
            "{'loss': 0.1011, 'learning_rate': 1.341935483870968e-05, 'epoch': 32.9}\n",
            "{'loss': 0.1051, 'learning_rate': 1.3403225806451615e-05, 'epoch': 32.98}\n",
            " 33% 4092/12400 [2:16:21<3:16:46,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:45:05,523 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:45:05,523 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:45:05,523 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.99it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.54it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            {'eval_loss': 0.5969477891921997, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.114, 'eval_samples_per_second': 24.029, 'eval_steps_per_second': 1.536, 'epoch': 33.0}\n",
            "\n",
            " 33% 4092/12400 [2:16:30<3:16:46,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:45:14,640 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4092\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:45:14,642 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4092/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:45:18,032 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4092/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:45:18,032 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4092/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:45:27,827 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-2976] due to args.save_total_limit\n",
            " 33% 4100/12400 [2:16:58<5:40:13,  2.46s/it]{'loss': 0.0386, 'learning_rate': 1.3387096774193548e-05, 'epoch': 33.06}\n",
            "{'loss': 0.1725, 'learning_rate': 1.3370967741935485e-05, 'epoch': 33.15}\n",
            "{'loss': 0.0912, 'learning_rate': 1.335483870967742e-05, 'epoch': 33.23}\n",
            "{'loss': 0.094, 'learning_rate': 1.3338709677419358e-05, 'epoch': 33.31}\n",
            "{'loss': 0.1686, 'learning_rate': 1.3322580645161291e-05, 'epoch': 33.39}\n",
            " 33% 4150/12400 [2:18:30<4:10:44,  1.82s/it]{'loss': 0.0784, 'learning_rate': 1.3306451612903227e-05, 'epoch': 33.47}\n",
            "{'loss': 0.0756, 'learning_rate': 1.3290322580645164e-05, 'epoch': 33.55}\n",
            "{'loss': 0.084, 'learning_rate': 1.3274193548387097e-05, 'epoch': 33.63}\n",
            " 34% 4180/12400 [2:19:24<4:08:40,  1.82s/it]{'loss': 0.1192, 'learning_rate': 1.3258064516129034e-05, 'epoch': 33.71}\n",
            "{'loss': 0.1044, 'learning_rate': 1.324193548387097e-05, 'epoch': 33.79}\n",
            "{'loss': 0.1513, 'learning_rate': 1.3225806451612903e-05, 'epoch': 33.87}\n",
            "{'loss': 0.0908, 'learning_rate': 1.320967741935484e-05, 'epoch': 33.95}\n",
            " 34% 4216/12400 [2:20:29<3:13:44,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:49:13,625 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:49:13,626 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:49:13,626 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.00it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 34% 4216/12400 [2:20:38<3:13:44,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A{'eval_loss': 0.7118682265281677, 'eval_accuracy': 0.8082191780821918, 'eval_runtime': 9.103, 'eval_samples_per_second': 24.058, 'eval_steps_per_second': 1.538, 'epoch': 34.0}\n",
            "\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:49:22,731 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4216\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:49:22,732 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4216/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:49:26,238 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4216/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:49:26,239 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4216/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:49:35,785 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3844] due to args.save_total_limit\n",
            " 34% 4220/12400 [2:20:58<9:06:15,  4.01s/it]{'loss': 0.1544, 'learning_rate': 1.3193548387096775e-05, 'epoch': 34.03}\n",
            "{'loss': 0.1134, 'learning_rate': 1.3177419354838709e-05, 'epoch': 34.11}\n",
            " 34% 4240/12400 [2:21:35<4:12:15,  1.85s/it]{'loss': 0.0408, 'learning_rate': 1.3161290322580646e-05, 'epoch': 34.19}\n",
            " 34% 4250/12400 [2:21:54<4:07:01,  1.82s/it]{'loss': 0.044, 'learning_rate': 1.3145161290322581e-05, 'epoch': 34.27}\n",
            " 34% 4260/12400 [2:22:12<4:05:17,  1.81s/it]{'loss': 0.1083, 'learning_rate': 1.3129032258064518e-05, 'epoch': 34.35}\n",
            "{'loss': 0.116, 'learning_rate': 1.3112903225806452e-05, 'epoch': 34.44}\n",
            " 35% 4280/12400 [2:22:48<4:06:54,  1.82s/it]{'loss': 0.156, 'learning_rate': 1.3096774193548387e-05, 'epoch': 34.52}\n",
            "{'loss': 0.1227, 'learning_rate': 1.3080645161290324e-05, 'epoch': 34.6}\n",
            "{'loss': 0.0357, 'learning_rate': 1.3064516129032258e-05, 'epoch': 34.68}\n",
            " 35% 4310/12400 [2:23:43<4:05:42,  1.82s/it]{'loss': 0.121, 'learning_rate': 1.3048387096774195e-05, 'epoch': 34.76}\n",
            " 35% 4320/12400 [2:24:01<4:05:21,  1.82s/it]{'loss': 0.0909, 'learning_rate': 1.303225806451613e-05, 'epoch': 34.84}\n",
            " 35% 4330/12400 [2:24:20<4:05:07,  1.82s/it]{'loss': 0.0993, 'learning_rate': 1.3016129032258064e-05, 'epoch': 34.92}\n",
            " 35% 4340/12400 [2:24:37<3:10:31,  1.42s/it]{'loss': 0.1469, 'learning_rate': 1.3000000000000001e-05, 'epoch': 35.0}\n",
            " 35% 4340/12400 [2:24:37<3:10:31,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:53:21,239 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:53:21,239 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:53:21,239 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5660012364387512, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.0812, 'eval_samples_per_second': 24.116, 'eval_steps_per_second': 1.542, 'epoch': 35.0}\n",
            " 35% 4340/12400 [2:24:46<3:10:31,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:53:30,322 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4340\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:53:30,324 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4340/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:53:33,760 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4340/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:53:33,761 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4340/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:53:43,322 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-3968] due to args.save_total_limit\n",
            "{'loss': 0.0513, 'learning_rate': 1.2983870967741936e-05, 'epoch': 35.08}\n",
            " 35% 4360/12400 [2:25:35<4:09:59,  1.87s/it]{'loss': 0.1524, 'learning_rate': 1.2967741935483873e-05, 'epoch': 35.16}\n",
            "                                            {'loss': 0.0655, 'learning_rate': 1.2951612903225807e-05, 'epoch': 35.24}\n",
            " 35% 4380/12400 [2:26:12<4:02:00,  1.81s/it]{'loss': 0.188, 'learning_rate': 1.2935483870967742e-05, 'epoch': 35.32}\n",
            " 35% 4390/12400 [2:26:30<4:01:51,  1.81s/it]{'loss': 0.0513, 'learning_rate': 1.2919354838709679e-05, 'epoch': 35.4}\n",
            "{'loss': 0.11, 'learning_rate': 1.2903225806451613e-05, 'epoch': 35.48}\n",
            "{'loss': 0.2004, 'learning_rate': 1.288709677419355e-05, 'epoch': 35.56}\n",
            "{'loss': 0.1145, 'learning_rate': 1.2870967741935485e-05, 'epoch': 35.65}\n",
            " 36% 4430/12400 [2:27:43<4:01:11,  1.82s/it]{'loss': 0.1713, 'learning_rate': 1.285483870967742e-05, 'epoch': 35.73}\n",
            " 36% 4440/12400 [2:28:02<4:01:42,  1.82s/it]{'loss': 0.1559, 'learning_rate': 1.2838709677419356e-05, 'epoch': 35.81}\n",
            " 36% 4450/12400 [2:28:20<4:01:23,  1.82s/it]{'loss': 0.0941, 'learning_rate': 1.2822580645161291e-05, 'epoch': 35.89}\n",
            " 36% 4460/12400 [2:28:38<4:00:54,  1.82s/it]\n",
            " 36% 4464/12400 [2:28:44<3:07:15,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 00:57:28,753 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 00:57:28,753 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 00:57:28,753 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5946837663650513, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.0769, 'eval_samples_per_second': 24.127, 'eval_steps_per_second': 1.542, 'epoch': 36.0}\n",
            " 36% 4464/12400 [2:28:53<3:07:15,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 00:57:37,832 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4464\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 00:57:37,834 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4464/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 00:57:41,206 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4464/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 00:57:41,206 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4464/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 00:57:50,858 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4092] due to args.save_total_limit\n",
            "{'loss': 0.1354, 'learning_rate': 1.2790322580645163e-05, 'epoch': 36.05}\n",
            "{'loss': 0.0681, 'learning_rate': 1.2774193548387097e-05, 'epoch': 36.13}\n",
            "{'loss': 0.0977, 'learning_rate': 1.2758064516129034e-05, 'epoch': 36.21}\n",
            "{'loss': 0.0588, 'learning_rate': 1.274193548387097e-05, 'epoch': 36.29}\n",
            "                                            {'loss': 0.1701, 'learning_rate': 1.2725806451612903e-05, 'epoch': 36.37}\n",
            " 36% 4520/12400 [2:30:49<3:59:09,  1.82s/it]{'loss': 0.0933, 'learning_rate': 1.270967741935484e-05, 'epoch': 36.45}\n",
            "{'loss': 0.0983, 'learning_rate': 1.2693548387096775e-05, 'epoch': 36.53}\n",
            " 37% 4540/12400 [2:31:25<3:58:48,  1.82s/it]{'loss': 0.0588, 'learning_rate': 1.2677419354838712e-05, 'epoch': 36.61}\n",
            " 37% 4550/12400 [2:31:44<3:58:13,  1.82s/it]{'loss': 0.1441, 'learning_rate': 1.2661290322580646e-05, 'epoch': 36.69}\n",
            "                                            {'loss': 0.0733, 'learning_rate': 1.2645161290322581e-05, 'epoch': 36.77}\n",
            "{'loss': 0.0521, 'learning_rate': 1.2629032258064518e-05, 'epoch': 36.85}\n",
            " 37% 4580/12400 [2:32:38<3:57:22,  1.82s/it]{'loss': 0.0829, 'learning_rate': 1.2612903225806452e-05, 'epoch': 36.94}\n",
            " 37% 4588/12400 [2:32:52<3:04:07,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 01:01:36,280 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:01:36,280 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:01:36,280 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5566255450248718, 'eval_accuracy': 0.8310502283105022, 'eval_runtime': 9.1153, 'eval_samples_per_second': 24.026, 'eval_steps_per_second': 1.536, 'epoch': 37.0}\n",
            " 37% 4588/12400 [2:33:01<3:04:07,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:01:45,397 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4588\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:01:45,399 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4588/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:01:48,862 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4588/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:01:48,863 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4588/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:01:58,454 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4216] due to args.save_total_limit\n",
            " 37% 4590/12400 [2:33:18<13:39:51,  6.30s/it]{'loss': 0.2004, 'learning_rate': 1.2596774193548389e-05, 'epoch': 37.02}\n",
            "{'loss': 0.1388, 'learning_rate': 1.2580645161290324e-05, 'epoch': 37.1}\n",
            "{'loss': 0.0961, 'learning_rate': 1.2564516129032258e-05, 'epoch': 37.18}\n",
            " 37% 4620/12400 [2:34:13<3:56:00,  1.82s/it]{'loss': 0.0645, 'learning_rate': 1.2548387096774195e-05, 'epoch': 37.26}\n",
            "{'loss': 0.0497, 'learning_rate': 1.253225806451613e-05, 'epoch': 37.34}\n",
            "{'loss': 0.1493, 'learning_rate': 1.2516129032258067e-05, 'epoch': 37.42}\n",
            "{'loss': 0.1258, 'learning_rate': 1.25e-05, 'epoch': 37.5}\n",
            "{'loss': 0.0694, 'learning_rate': 1.2483870967741936e-05, 'epoch': 37.58}\n",
            "{'loss': 0.1121, 'learning_rate': 1.2467741935483873e-05, 'epoch': 37.66}\n",
            " 38% 4680/12400 [2:36:02<3:53:48,  1.82s/it]{'loss': 0.128, 'learning_rate': 1.2451612903225807e-05, 'epoch': 37.74}\n",
            "{'loss': 0.1367, 'learning_rate': 1.2435483870967744e-05, 'epoch': 37.82}\n",
            " 38% 4700/12400 [2:36:39<4:09:57,  1.95s/it]{'loss': 0.0557, 'learning_rate': 1.2419354838709679e-05, 'epoch': 37.9}\n",
            "{'loss': 0.247, 'learning_rate': 1.2403225806451612e-05, 'epoch': 37.98}\n",
            " 38% 4712/12400 [2:37:00<3:02:03,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:05:44,354 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:05:44,354 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:05:44,354 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.62it/s]\u001b[A\n",
            " 50% 7/14 [00:04<00:04,  1.58it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.54it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5816435217857361, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.1196, 'eval_samples_per_second': 24.014, 'eval_steps_per_second': 1.535, 'epoch': 38.0}\n",
            " 38% 4712/12400 [2:37:09<3:02:03,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:05:53,476 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4712\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:05:53,479 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4712/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:05:56,943 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4712/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:05:56,943 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4712/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:06:06,438 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4340] due to args.save_total_limit\n",
            "                                            {'loss': 0.0531, 'learning_rate': 1.238709677419355e-05, 'epoch': 38.06}\n",
            "{'loss': 0.0735, 'learning_rate': 1.2370967741935485e-05, 'epoch': 38.15}\n",
            "{'loss': 0.0554, 'learning_rate': 1.2354838709677422e-05, 'epoch': 38.23}\n",
            " 38% 4750/12400 [2:38:32<3:51:47,  1.82s/it]{'loss': 0.062, 'learning_rate': 1.2338709677419355e-05, 'epoch': 38.31}\n",
            " 38% 4760/12400 [2:38:50<3:50:09,  1.81s/it]{'loss': 0.0865, 'learning_rate': 1.232258064516129e-05, 'epoch': 38.39}\n",
            "{'loss': 0.0447, 'learning_rate': 1.2306451612903228e-05, 'epoch': 38.47}\n",
            "{'loss': 0.1405, 'learning_rate': 1.2290322580645161e-05, 'epoch': 38.55}\n",
            " 39% 4790/12400 [2:39:45<3:51:11,  1.82s/it]{'loss': 0.0524, 'learning_rate': 1.2274193548387098e-05, 'epoch': 38.63}\n",
            "{'loss': 0.1185, 'learning_rate': 1.2258064516129034e-05, 'epoch': 38.71}\n",
            " 39% 4810/12400 [2:40:21<3:50:42,  1.82s/it]{'loss': 0.0904, 'learning_rate': 1.2241935483870967e-05, 'epoch': 38.79}\n",
            "{'loss': 0.077, 'learning_rate': 1.2225806451612904e-05, 'epoch': 38.87}\n",
            "{'loss': 0.0586, 'learning_rate': 1.220967741935484e-05, 'epoch': 38.95}\n",
            " 39% 4836/12400 [2:41:08<2:58:24,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:09:52,192 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:09:52,192 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:09:52,193 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.51it/s]\u001b[A\n",
            "{'eval_loss': 0.6500716805458069, 'eval_accuracy': 0.8310502283105022, 'eval_runtime': 9.0985, 'eval_samples_per_second': 24.07, 'eval_steps_per_second': 1.539, 'epoch': 39.0}\n",
            "\n",
            " 39% 4836/12400 [2:41:17<2:58:24,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:10:01,293 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4836\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:10:01,296 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4836/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:10:04,740 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4836/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:10:04,741 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4836/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:10:14,335 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4464] due to args.save_total_limit\n",
            " 39% 4840/12400 [2:41:37<8:24:42,  4.01s/it] {'loss': 0.0574, 'learning_rate': 1.2193548387096775e-05, 'epoch': 39.03}\n",
            "{'loss': 0.1099, 'learning_rate': 1.217741935483871e-05, 'epoch': 39.11}\n",
            " 39% 4860/12400 [2:42:14<3:53:29,  1.86s/it]{'loss': 0.0918, 'learning_rate': 1.2161290322580646e-05, 'epoch': 39.19}\n",
            " 39% 4870/12400 [2:42:32<3:49:03,  1.83s/it]{'loss': 0.1303, 'learning_rate': 1.2145161290322583e-05, 'epoch': 39.27}\n",
            " 39% 4880/12400 [2:42:50<3:46:30,  1.81s/it]{'loss': 0.0769, 'learning_rate': 1.2129032258064518e-05, 'epoch': 39.35}\n",
            " 39% 4890/12400 [2:43:09<3:47:47,  1.82s/it]{'loss': 0.0577, 'learning_rate': 1.2112903225806451e-05, 'epoch': 39.44}\n",
            "{'loss': 0.1052, 'learning_rate': 1.2096774193548388e-05, 'epoch': 39.52}\n",
            " 40% 4910/12400 [2:43:46<3:47:52,  1.83s/it]{'loss': 0.1136, 'learning_rate': 1.2080645161290324e-05, 'epoch': 39.6}\n",
            " 40% 4920/12400 [2:44:04<3:45:46,  1.81s/it]{'loss': 0.081, 'learning_rate': 1.2064516129032259e-05, 'epoch': 39.68}\n",
            "{'loss': 0.0848, 'learning_rate': 1.2048387096774194e-05, 'epoch': 39.76}\n",
            "{'loss': 0.133, 'learning_rate': 1.203225806451613e-05, 'epoch': 39.84}\n",
            " 40% 4950/12400 [2:44:58<3:45:59,  1.82s/it]{'loss': 0.1925, 'learning_rate': 1.2016129032258067e-05, 'epoch': 39.92}\n",
            "{'loss': 0.1267, 'learning_rate': 1.2e-05, 'epoch': 40.0}\n",
            " 40% 4960/12400 [2:45:15<2:55:02,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 01:13:59,864 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:13:59,864 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:13:59,864 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5907295942306519, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1171, 'eval_samples_per_second': 24.021, 'eval_steps_per_second': 1.536, 'epoch': 40.0}\n",
            " 40% 4960/12400 [2:45:24<2:55:02,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:14:08,983 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-4960\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:14:08,986 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-4960/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:14:12,605 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-4960/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:14:12,605 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-4960/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:14:22,142 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4712] due to args.save_total_limit\n",
            "{'loss': 0.1151, 'learning_rate': 1.1983870967741937e-05, 'epoch': 40.08}\n",
            " 40% 4980/12400 [2:46:14<3:50:45,  1.87s/it]{'loss': 0.1417, 'learning_rate': 1.1967741935483873e-05, 'epoch': 40.16}\n",
            "{'loss': 0.0602, 'learning_rate': 1.1951612903225806e-05, 'epoch': 40.24}\n",
            "{'loss': 0.116, 'learning_rate': 1.1935483870967743e-05, 'epoch': 40.32}\n",
            "{'loss': 0.0535, 'learning_rate': 1.1919354838709679e-05, 'epoch': 40.4}\n",
            "{'loss': 0.1002, 'learning_rate': 1.1903225806451616e-05, 'epoch': 40.48}\n",
            "{'loss': 0.1112, 'learning_rate': 1.188709677419355e-05, 'epoch': 40.56}\n",
            "{'loss': 0.1011, 'learning_rate': 1.1870967741935484e-05, 'epoch': 40.65}\n",
            " 41% 5050/12400 [2:48:22<3:42:54,  1.82s/it]{'loss': 0.1225, 'learning_rate': 1.1854838709677421e-05, 'epoch': 40.73}\n",
            "{'loss': 0.0975, 'learning_rate': 1.1838709677419355e-05, 'epoch': 40.81}\n",
            "{'loss': 0.0879, 'learning_rate': 1.1822580645161292e-05, 'epoch': 40.89}\n",
            " 41% 5080/12400 [2:49:17<3:42:16,  1.82s/it]{'loss': 0.0526, 'learning_rate': 1.1806451612903227e-05, 'epoch': 40.97}\n",
            " 41% 5084/12400 [2:49:23<2:52:58,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:18:07,783 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:18:07,783 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:18:07,783 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5591571927070618, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.1, 'eval_samples_per_second': 24.066, 'eval_steps_per_second': 1.538, 'epoch': 41.0}\n",
            " 41% 5084/12400 [2:49:32<2:52:58,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:18:16,885 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5084\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:18:16,887 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5084/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:18:20,377 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5084/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:18:20,378 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5084/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:18:30,048 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4836] due to args.save_total_limit\n",
            " 41% 5090/12400 [2:49:56<5:52:56,  2.90s/it]{'loss': 0.1176, 'learning_rate': 1.1790322580645161e-05, 'epoch': 41.05}\n",
            "{'loss': 0.1464, 'learning_rate': 1.1774193548387098e-05, 'epoch': 41.13}\n",
            "{'loss': 0.1226, 'learning_rate': 1.1758064516129033e-05, 'epoch': 41.21}\n",
            "{'loss': 0.0387, 'learning_rate': 1.1741935483870967e-05, 'epoch': 41.29}\n",
            "                                            {'loss': 0.0575, 'learning_rate': 1.1725806451612904e-05, 'epoch': 41.37}\n",
            " 41% 5140/12400 [2:51:28<3:40:30,  1.82s/it]{'loss': 0.0157, 'learning_rate': 1.170967741935484e-05, 'epoch': 41.45}\n",
            "{'loss': 0.0164, 'learning_rate': 1.1693548387096776e-05, 'epoch': 41.53}\n",
            "{'loss': 0.128, 'learning_rate': 1.167741935483871e-05, 'epoch': 41.61}\n",
            "{'loss': 0.1322, 'learning_rate': 1.1661290322580645e-05, 'epoch': 41.69}\n",
            "{'loss': 0.064, 'learning_rate': 1.1645161290322582e-05, 'epoch': 41.77}\n",
            " 42% 5190/12400 [2:53:00<3:39:28,  1.83s/it]{'loss': 0.1415, 'learning_rate': 1.1629032258064516e-05, 'epoch': 41.85}\n",
            "{'loss': 0.0937, 'learning_rate': 1.1612903225806453e-05, 'epoch': 41.94}\n",
            " 42% 5208/12400 [2:53:32<2:50:14,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:22:16,236 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:22:16,236 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:22:16,236 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "{'eval_loss': 0.5173339247703552, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.0814, 'eval_samples_per_second': 24.115, 'eval_steps_per_second': 1.542, 'epoch': 42.0}\n",
            "\n",
            " 42% 5208/12400 [2:53:41<2:50:14,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:22:25,320 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5208\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:22:25,322 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5208/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:22:28,617 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5208/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:22:28,618 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5208/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:22:38,363 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4588] due to args.save_total_limit\n",
            "{'loss': 0.0723, 'learning_rate': 1.1596774193548388e-05, 'epoch': 42.02}\n",
            "{'loss': 0.0614, 'learning_rate': 1.1580645161290322e-05, 'epoch': 42.1}\n",
            "{'loss': 0.1212, 'learning_rate': 1.1564516129032259e-05, 'epoch': 42.18}\n",
            " 42% 5240/12400 [2:54:53<3:37:38,  1.82s/it]{'loss': 0.137, 'learning_rate': 1.1548387096774194e-05, 'epoch': 42.26}\n",
            " 42% 5250/12400 [2:55:11<3:35:45,  1.81s/it]{'loss': 0.0552, 'learning_rate': 1.1532258064516131e-05, 'epoch': 42.34}\n",
            " 42% 5260/12400 [2:55:29<3:35:56,  1.81s/it]{'loss': 0.0578, 'learning_rate': 1.1516129032258065e-05, 'epoch': 42.42}\n",
            "{'loss': 0.0546, 'learning_rate': 1.15e-05, 'epoch': 42.5}\n",
            "{'loss': 0.1219, 'learning_rate': 1.1483870967741937e-05, 'epoch': 42.58}\n",
            "{'loss': 0.0595, 'learning_rate': 1.1467741935483872e-05, 'epoch': 42.66}\n",
            " 43% 5300/12400 [2:56:42<3:48:39,  1.93s/it]{'loss': 0.1409, 'learning_rate': 1.1451612903225808e-05, 'epoch': 42.74}\n",
            " 43% 5310/12400 [2:57:00<3:35:30,  1.82s/it]{'loss': 0.188, 'learning_rate': 1.1435483870967743e-05, 'epoch': 42.82}\n",
            "{'loss': 0.1304, 'learning_rate': 1.1419354838709678e-05, 'epoch': 42.9}\n",
            " 43% 5330/12400 [2:57:37<3:34:48,  1.82s/it]{'loss': 0.1225, 'learning_rate': 1.1403225806451614e-05, 'epoch': 42.98}\n",
            " 43% 5332/12400 [2:57:39<2:47:10,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:26:23,881 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:26:23,881 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:26:23,881 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.98it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.11it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.83it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.70it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 43% 5332/12400 [2:57:48<2:47:10,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A{'eval_loss': 0.5524850487709045, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1361, 'eval_samples_per_second': 23.971, 'eval_steps_per_second': 1.532, 'epoch': 43.0}\n",
            "[INFO|trainer.py:2213] 2022-05-04 01:26:33,019 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5332\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:26:33,021 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5332/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:26:36,525 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5332/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:26:36,525 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5332/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:26:46,323 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-4960] due to args.save_total_limit\n",
            "{'loss': 0.0986, 'learning_rate': 1.1387096774193549e-05, 'epoch': 43.06}\n",
            "{'loss': 0.0804, 'learning_rate': 1.1370967741935486e-05, 'epoch': 43.15}\n",
            " 43% 5360/12400 [2:58:53<3:35:11,  1.83s/it]{'loss': 0.0321, 'learning_rate': 1.1354838709677421e-05, 'epoch': 43.23}\n",
            " 43% 5370/12400 [2:59:11<3:32:16,  1.81s/it]{'loss': 0.0789, 'learning_rate': 1.1338709677419355e-05, 'epoch': 43.31}\n",
            " 43% 5380/12400 [2:59:29<3:32:09,  1.81s/it]{'loss': 0.1456, 'learning_rate': 1.1322580645161292e-05, 'epoch': 43.39}\n",
            "{'loss': 0.0659, 'learning_rate': 1.1306451612903227e-05, 'epoch': 43.47}\n",
            " 44% 5400/12400 [3:00:06<3:46:49,  1.94s/it]{'loss': 0.1147, 'learning_rate': 1.1290322580645164e-05, 'epoch': 43.55}\n",
            "{'loss': 0.139, 'learning_rate': 1.1274193548387098e-05, 'epoch': 43.63}\n",
            "                                            {'loss': 0.1514, 'learning_rate': 1.1258064516129033e-05, 'epoch': 43.71}\n",
            "{'loss': 0.0996, 'learning_rate': 1.124193548387097e-05, 'epoch': 43.79}\n",
            " 44% 5440/12400 [3:01:19<3:31:40,  1.82s/it]{'loss': 0.0815, 'learning_rate': 1.1225806451612904e-05, 'epoch': 43.87}\n",
            " 44% 5450/12400 [3:01:38<3:31:43,  1.83s/it]{'loss': 0.0314, 'learning_rate': 1.1209677419354839e-05, 'epoch': 43.95}\n",
            " 44% 5456/12400 [3:01:47<2:43:37,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 01:30:31,904 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:30:31,904 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:30:31,904 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 44% 5456/12400 [3:01:56<2:43:37,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A{'eval_loss': 0.602924644947052, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.0901, 'eval_samples_per_second': 24.092, 'eval_steps_per_second': 1.54, 'epoch': 44.0}\n",
            "\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:30:40,996 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5456\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:30:41,000 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5456/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:30:44,471 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5456/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:30:44,472 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5456/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:30:54,027 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5084] due to args.save_total_limit\n",
            " 44% 5460/12400 [3:02:17<7:41:57,  3.99s/it]{'loss': 0.0296, 'learning_rate': 1.1193548387096776e-05, 'epoch': 44.03}\n",
            "{'loss': 0.0394, 'learning_rate': 1.117741935483871e-05, 'epoch': 44.11}\n",
            "{'loss': 0.0688, 'learning_rate': 1.1161290322580647e-05, 'epoch': 44.19}\n",
            "{'loss': 0.1396, 'learning_rate': 1.1145161290322582e-05, 'epoch': 44.27}\n",
            "{'loss': 0.0832, 'learning_rate': 1.1129032258064516e-05, 'epoch': 44.35}\n",
            " 44% 5510/12400 [3:03:48<3:28:45,  1.82s/it]{'loss': 0.1185, 'learning_rate': 1.1112903225806453e-05, 'epoch': 44.44}\n",
            " 45% 5520/12400 [3:04:07<3:29:32,  1.83s/it]{'loss': 0.1053, 'learning_rate': 1.1096774193548388e-05, 'epoch': 44.52}\n",
            "{'loss': 0.1204, 'learning_rate': 1.1080645161290325e-05, 'epoch': 44.6}\n",
            " 45% 5540/12400 [3:04:43<3:28:11,  1.82s/it]{'loss': 0.1617, 'learning_rate': 1.1064516129032258e-05, 'epoch': 44.68}\n",
            "{'loss': 0.1209, 'learning_rate': 1.1048387096774194e-05, 'epoch': 44.76}\n",
            "                                            {'loss': 0.0308, 'learning_rate': 1.103225806451613e-05, 'epoch': 44.84}\n",
            " 45% 5570/12400 [3:05:38<3:27:26,  1.82s/it]{'loss': 0.0135, 'learning_rate': 1.1016129032258064e-05, 'epoch': 44.92}\n",
            " 45% 5580/12400 [3:05:55<2:40:44,  1.41s/it]{'loss': 0.0665, 'learning_rate': 1.1000000000000001e-05, 'epoch': 45.0}\n",
            "[INFO|trainer.py:2463] 2022-05-04 01:34:39,361 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:34:39,361 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:34:39,361 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "{'eval_loss': 0.6028414368629456, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.1246, 'eval_samples_per_second': 24.001, 'eval_steps_per_second': 1.534, 'epoch': 45.0}\n",
            "\n",
            " 45% 5580/12400 [3:06:04<2:40:44,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:34:48,488 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5580\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:34:48,491 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5580/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:34:52,080 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5580/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:34:52,081 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5580/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:35:01,921 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5332] due to args.save_total_limit\n",
            " 45% 5590/12400 [3:06:36<3:56:42,  2.09s/it]{'loss': 0.1314, 'learning_rate': 1.0983870967741937e-05, 'epoch': 45.08}\n",
            " 45% 5600/12400 [3:06:55<3:44:32,  1.98s/it]{'loss': 0.1243, 'learning_rate': 1.096774193548387e-05, 'epoch': 45.16}\n",
            "{'loss': 0.0485, 'learning_rate': 1.0951612903225807e-05, 'epoch': 45.24}\n",
            "{'loss': 0.0384, 'learning_rate': 1.0935483870967743e-05, 'epoch': 45.32}\n",
            " 45% 5630/12400 [3:07:49<3:24:13,  1.81s/it]{'loss': 0.0944, 'learning_rate': 1.091935483870968e-05, 'epoch': 45.4}\n",
            "{'loss': 0.0645, 'learning_rate': 1.0903225806451613e-05, 'epoch': 45.48}\n",
            " 46% 5650/12400 [3:08:26<3:25:22,  1.83s/it]{'loss': 0.0827, 'learning_rate': 1.0887096774193549e-05, 'epoch': 45.56}\n",
            "{'loss': 0.0171, 'learning_rate': 1.0870967741935486e-05, 'epoch': 45.65}\n",
            "{'loss': 0.1014, 'learning_rate': 1.085483870967742e-05, 'epoch': 45.73}\n",
            "{'loss': 0.0731, 'learning_rate': 1.0838709677419356e-05, 'epoch': 45.81}\n",
            "{'loss': 0.0542, 'learning_rate': 1.0822580645161292e-05, 'epoch': 45.89}\n",
            " 46% 5700/12400 [3:09:57<3:36:50,  1.94s/it]{'loss': 0.0417, 'learning_rate': 1.0806451612903225e-05, 'epoch': 45.97}\n",
            " 46% 5704/12400 [3:10:03<2:41:25,  1.45s/it][INFO|trainer.py:2463] 2022-05-04 01:38:47,768 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:38:47,769 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:38:47,769 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.00it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5804633498191833, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.1053, 'eval_samples_per_second': 24.052, 'eval_steps_per_second': 1.538, 'epoch': 46.0}\n",
            " 46% 5704/12400 [3:10:12<2:41:25,  1.45s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:38:56,876 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5704\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:38:56,878 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5704/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:39:00,581 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5704/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:39:00,581 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5704/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:39:10,272 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5456] due to args.save_total_limit\n",
            "{'loss': 0.0614, 'learning_rate': 1.0790322580645162e-05, 'epoch': 46.05}\n",
            "{'loss': 0.0881, 'learning_rate': 1.0774193548387097e-05, 'epoch': 46.13}\n",
            "{'loss': 0.2091, 'learning_rate': 1.0758064516129034e-05, 'epoch': 46.21}\n",
            " 46% 5740/12400 [3:11:32<3:21:51,  1.82s/it]{'loss': 0.0425, 'learning_rate': 1.0741935483870968e-05, 'epoch': 46.29}\n",
            " 46% 5750/12400 [3:11:50<3:20:12,  1.81s/it]{'loss': 0.0653, 'learning_rate': 1.0725806451612903e-05, 'epoch': 46.37}\n",
            "{'loss': 0.1127, 'learning_rate': 1.070967741935484e-05, 'epoch': 46.45}\n",
            "{'loss': 0.1208, 'learning_rate': 1.0693548387096776e-05, 'epoch': 46.53}\n",
            " 47% 5780/12400 [3:12:45<3:21:03,  1.82s/it]{'loss': 0.0264, 'learning_rate': 1.067741935483871e-05, 'epoch': 46.61}\n",
            "{'loss': 0.0773, 'learning_rate': 1.0661290322580646e-05, 'epoch': 46.69}\n",
            " 47% 5800/12400 [3:13:21<3:33:39,  1.94s/it]{'loss': 0.1024, 'learning_rate': 1.0645161290322582e-05, 'epoch': 46.77}\n",
            " 47% 5810/12400 [3:13:40<3:20:45,  1.83s/it]{'loss': 0.1115, 'learning_rate': 1.0629032258064517e-05, 'epoch': 46.85}\n",
            "{'loss': 0.0754, 'learning_rate': 1.0612903225806452e-05, 'epoch': 46.94}\n",
            " 47% 5828/12400 [3:14:11<2:34:40,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 01:42:55,814 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:42:55,815 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:42:55,815 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.54it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "{'eval_loss': 0.5937331318855286, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.0463, 'eval_samples_per_second': 24.209, 'eval_steps_per_second': 1.548, 'epoch': 47.0}\n",
            "\n",
            " 47% 5828/12400 [3:14:20<2:34:40,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:43:04,863 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5828\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:43:04,865 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5828/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:43:08,561 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5828/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:43:08,562 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5828/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:43:18,429 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5580] due to args.save_total_limit\n",
            " 47% 5830/12400 [3:14:38<11:41:58,  6.41s/it]{'loss': 0.069, 'learning_rate': 1.0596774193548388e-05, 'epoch': 47.02}\n",
            "{'loss': 0.0655, 'learning_rate': 1.0580645161290325e-05, 'epoch': 47.1}\n",
            "{'loss': 0.0513, 'learning_rate': 1.0564516129032258e-05, 'epoch': 47.18}\n",
            " 47% 5860/12400 [3:15:33<3:18:50,  1.82s/it]{'loss': 0.0864, 'learning_rate': 1.0548387096774195e-05, 'epoch': 47.26}\n",
            " 47% 5870/12400 [3:15:51<3:17:05,  1.81s/it]{'loss': 0.0678, 'learning_rate': 1.053225806451613e-05, 'epoch': 47.34}\n",
            "{'loss': 0.066, 'learning_rate': 1.0516129032258064e-05, 'epoch': 47.42}\n",
            "{'loss': 0.0615, 'learning_rate': 1.0500000000000001e-05, 'epoch': 47.5}\n",
            "{'loss': 0.1006, 'learning_rate': 1.0483870967741936e-05, 'epoch': 47.58}\n",
            " 48% 5910/12400 [3:17:04<3:17:28,  1.83s/it]{'loss': 0.1101, 'learning_rate': 1.0467741935483873e-05, 'epoch': 47.66}\n",
            "{'loss': 0.0861, 'learning_rate': 1.0451612903225807e-05, 'epoch': 47.74}\n",
            "{'loss': 0.1135, 'learning_rate': 1.0435483870967742e-05, 'epoch': 47.82}\n",
            "                                            {'loss': 0.0859, 'learning_rate': 1.041935483870968e-05, 'epoch': 47.9}\n",
            " 48% 5950/12400 [3:18:17<3:16:28,  1.83s/it]{'loss': 0.0502, 'learning_rate': 1.0403225806451613e-05, 'epoch': 47.98}\n",
            " 48% 5952/12400 [3:18:19<2:33:14,  1.43s/it][INFO|trainer.py:2463] 2022-05-04 01:47:04,091 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:47:04,091 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:47:04,091 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.00it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6800532341003418, 'eval_accuracy': 0.821917808219178, 'eval_runtime': 9.104, 'eval_samples_per_second': 24.055, 'eval_steps_per_second': 1.538, 'epoch': 48.0}\n",
            " 48% 5952/12400 [3:18:29<2:33:14,  1.43s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:47:13,197 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-5952\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:47:13,199 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-5952/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:47:16,663 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-5952/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:47:16,664 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-5952/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:47:26,310 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5704] due to args.save_total_limit\n",
            "{'loss': 0.0839, 'learning_rate': 1.038709677419355e-05, 'epoch': 48.06}\n",
            "{'loss': 0.0612, 'learning_rate': 1.0370967741935485e-05, 'epoch': 48.15}\n",
            " 48% 5980/12400 [3:19:33<3:16:14,  1.83s/it]{'loss': 0.0581, 'learning_rate': 1.0354838709677419e-05, 'epoch': 48.23}\n",
            "{'loss': 0.0548, 'learning_rate': 1.0338709677419356e-05, 'epoch': 48.31}\n",
            "                                            {'loss': 0.0448, 'learning_rate': 1.0322580645161291e-05, 'epoch': 48.39}\n",
            "{'loss': 0.0481, 'learning_rate': 1.0306451612903228e-05, 'epoch': 48.47}\n",
            "{'loss': 0.1083, 'learning_rate': 1.0290322580645162e-05, 'epoch': 48.55}\n",
            "{'loss': 0.124, 'learning_rate': 1.0274193548387097e-05, 'epoch': 48.63}\n",
            "{'loss': 0.0569, 'learning_rate': 1.0258064516129034e-05, 'epoch': 48.71}\n",
            " 49% 6050/12400 [3:21:41<3:12:47,  1.82s/it]{'loss': 0.053, 'learning_rate': 1.0241935483870968e-05, 'epoch': 48.79}\n",
            "                                            {'loss': 0.1319, 'learning_rate': 1.0225806451612903e-05, 'epoch': 48.87}\n",
            "{'loss': 0.0977, 'learning_rate': 1.020967741935484e-05, 'epoch': 48.95}\n",
            " 49% 6076/12400 [3:22:27<2:29:23,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:51:11,742 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:51:11,742 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:51:11,742 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 49% 6076/12400 [3:22:36<2:29:23,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A{'eval_loss': 0.6650868654251099, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.0723, 'eval_samples_per_second': 24.139, 'eval_steps_per_second': 1.543, 'epoch': 49.0}\n",
            "[INFO|trainer.py:2213] 2022-05-04 01:51:20,816 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6076\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:51:20,818 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6076/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:51:24,606 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6076/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:51:24,607 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6076/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:51:34,098 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5828] due to args.save_total_limit\n",
            " 49% 6080/12400 [3:22:57<7:04:13,  4.03s/it]{'loss': 0.0731, 'learning_rate': 1.0193548387096774e-05, 'epoch': 49.03}\n",
            "{'loss': 0.1039, 'learning_rate': 1.017741935483871e-05, 'epoch': 49.11}\n",
            "                                            {'loss': 0.0288, 'learning_rate': 1.0161290322580646e-05, 'epoch': 49.19}\n",
            "{'loss': 0.02, 'learning_rate': 1.014516129032258e-05, 'epoch': 49.27}\n",
            "{'loss': 0.046, 'learning_rate': 1.0129032258064517e-05, 'epoch': 49.35}\n",
            " 49% 6130/12400 [3:24:29<3:09:44,  1.82s/it]{'loss': 0.129, 'learning_rate': 1.0112903225806452e-05, 'epoch': 49.44}\n",
            "{'loss': 0.0691, 'learning_rate': 1.0096774193548389e-05, 'epoch': 49.52}\n",
            "{'loss': 0.127, 'learning_rate': 1.0080645161290323e-05, 'epoch': 49.6}\n",
            " 50% 6160/12400 [3:25:23<3:08:40,  1.81s/it]{'loss': 0.1038, 'learning_rate': 1.0064516129032258e-05, 'epoch': 49.68}\n",
            " 50% 6170/12400 [3:25:42<3:09:09,  1.82s/it]{'loss': 0.0944, 'learning_rate': 1.0048387096774195e-05, 'epoch': 49.76}\n",
            "{'loss': 0.0774, 'learning_rate': 1.003225806451613e-05, 'epoch': 49.84}\n",
            " 50% 6190/12400 [3:26:18<3:08:37,  1.82s/it]{'loss': 0.0616, 'learning_rate': 1.0016129032258066e-05, 'epoch': 49.92}\n",
            "{'loss': 0.0234, 'learning_rate': 1e-05, 'epoch': 50.0}\n",
            " 50% 6200/12400 [3:26:35<2:40:48,  1.56s/it][INFO|trainer.py:2463] 2022-05-04 01:55:20,029 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:55:20,029 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:55:20,029 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6175013184547424, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1261, 'eval_samples_per_second': 23.997, 'eval_steps_per_second': 1.534, 'epoch': 50.0}\n",
            " 50% 6200/12400 [3:26:44<2:40:48,  1.56s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:55:29,157 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6200\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:55:29,159 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6200/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:55:32,844 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6200/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:55:32,845 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6200/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:55:42,981 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-5952] due to args.save_total_limit\n",
            " 50% 6210/12400 [3:27:17<3:35:32,  2.09s/it]{'loss': 0.1497, 'learning_rate': 9.983870967741936e-06, 'epoch': 50.08}\n",
            " 50% 6220/12400 [3:27:35<3:11:49,  1.86s/it]{'loss': 0.0163, 'learning_rate': 9.967741935483871e-06, 'epoch': 50.16}\n",
            "{'loss': 0.041, 'learning_rate': 9.951612903225807e-06, 'epoch': 50.24}\n",
            " 50% 6240/12400 [3:28:12<3:06:02,  1.81s/it]{'loss': 0.0561, 'learning_rate': 9.935483870967742e-06, 'epoch': 50.32}\n",
            " 50% 6250/12400 [3:28:30<3:06:11,  1.82s/it]{'loss': 0.0422, 'learning_rate': 9.919354838709679e-06, 'epoch': 50.4}\n",
            "{'loss': 0.0956, 'learning_rate': 9.903225806451614e-06, 'epoch': 50.48}\n",
            " 51% 6270/12400 [3:29:06<3:06:43,  1.83s/it]{'loss': 0.0982, 'learning_rate': 9.88709677419355e-06, 'epoch': 50.56}\n",
            "{'loss': 0.086, 'learning_rate': 9.870967741935485e-06, 'epoch': 50.65}\n",
            "{'loss': 0.067, 'learning_rate': 9.85483870967742e-06, 'epoch': 50.73}\n",
            " 51% 6300/12400 [3:30:01<3:17:16,  1.94s/it]{'loss': 0.0921, 'learning_rate': 9.838709677419356e-06, 'epoch': 50.81}\n",
            "{'loss': 0.123, 'learning_rate': 9.822580645161291e-06, 'epoch': 50.89}\n",
            "{'loss': 0.08, 'learning_rate': 9.806451612903226e-06, 'epoch': 50.97}\n",
            " 51% 6324/12400 [3:30:44<2:23:25,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 01:59:28,430 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 01:59:28,430 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 01:59:28,430 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "                                   {'eval_loss': 0.624687671661377, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.0981, 'eval_samples_per_second': 24.071, 'eval_steps_per_second': 1.539, 'epoch': 51.0}\n",
            " 51% 6324/12400 [3:30:53<2:23:25,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 01:59:37,530 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6324\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 01:59:37,532 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6324/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 01:59:41,062 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6324/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 01:59:41,063 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6324/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 01:59:50,480 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6076] due to args.save_total_limit\n",
            "{'loss': 0.0802, 'learning_rate': 9.790322580645162e-06, 'epoch': 51.05}\n",
            "{'loss': 0.0389, 'learning_rate': 9.774193548387097e-06, 'epoch': 51.13}\n",
            " 51% 6350/12400 [3:31:54<3:06:32,  1.85s/it]{'loss': 0.1754, 'learning_rate': 9.758064516129034e-06, 'epoch': 51.21}\n",
            "{'loss': 0.0257, 'learning_rate': 9.74193548387097e-06, 'epoch': 51.29}\n",
            "{'loss': 0.0705, 'learning_rate': 9.725806451612903e-06, 'epoch': 51.37}\n",
            " 51% 6380/12400 [3:32:48<3:02:24,  1.82s/it]{'loss': 0.0225, 'learning_rate': 9.70967741935484e-06, 'epoch': 51.45}\n",
            "{'loss': 0.067, 'learning_rate': 9.693548387096775e-06, 'epoch': 51.53}\n",
            "                                            {'loss': 0.0162, 'learning_rate': 9.67741935483871e-06, 'epoch': 51.61}\n",
            " 52% 6410/12400 [3:33:43<3:01:46,  1.82s/it]{'loss': 0.0969, 'learning_rate': 9.661290322580646e-06, 'epoch': 51.69}\n",
            "{'loss': 0.0825, 'learning_rate': 9.645161290322581e-06, 'epoch': 51.77}\n",
            "{'loss': 0.0244, 'learning_rate': 9.629032258064516e-06, 'epoch': 51.85}\n",
            " 52% 6440/12400 [3:34:38<3:01:00,  1.82s/it]{'loss': 0.013, 'learning_rate': 9.612903225806453e-06, 'epoch': 51.94}\n",
            " 52% 6448/12400 [3:34:51<2:20:23,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:03:36,061 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:03:36,061 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:03:36,061 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.95it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.11it/s]\u001b[A\n",
            " 29% 4/14 [00:02<00:05,  1.83it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.70it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:04<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "{'eval_loss': 0.6189457178115845, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.1252, 'eval_samples_per_second': 23.999, 'eval_steps_per_second': 1.534, 'epoch': 52.0}\n",
            " 52% 6448/12400 [3:35:01<2:20:23,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:03:45,188 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6448\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:03:45,190 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6448/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:03:48,591 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6448/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:03:48,592 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6448/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:03:58,222 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6200] due to args.save_total_limit\n",
            " 52% 6450/12400 [3:35:17<10:26:15,  6.32s/it]{'loss': 0.0596, 'learning_rate': 9.596774193548389e-06, 'epoch': 52.02}\n",
            "{'loss': 0.0888, 'learning_rate': 9.580645161290322e-06, 'epoch': 52.1}\n",
            "{'loss': 0.0427, 'learning_rate': 9.56451612903226e-06, 'epoch': 52.18}\n",
            " 52% 6480/12400 [3:36:13<3:00:00,  1.82s/it]{'loss': 0.1349, 'learning_rate': 9.548387096774195e-06, 'epoch': 52.26}\n",
            " 52% 6490/12400 [3:36:31<2:58:30,  1.81s/it]{'loss': 0.0528, 'learning_rate': 9.53225806451613e-06, 'epoch': 52.34}\n",
            "{'loss': 0.0354, 'learning_rate': 9.516129032258065e-06, 'epoch': 52.42}\n",
            "{'loss': 0.1596, 'learning_rate': 9.5e-06, 'epoch': 52.5}\n",
            " 53% 6520/12400 [3:37:26<2:59:04,  1.83s/it]{'loss': 0.0357, 'learning_rate': 9.483870967741936e-06, 'epoch': 52.58}\n",
            " 53% 6530/12400 [3:37:44<2:57:39,  1.82s/it]{'loss': 0.0839, 'learning_rate': 9.467741935483871e-06, 'epoch': 52.66}\n",
            " 53% 6540/12400 [3:38:02<2:57:39,  1.82s/it]{'loss': 0.1089, 'learning_rate': 9.451612903225808e-06, 'epoch': 52.74}\n",
            "{'loss': 0.0906, 'learning_rate': 9.435483870967743e-06, 'epoch': 52.82}\n",
            "                                            {'loss': 0.084, 'learning_rate': 9.419354838709677e-06, 'epoch': 52.9}\n",
            "{'loss': 0.1085, 'learning_rate': 9.403225806451614e-06, 'epoch': 52.98}\n",
            " 53% 6572/12400 [3:38:59<2:17:57,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:07:43,844 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:07:43,844 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:07:43,844 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.54it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.52it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "{'eval_loss': 0.656372606754303, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.1356, 'eval_samples_per_second': 23.972, 'eval_steps_per_second': 1.532, 'epoch': 53.0}\n",
            " 53% 6572/12400 [3:39:08<2:17:57,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:07:52,982 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6572\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:07:52,983 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6572/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:07:56,365 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6572/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:07:56,366 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6572/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:08:05,978 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6324] due to args.save_total_limit\n",
            "{'loss': 0.0868, 'learning_rate': 9.38709677419355e-06, 'epoch': 53.06}\n",
            "{'loss': 0.0362, 'learning_rate': 9.370967741935485e-06, 'epoch': 53.15}\n",
            "{'loss': 0.1067, 'learning_rate': 9.35483870967742e-06, 'epoch': 53.23}\n",
            "{'loss': 0.0196, 'learning_rate': 9.338709677419355e-06, 'epoch': 53.31}\n",
            "{'loss': 0.0532, 'learning_rate': 9.32258064516129e-06, 'epoch': 53.39}\n",
            " 53% 6630/12400 [3:41:08<2:54:57,  1.82s/it]{'loss': 0.0427, 'learning_rate': 9.306451612903226e-06, 'epoch': 53.47}\n",
            " 54% 6640/12400 [3:41:26<2:55:07,  1.82s/it]{'loss': 0.0573, 'learning_rate': 9.290322580645163e-06, 'epoch': 53.55}\n",
            "{'loss': 0.1369, 'learning_rate': 9.274193548387097e-06, 'epoch': 53.63}\n",
            "{'loss': 0.0391, 'learning_rate': 9.258064516129034e-06, 'epoch': 53.71}\n",
            "{'loss': 0.0516, 'learning_rate': 9.241935483870969e-06, 'epoch': 53.79}\n",
            "{'loss': 0.0471, 'learning_rate': 9.225806451612904e-06, 'epoch': 53.87}\n",
            " 54% 6690/12400 [3:42:57<2:53:38,  1.82s/it]{'loss': 0.0849, 'learning_rate': 9.20967741935484e-06, 'epoch': 53.95}\n",
            " 54% 6696/12400 [3:43:07<2:14:28,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 02:11:51,498 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:11:51,498 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:11:51,498 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.7998244166374207, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.0984, 'eval_samples_per_second': 24.07, 'eval_steps_per_second': 1.539, 'epoch': 54.0}\n",
            " 54% 6696/12400 [3:43:16<2:14:28,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:12:00,598 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6696\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:12:00,600 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6696/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:12:04,068 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6696/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:12:04,069 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6696/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:12:13,753 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6448] due to args.save_total_limit\n",
            "{'loss': 0.0998, 'learning_rate': 9.193548387096775e-06, 'epoch': 54.03}\n",
            "{'loss': 0.0583, 'learning_rate': 9.17741935483871e-06, 'epoch': 54.11}\n",
            " 54% 6720/12400 [3:44:14<2:55:27,  1.85s/it]{'loss': 0.1679, 'learning_rate': 9.161290322580645e-06, 'epoch': 54.19}\n",
            " 54% 6730/12400 [3:44:32<2:51:54,  1.82s/it]{'loss': 0.113, 'learning_rate': 9.145161290322582e-06, 'epoch': 54.27}\n",
            "{'loss': 0.0759, 'learning_rate': 9.129032258064518e-06, 'epoch': 54.35}\n",
            " 54% 6750/12400 [3:45:08<2:51:08,  1.82s/it]{'loss': 0.0584, 'learning_rate': 9.112903225806451e-06, 'epoch': 54.44}\n",
            "                                            {'loss': 0.0633, 'learning_rate': 9.096774193548388e-06, 'epoch': 54.52}\n",
            "{'loss': 0.0228, 'learning_rate': 9.080645161290324e-06, 'epoch': 54.6}\n",
            " 55% 6780/12400 [3:46:03<2:49:50,  1.81s/it]{'loss': 0.0478, 'learning_rate': 9.064516129032259e-06, 'epoch': 54.68}\n",
            " 55% 6790/12400 [3:46:21<2:50:12,  1.82s/it]{'loss': 0.0779, 'learning_rate': 9.048387096774194e-06, 'epoch': 54.76}\n",
            "{'loss': 0.1521, 'learning_rate': 9.03225806451613e-06, 'epoch': 54.84}\n",
            "{'loss': 0.098, 'learning_rate': 9.016129032258065e-06, 'epoch': 54.92}\n",
            " 55% 6820/12400 [3:47:15<2:11:40,  1.42s/it]{'loss': 0.0471, 'learning_rate': 9e-06, 'epoch': 55.0}\n",
            " 55% 6820/12400 [3:47:15<2:11:40,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:15:59,744 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:15:59,744 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:15:59,744 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "                                   {'eval_loss': 0.573469340801239, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.1049, 'eval_samples_per_second': 24.053, 'eval_steps_per_second': 1.538, 'epoch': 55.0}\n",
            " 55% 6820/12400 [3:47:24<2:11:40,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:16:08,851 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6820\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:16:08,853 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6820/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:16:12,432 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6820/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:16:12,433 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6820/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:16:22,080 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6572] due to args.save_total_limit\n",
            " 55% 6830/12400 [3:47:56<3:13:17,  2.08s/it]{'loss': 0.0494, 'learning_rate': 8.983870967741937e-06, 'epoch': 55.08}\n",
            "{'loss': 0.0433, 'learning_rate': 8.967741935483871e-06, 'epoch': 55.16}\n",
            "                                            {'loss': 0.0442, 'learning_rate': 8.951612903225806e-06, 'epoch': 55.24}\n",
            " 55% 6860/12400 [3:48:51<2:47:11,  1.81s/it]{'loss': 0.0583, 'learning_rate': 8.935483870967743e-06, 'epoch': 55.32}\n",
            "{'loss': 0.1205, 'learning_rate': 8.919354838709678e-06, 'epoch': 55.4}\n",
            "{'loss': 0.0665, 'learning_rate': 8.903225806451614e-06, 'epoch': 55.48}\n",
            " 56% 6890/12400 [3:49:46<2:47:21,  1.82s/it]{'loss': 0.0738, 'learning_rate': 8.887096774193549e-06, 'epoch': 55.56}\n",
            " 56% 6900/12400 [3:50:04<2:57:22,  1.93s/it]{'loss': 0.0381, 'learning_rate': 8.870967741935484e-06, 'epoch': 55.65}\n",
            " 56% 6910/12400 [3:50:22<2:46:35,  1.82s/it]{'loss': 0.0553, 'learning_rate': 8.85483870967742e-06, 'epoch': 55.73}\n",
            "{'loss': 0.0496, 'learning_rate': 8.838709677419357e-06, 'epoch': 55.81}\n",
            "                                            {'loss': 0.0118, 'learning_rate': 8.82258064516129e-06, 'epoch': 55.89}\n",
            " 56% 6940/12400 [3:51:17<2:45:45,  1.82s/it]{'loss': 0.0197, 'learning_rate': 8.806451612903226e-06, 'epoch': 55.97}\n",
            " 56% 6944/12400 [3:51:23<2:08:52,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:20:07,699 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:20:07,700 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:20:07,700 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5794802308082581, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.0776, 'eval_samples_per_second': 24.125, 'eval_steps_per_second': 1.542, 'epoch': 56.0}\n",
            " 56% 6944/12400 [3:51:32<2:08:52,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:20:16,779 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-6944\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:20:16,781 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-6944/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:20:20,031 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-6944/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:20:20,032 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-6944/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:20:29,857 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6696] due to args.save_total_limit\n",
            " 56% 6950/12400 [3:51:56<4:22:15,  2.89s/it]{'loss': 0.042, 'learning_rate': 8.790322580645163e-06, 'epoch': 56.05}\n",
            " 56% 6960/12400 [3:52:15<2:49:44,  1.87s/it]{'loss': 0.0518, 'learning_rate': 8.774193548387098e-06, 'epoch': 56.13}\n",
            "{'loss': 0.0393, 'learning_rate': 8.758064516129033e-06, 'epoch': 56.21}\n",
            " 56% 6980/12400 [3:52:51<2:44:28,  1.82s/it]{'loss': 0.049, 'learning_rate': 8.741935483870969e-06, 'epoch': 56.29}\n",
            " 56% 6990/12400 [3:53:10<2:43:06,  1.81s/it]{'loss': 0.0422, 'learning_rate': 8.725806451612904e-06, 'epoch': 56.37}\n",
            "{'loss': 0.0515, 'learning_rate': 8.70967741935484e-06, 'epoch': 56.45}\n",
            "{'loss': 0.0646, 'learning_rate': 8.693548387096775e-06, 'epoch': 56.53}\n",
            " 57% 7020/12400 [3:54:05<2:43:35,  1.82s/it]{'loss': 0.0377, 'learning_rate': 8.677419354838712e-06, 'epoch': 56.61}\n",
            "{'loss': 0.0122, 'learning_rate': 8.661290322580645e-06, 'epoch': 56.69}\n",
            " 57% 7040/12400 [3:54:41<2:42:12,  1.82s/it]{'loss': 0.0777, 'learning_rate': 8.64516129032258e-06, 'epoch': 56.77}\n",
            " 57% 7050/12400 [3:54:59<2:42:34,  1.82s/it]{'loss': 0.0526, 'learning_rate': 8.629032258064517e-06, 'epoch': 56.85}\n",
            " 57% 7060/12400 [3:55:18<2:42:36,  1.83s/it]{'loss': 0.0661, 'learning_rate': 8.612903225806453e-06, 'epoch': 56.94}\n",
            " 57% 7068/12400 [3:55:31<2:06:01,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:24:15,567 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:24:15,568 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:24:15,568 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6394926309585571, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.0903, 'eval_samples_per_second': 24.092, 'eval_steps_per_second': 1.54, 'epoch': 57.0}\n",
            " 57% 7068/12400 [3:55:40<2:06:01,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:24:24,660 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7068\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:24:24,663 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7068/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:24:28,347 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7068/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:24:28,347 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7068/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:24:38,037 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6820] due to args.save_total_limit\n",
            "{'loss': 0.0363, 'learning_rate': 8.596774193548388e-06, 'epoch': 57.02}\n",
            "{'loss': 0.0898, 'learning_rate': 8.580645161290323e-06, 'epoch': 57.1}\n",
            "{'loss': 0.03, 'learning_rate': 8.564516129032259e-06, 'epoch': 57.18}\n",
            " 57% 7100/12400 [3:56:53<2:51:23,  1.94s/it]{'loss': 0.0351, 'learning_rate': 8.548387096774194e-06, 'epoch': 57.26}\n",
            "{'loss': 0.0669, 'learning_rate': 8.53225806451613e-06, 'epoch': 57.34}\n",
            " 57% 7120/12400 [3:57:29<2:39:41,  1.81s/it]{'loss': 0.0602, 'learning_rate': 8.516129032258065e-06, 'epoch': 57.42}\n",
            "{'loss': 0.0236, 'learning_rate': 8.5e-06, 'epoch': 57.5}\n",
            "{'loss': 0.0081, 'learning_rate': 8.483870967741937e-06, 'epoch': 57.58}\n",
            "{'loss': 0.0137, 'learning_rate': 8.467741935483872e-06, 'epoch': 57.66}\n",
            " 58% 7160/12400 [3:58:42<2:38:32,  1.82s/it]{'loss': 0.0538, 'learning_rate': 8.451612903225808e-06, 'epoch': 57.74}\n",
            " 58% 7170/12400 [3:59:00<2:38:40,  1.82s/it]{'loss': 0.0557, 'learning_rate': 8.435483870967743e-06, 'epoch': 57.82}\n",
            "{'loss': 0.09, 'learning_rate': 8.419354838709678e-06, 'epoch': 57.9}\n",
            " 58% 7190/12400 [3:59:37<2:38:09,  1.82s/it]{'loss': 0.0115, 'learning_rate': 8.403225806451613e-06, 'epoch': 57.98}\n",
            " 58% 7192/12400 [3:59:39<2:03:11,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:28:23,581 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:28:23,581 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:28:23,581 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.591938853263855, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.0722, 'eval_samples_per_second': 24.14, 'eval_steps_per_second': 1.543, 'epoch': 58.0}\n",
            " 58% 7192/12400 [3:59:48<2:03:11,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:28:32,656 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7192\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:28:32,659 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7192/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:28:36,177 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7192/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:28:36,177 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7192/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:28:45,820 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-6944] due to args.save_total_limit\n",
            "{'loss': 0.0581, 'learning_rate': 8.387096774193549e-06, 'epoch': 58.06}\n",
            " 58% 7210/12400 [4:00:35<2:42:00,  1.87s/it]{'loss': 0.0486, 'learning_rate': 8.370967741935484e-06, 'epoch': 58.15}\n",
            " 58% 7220/12400 [4:00:53<2:38:48,  1.84s/it]{'loss': 0.0741, 'learning_rate': 8.35483870967742e-06, 'epoch': 58.23}\n",
            "{'loss': 0.0697, 'learning_rate': 8.338709677419355e-06, 'epoch': 58.31}\n",
            " 58% 7240/12400 [4:01:29<2:35:20,  1.81s/it]{'loss': 0.0574, 'learning_rate': 8.322580645161292e-06, 'epoch': 58.39}\n",
            " 58% 7250/12400 [4:01:48<2:36:27,  1.82s/it]{'loss': 0.0293, 'learning_rate': 8.306451612903227e-06, 'epoch': 58.47}\n",
            "{'loss': 0.0711, 'learning_rate': 8.29032258064516e-06, 'epoch': 58.55}\n",
            " 59% 7270/12400 [4:02:24<2:35:54,  1.82s/it]{'loss': 0.0881, 'learning_rate': 8.274193548387098e-06, 'epoch': 58.63}\n",
            "{'loss': 0.0321, 'learning_rate': 8.258064516129033e-06, 'epoch': 58.71}\n",
            "{'loss': 0.0907, 'learning_rate': 8.241935483870968e-06, 'epoch': 58.79}\n",
            "{'loss': 0.0435, 'learning_rate': 8.225806451612904e-06, 'epoch': 58.87}\n",
            " 59% 7310/12400 [4:03:38<2:35:31,  1.83s/it]{'loss': 0.0471, 'learning_rate': 8.209677419354839e-06, 'epoch': 58.95}\n",
            " 59% 7316/12400 [4:03:47<1:59:54,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:32:31,876 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:32:31,877 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:32:31,877 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 59% 7316/12400 [4:03:56<1:59:54,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]{'eval_loss': 0.5560595989227295, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.1226, 'eval_samples_per_second': 24.006, 'eval_steps_per_second': 1.535, 'epoch': 59.0}\n",
            "\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:32:41,002 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7316\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:32:41,004 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7316/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:32:44,423 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7316/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:32:44,424 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7316/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:32:54,089 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7068] due to args.save_total_limit\n",
            "{'loss': 0.0302, 'learning_rate': 8.193548387096774e-06, 'epoch': 59.03}\n",
            " 59% 7330/12400 [4:04:35<2:40:24,  1.90s/it]{'loss': 0.1273, 'learning_rate': 8.177419354838711e-06, 'epoch': 59.11}\n",
            "{'loss': 0.061, 'learning_rate': 8.161290322580647e-06, 'epoch': 59.19}\n",
            " 59% 7350/12400 [4:05:12<2:33:10,  1.82s/it]{'loss': 0.0634, 'learning_rate': 8.145161290322582e-06, 'epoch': 59.27}\n",
            " 59% 7360/12400 [4:05:30<2:32:34,  1.82s/it]{'loss': 0.0291, 'learning_rate': 8.129032258064517e-06, 'epoch': 59.35}\n",
            " 59% 7370/12400 [4:05:48<2:32:39,  1.82s/it]{'loss': 0.0079, 'learning_rate': 8.112903225806452e-06, 'epoch': 59.44}\n",
            " 60% 7380/12400 [4:06:07<2:32:25,  1.82s/it]{'loss': 0.0387, 'learning_rate': 8.096774193548388e-06, 'epoch': 59.52}\n",
            "{'loss': 0.042, 'learning_rate': 8.080645161290323e-06, 'epoch': 59.6}\n",
            "{'loss': 0.1019, 'learning_rate': 8.064516129032258e-06, 'epoch': 59.68}\n",
            "                                            {'loss': 0.0786, 'learning_rate': 8.048387096774194e-06, 'epoch': 59.76}\n",
            " 60% 7420/12400 [4:07:20<2:31:28,  1.83s/it]{'loss': 0.1427, 'learning_rate': 8.032258064516129e-06, 'epoch': 59.84}\n",
            "{'loss': 0.0485, 'learning_rate': 8.016129032258066e-06, 'epoch': 59.92}\n",
            "{'loss': 0.1024, 'learning_rate': 8.000000000000001e-06, 'epoch': 60.0}\n",
            " 60% 7440/12400 [4:07:55<1:57:03,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:36:39,683 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:36:39,683 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:36:39,683 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.51it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6614524126052856, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.1232, 'eval_samples_per_second': 24.005, 'eval_steps_per_second': 1.535, 'epoch': 60.0}\n",
            " 60% 7440/12400 [4:08:04<1:57:03,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:36:48,808 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7440\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:36:48,811 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7440/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:36:52,101 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7440/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:36:52,102 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7440/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:37:01,925 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7192] due to args.save_total_limit\n",
            " 60% 7450/12400 [4:08:36<2:51:54,  2.08s/it]{'loss': 0.067, 'learning_rate': 7.983870967741935e-06, 'epoch': 60.08}\n",
            "{'loss': 0.0256, 'learning_rate': 7.967741935483872e-06, 'epoch': 60.16}\n",
            "{'loss': 0.0259, 'learning_rate': 7.951612903225807e-06, 'epoch': 60.24}\n",
            "{'loss': 0.051, 'learning_rate': 7.935483870967743e-06, 'epoch': 60.32}\n",
            " 60% 7490/12400 [4:09:49<2:28:19,  1.81s/it]{'loss': 0.056, 'learning_rate': 7.919354838709678e-06, 'epoch': 60.4}\n",
            " 60% 7500/12400 [4:10:08<2:38:52,  1.95s/it]{'loss': 0.1043, 'learning_rate': 7.903225806451613e-06, 'epoch': 60.48}\n",
            "{'loss': 0.1123, 'learning_rate': 7.887096774193549e-06, 'epoch': 60.56}\n",
            "{'loss': 0.0762, 'learning_rate': 7.870967741935484e-06, 'epoch': 60.65}\n",
            "{'loss': 0.0162, 'learning_rate': 7.85483870967742e-06, 'epoch': 60.73}\n",
            "{'loss': 0.0568, 'learning_rate': 7.838709677419354e-06, 'epoch': 60.81}\n",
            "{'loss': 0.1057, 'learning_rate': 7.822580645161291e-06, 'epoch': 60.89}\n",
            "{'loss': 0.0928, 'learning_rate': 7.806451612903227e-06, 'epoch': 60.97}\n",
            " 61% 7564/12400 [4:12:03<1:54:15,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:40:47,445 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:40:47,445 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:40:47,445 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6523568630218506, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.0646, 'eval_samples_per_second': 24.16, 'eval_steps_per_second': 1.544, 'epoch': 61.0}\n",
            " 61% 7564/12400 [4:12:12<1:54:15,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:40:56,512 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7564\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:40:56,515 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7564/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:41:00,002 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7564/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:41:00,003 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7564/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:41:09,715 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7316] due to args.save_total_limit\n",
            " 61% 7570/12400 [4:12:36<3:53:15,  2.90s/it]{'loss': 0.0349, 'learning_rate': 7.790322580645162e-06, 'epoch': 61.05}\n",
            "{'loss': 0.0703, 'learning_rate': 7.774193548387097e-06, 'epoch': 61.13}\n",
            "{'loss': 0.0269, 'learning_rate': 7.758064516129033e-06, 'epoch': 61.21}\n",
            " 61% 7600/12400 [4:13:32<2:35:39,  1.95s/it]{'loss': 0.0188, 'learning_rate': 7.741935483870968e-06, 'epoch': 61.29}\n",
            "{'loss': 0.0897, 'learning_rate': 7.725806451612903e-06, 'epoch': 61.37}\n",
            "{'loss': 0.0567, 'learning_rate': 7.70967741935484e-06, 'epoch': 61.45}\n",
            "{'loss': 0.0221, 'learning_rate': 7.693548387096776e-06, 'epoch': 61.53}\n",
            "{'loss': 0.0114, 'learning_rate': 7.67741935483871e-06, 'epoch': 61.61}\n",
            " 62% 7650/12400 [4:15:03<2:23:53,  1.82s/it]{'loss': 0.0583, 'learning_rate': 7.661290322580646e-06, 'epoch': 61.69}\n",
            " 62% 7660/12400 [4:15:21<2:23:55,  1.82s/it]{'loss': 0.0591, 'learning_rate': 7.645161290322582e-06, 'epoch': 61.77}\n",
            "{'loss': 0.0285, 'learning_rate': 7.629032258064517e-06, 'epoch': 61.85}\n",
            "{'loss': 0.0689, 'learning_rate': 7.612903225806451e-06, 'epoch': 61.94}\n",
            " 62% 7688/12400 [4:16:11<1:50:51,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 02:44:55,450 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:44:55,450 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:44:55,450 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6324096918106079, 'eval_accuracy': 0.867579908675799, 'eval_runtime': 9.063, 'eval_samples_per_second': 24.164, 'eval_steps_per_second': 1.545, 'epoch': 62.0}\n",
            " 62% 7688/12400 [4:16:20<1:50:51,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:45:04,515 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7688\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:45:04,517 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7688/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:45:07,902 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7688/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:45:07,902 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7688/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:45:17,748 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7440] due to args.save_total_limit\n",
            " 62% 7690/12400 [4:16:37<8:16:51,  6.33s/it] {'loss': 0.0147, 'learning_rate': 7.5967741935483875e-06, 'epoch': 62.02}\n",
            "{'loss': 0.071, 'learning_rate': 7.580645161290323e-06, 'epoch': 62.1}\n",
            "{'loss': 0.0568, 'learning_rate': 7.564516129032259e-06, 'epoch': 62.18}\n",
            " 62% 7720/12400 [4:17:32<2:22:21,  1.83s/it]{'loss': 0.0569, 'learning_rate': 7.548387096774194e-06, 'epoch': 62.26}\n",
            "{'loss': 0.022, 'learning_rate': 7.5322580645161296e-06, 'epoch': 62.34}\n",
            " 62% 7740/12400 [4:18:09<2:20:55,  1.81s/it]{'loss': 0.0295, 'learning_rate': 7.516129032258065e-06, 'epoch': 62.42}\n",
            " 62% 7750/12400 [4:18:27<2:21:20,  1.82s/it]{'loss': 0.067, 'learning_rate': 7.500000000000001e-06, 'epoch': 62.5}\n",
            "{'loss': 0.0696, 'learning_rate': 7.483870967741936e-06, 'epoch': 62.58}\n",
            " 63% 7770/12400 [4:19:03<2:20:14,  1.82s/it]{'loss': 0.0352, 'learning_rate': 7.467741935483872e-06, 'epoch': 62.66}\n",
            "{'loss': 0.0433, 'learning_rate': 7.451612903225807e-06, 'epoch': 62.74}\n",
            " 63% 7790/12400 [4:19:40<2:19:36,  1.82s/it]{'loss': 0.0427, 'learning_rate': 7.435483870967742e-06, 'epoch': 62.82}\n",
            "{'loss': 0.0829, 'learning_rate': 7.4193548387096784e-06, 'epoch': 62.9}\n",
            "{'loss': 0.0142, 'learning_rate': 7.403225806451614e-06, 'epoch': 62.98}\n",
            " 63% 7812/12400 [4:20:19<1:48:50,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:49:03,625 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:49:03,626 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:49:03,626 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.95it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.51it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.51it/s]\u001b[A\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A{'eval_loss': 0.6313231587409973, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1523, 'eval_samples_per_second': 23.928, 'eval_steps_per_second': 1.53, 'epoch': 63.0}\n",
            "                                            \n",
            " 63% 7812/12400 [4:20:28<1:48:50,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:49:12,780 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7812\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:49:12,783 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7812/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:49:16,277 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7812/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:49:16,278 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7812/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:49:25,783 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7564] due to args.save_total_limit\n",
            "{'loss': 0.1067, 'learning_rate': 7.38709677419355e-06, 'epoch': 63.06}\n",
            "{'loss': 0.0178, 'learning_rate': 7.370967741935484e-06, 'epoch': 63.15}\n",
            "{'loss': 0.0931, 'learning_rate': 7.35483870967742e-06, 'epoch': 63.23}\n",
            "{'loss': 0.022, 'learning_rate': 7.338709677419356e-06, 'epoch': 63.31}\n",
            " 63% 7860/12400 [4:22:09<2:17:21,  1.82s/it]{'loss': 0.0313, 'learning_rate': 7.322580645161291e-06, 'epoch': 63.39}\n",
            "{'loss': 0.035, 'learning_rate': 7.306451612903226e-06, 'epoch': 63.47}\n",
            " 64% 7880/12400 [4:22:46<2:17:25,  1.82s/it]{'loss': 0.0205, 'learning_rate': 7.290322580645162e-06, 'epoch': 63.55}\n",
            "{'loss': 0.0547, 'learning_rate': 7.274193548387097e-06, 'epoch': 63.63}\n",
            "{'loss': 0.0532, 'learning_rate': 7.258064516129033e-06, 'epoch': 63.71}\n",
            " 64% 7910/12400 [4:23:41<2:15:52,  1.82s/it]{'loss': 0.0415, 'learning_rate': 7.2419354838709685e-06, 'epoch': 63.79}\n",
            "{'loss': 0.0127, 'learning_rate': 7.225806451612903e-06, 'epoch': 63.87}\n",
            "{'loss': 0.027, 'learning_rate': 7.209677419354839e-06, 'epoch': 63.95}\n",
            " 64% 7936/12400 [4:24:27<1:45:41,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 02:53:11,384 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:53:11,384 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:53:11,384 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5776939392089844, 'eval_accuracy': 0.8767123287671232, 'eval_runtime': 9.1255, 'eval_samples_per_second': 23.999, 'eval_steps_per_second': 1.534, 'epoch': 64.0}\n",
            " 64% 7936/12400 [4:24:36<1:45:41,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:53:20,512 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-7936\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:53:20,515 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-7936/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:53:23,955 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-7936/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:53:23,956 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-7936/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:53:33,529 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7688] due to args.save_total_limit\n",
            " 64% 7940/12400 [4:24:56<4:57:55,  4.01s/it]{'loss': 0.0524, 'learning_rate': 7.1935483870967745e-06, 'epoch': 64.03}\n",
            "                                            {'loss': 0.0064, 'learning_rate': 7.177419354838711e-06, 'epoch': 64.11}\n",
            " 64% 7960/12400 [4:25:33<2:17:16,  1.86s/it]{'loss': 0.0838, 'learning_rate': 7.161290322580646e-06, 'epoch': 64.19}\n",
            " 64% 7970/12400 [4:25:51<2:14:04,  1.82s/it]{'loss': 0.0596, 'learning_rate': 7.145161290322581e-06, 'epoch': 64.27}\n",
            " 64% 7980/12400 [4:26:10<2:13:32,  1.81s/it]{'loss': 0.0575, 'learning_rate': 7.1290322580645166e-06, 'epoch': 64.35}\n",
            " 64% 7990/12400 [4:26:28<2:13:35,  1.82s/it]{'loss': 0.0112, 'learning_rate': 7.112903225806453e-06, 'epoch': 64.44}\n",
            " 65% 8000/12400 [4:26:46<2:22:27,  1.94s/it]{'loss': 0.0228, 'learning_rate': 7.096774193548388e-06, 'epoch': 64.52}\n",
            " 65% 8010/12400 [4:27:05<2:13:43,  1.83s/it]{'loss': 0.0437, 'learning_rate': 7.0806451612903225e-06, 'epoch': 64.6}\n",
            "{'loss': 0.1215, 'learning_rate': 7.064516129032259e-06, 'epoch': 64.68}\n",
            "{'loss': 0.0307, 'learning_rate': 7.048387096774194e-06, 'epoch': 64.76}\n",
            " 65% 8040/12400 [4:27:59<2:11:58,  1.82s/it]{'loss': 0.0827, 'learning_rate': 7.03225806451613e-06, 'epoch': 64.84}\n",
            "{'loss': 0.0199, 'learning_rate': 7.0161290322580654e-06, 'epoch': 64.92}\n",
            " 65% 8060/12400 [4:28:34<1:42:30,  1.42s/it]{'loss': 0.0328, 'learning_rate': 7e-06, 'epoch': 65.0}\n",
            "[INFO|trainer.py:2463] 2022-05-04 02:57:19,138 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 02:57:19,138 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 02:57:19,138 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.54it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "{'eval_loss': 0.5482553839683533, 'eval_accuracy': 0.867579908675799, 'eval_runtime': 9.0843, 'eval_samples_per_second': 24.107, 'eval_steps_per_second': 1.541, 'epoch': 65.0}\n",
            "\n",
            " 65% 8060/12400 [4:28:44<1:42:30,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 02:57:28,224 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8060\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 02:57:28,226 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8060/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 02:57:31,634 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8060/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 02:57:31,635 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8060/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 02:57:41,441 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7812] due to args.save_total_limit\n",
            "                                            {'loss': 0.03, 'learning_rate': 6.983870967741936e-06, 'epoch': 65.08}\n",
            "{'loss': 0.0773, 'learning_rate': 6.967741935483871e-06, 'epoch': 65.16}\n",
            " 65% 8090/12400 [4:29:52<2:11:18,  1.83s/it]{'loss': 0.0339, 'learning_rate': 6.9516129032258075e-06, 'epoch': 65.24}\n",
            " 65% 8100/12400 [4:30:11<2:18:06,  1.93s/it]{'loss': 0.0581, 'learning_rate': 6.935483870967743e-06, 'epoch': 65.32}\n",
            "{'loss': 0.0294, 'learning_rate': 6.919354838709677e-06, 'epoch': 65.4}\n",
            "{'loss': 0.0094, 'learning_rate': 6.9032258064516135e-06, 'epoch': 65.48}\n",
            "{'loss': 0.0517, 'learning_rate': 6.887096774193549e-06, 'epoch': 65.56}\n",
            "{'loss': 0.0815, 'learning_rate': 6.870967741935485e-06, 'epoch': 65.65}\n",
            " 66% 8150/12400 [4:31:42<2:08:38,  1.82s/it]{'loss': 0.0537, 'learning_rate': 6.854838709677419e-06, 'epoch': 65.73}\n",
            "{'loss': 0.0508, 'learning_rate': 6.838709677419355e-06, 'epoch': 65.81}\n",
            " 66% 8170/12400 [4:32:18<2:08:30,  1.82s/it]{'loss': 0.0363, 'learning_rate': 6.822580645161291e-06, 'epoch': 65.89}\n",
            "{'loss': 0.0457, 'learning_rate': 6.806451612903226e-06, 'epoch': 65.97}\n",
            " 66% 8184/12400 [4:32:42<1:39:40,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 03:01:27,044 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:01:27,044 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:01:27,044 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.55it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.53it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.51it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5922083854675293, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.1243, 'eval_samples_per_second': 24.002, 'eval_steps_per_second': 1.534, 'epoch': 66.0}\n",
            " 66% 8184/12400 [4:32:52<1:39:40,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:01:36,170 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8184\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:01:36,173 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8184/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:01:39,870 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8184/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:01:39,871 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8184/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:01:49,417 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-7936] due to args.save_total_limit\n",
            "{'loss': 0.0297, 'learning_rate': 6.790322580645162e-06, 'epoch': 66.05}\n",
            " 66% 8200/12400 [4:33:35<2:19:56,  2.00s/it]{'loss': 0.116, 'learning_rate': 6.774193548387097e-06, 'epoch': 66.13}\n",
            "{'loss': 0.0397, 'learning_rate': 6.758064516129033e-06, 'epoch': 66.21}\n",
            " 66% 8220/12400 [4:34:11<2:06:42,  1.82s/it]{'loss': 0.0401, 'learning_rate': 6.741935483870968e-06, 'epoch': 66.29}\n",
            "{'loss': 0.0351, 'learning_rate': 6.725806451612904e-06, 'epoch': 66.37}\n",
            "{'loss': 0.0396, 'learning_rate': 6.70967741935484e-06, 'epoch': 66.45}\n",
            " 67% 8250/12400 [4:35:06<2:06:12,  1.82s/it]{'loss': 0.0596, 'learning_rate': 6.693548387096774e-06, 'epoch': 66.53}\n",
            "{'loss': 0.1407, 'learning_rate': 6.67741935483871e-06, 'epoch': 66.61}\n",
            " 67% 8270/12400 [4:35:42<2:05:18,  1.82s/it]{'loss': 0.0692, 'learning_rate': 6.661290322580646e-06, 'epoch': 66.69}\n",
            "                                            {'loss': 0.0468, 'learning_rate': 6.645161290322582e-06, 'epoch': 66.77}\n",
            "                                            {'loss': 0.0434, 'learning_rate': 6.629032258064517e-06, 'epoch': 66.85}\n",
            " 67% 8300/12400 [4:36:37<2:12:19,  1.94s/it]{'loss': 0.0081, 'learning_rate': 6.612903225806452e-06, 'epoch': 66.94}\n",
            " 67% 8308/12400 [4:36:51<1:36:50,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 03:05:35,283 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:05:35,283 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:05:35,283 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "{'eval_loss': 0.6798784732818604, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.0782, 'eval_samples_per_second': 24.124, 'eval_steps_per_second': 1.542, 'epoch': 67.0}\n",
            " 67% 8308/12400 [4:37:00<1:36:50,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:05:44,364 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8308\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:05:44,367 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8308/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:05:47,720 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8308/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:05:47,721 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8308/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:05:57,569 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8060] due to args.save_total_limit\n",
            "{'loss': 0.0394, 'learning_rate': 6.596774193548388e-06, 'epoch': 67.02}\n",
            " 67% 8320/12400 [4:37:35<2:13:17,  1.96s/it]{'loss': 0.1, 'learning_rate': 6.580645161290323e-06, 'epoch': 67.1}\n",
            " 67% 8330/12400 [4:37:54<2:06:10,  1.86s/it]{'loss': 0.0346, 'learning_rate': 6.564516129032259e-06, 'epoch': 67.18}\n",
            " 67% 8340/12400 [4:38:12<2:02:59,  1.82s/it]{'loss': 0.0389, 'learning_rate': 6.548387096774194e-06, 'epoch': 67.26}\n",
            "{'loss': 0.0295, 'learning_rate': 6.532258064516129e-06, 'epoch': 67.34}\n",
            " 67% 8360/12400 [4:38:48<2:02:14,  1.82s/it]{'loss': 0.0306, 'learning_rate': 6.516129032258065e-06, 'epoch': 67.42}\n",
            "{'loss': 0.014, 'learning_rate': 6.5000000000000004e-06, 'epoch': 67.5}\n",
            "{'loss': 0.0641, 'learning_rate': 6.483870967741937e-06, 'epoch': 67.58}\n",
            "{'loss': 0.0532, 'learning_rate': 6.467741935483871e-06, 'epoch': 67.66}\n",
            "{'loss': 0.0607, 'learning_rate': 6.451612903225806e-06, 'epoch': 67.74}\n",
            "{'loss': 0.0589, 'learning_rate': 6.4354838709677425e-06, 'epoch': 67.82}\n",
            "{'loss': 0.0936, 'learning_rate': 6.419354838709678e-06, 'epoch': 67.9}\n",
            "{'loss': 0.033, 'learning_rate': 6.403225806451614e-06, 'epoch': 67.98}\n",
            " 68% 8432/12400 [4:40:58<1:33:48,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 03:09:43,057 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:09:43,057 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:09:43,057 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.12it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 68% 8432/12400 [4:41:08<1:33:48,  1.42s/it]\n",
            "{'eval_loss': 0.5854114294052124, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.1199, 'eval_samples_per_second': 24.013, 'eval_steps_per_second': 1.535, 'epoch': 68.0}\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:09:52,179 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8432\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:09:52,181 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8432/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:09:55,565 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8432/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:09:55,566 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8432/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:10:05,288 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8184] due to args.save_total_limit\n",
            " 68% 8440/12400 [4:41:35<2:34:59,  2.35s/it]{'loss': 0.0226, 'learning_rate': 6.3870967741935485e-06, 'epoch': 68.06}\n",
            "{'loss': 0.0341, 'learning_rate': 6.370967741935485e-06, 'epoch': 68.15}\n",
            "{'loss': 0.1061, 'learning_rate': 6.35483870967742e-06, 'epoch': 68.23}\n",
            "{'loss': 0.0581, 'learning_rate': 6.338709677419356e-06, 'epoch': 68.31}\n",
            "{'loss': 0.0198, 'learning_rate': 6.3225806451612906e-06, 'epoch': 68.39}\n",
            "{'loss': 0.0682, 'learning_rate': 6.306451612903226e-06, 'epoch': 68.47}\n",
            "{'loss': 0.0493, 'learning_rate': 6.290322580645162e-06, 'epoch': 68.55}\n",
            " 69% 8510/12400 [4:43:44<1:58:29,  1.83s/it]{'loss': 0.0826, 'learning_rate': 6.274193548387097e-06, 'epoch': 68.63}\n",
            " 69% 8520/12400 [4:44:02<1:57:35,  1.82s/it]{'loss': 0.079, 'learning_rate': 6.2580645161290335e-06, 'epoch': 68.71}\n",
            "{'loss': 0.0656, 'learning_rate': 6.241935483870968e-06, 'epoch': 68.79}\n",
            " 69% 8540/12400 [4:44:38<1:56:59,  1.82s/it]{'loss': 0.0614, 'learning_rate': 6.225806451612903e-06, 'epoch': 68.87}\n",
            " 69% 8550/12400 [4:44:56<1:56:36,  1.82s/it]{'loss': 0.0821, 'learning_rate': 6.209677419354839e-06, 'epoch': 68.95}\n",
            " 69% 8556/12400 [4:45:06<1:30:24,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:13:50,633 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:13:50,633 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:13:50,633 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "{'eval_loss': 0.6810855865478516, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.0728, 'eval_samples_per_second': 24.138, 'eval_steps_per_second': 1.543, 'epoch': 69.0}\n",
            " 69% 8556/12400 [4:45:15<1:30:24,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:13:59,708 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8556\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:13:59,710 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8556/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:14:03,208 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8556/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:14:03,209 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8556/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:14:12,930 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8308] due to args.save_total_limit\n",
            " 69% 8560/12400 [4:45:36<4:17:24,  4.02s/it]{'loss': 0.0478, 'learning_rate': 6.193548387096775e-06, 'epoch': 69.03}\n",
            "{'loss': 0.0209, 'learning_rate': 6.177419354838711e-06, 'epoch': 69.11}\n",
            " 69% 8580/12400 [4:46:13<1:57:39,  1.85s/it]{'loss': 0.0286, 'learning_rate': 6.161290322580645e-06, 'epoch': 69.19}\n",
            "{'loss': 0.0876, 'learning_rate': 6.145161290322581e-06, 'epoch': 69.27}\n",
            "                                            {'loss': 0.0225, 'learning_rate': 6.129032258064517e-06, 'epoch': 69.35}\n",
            "{'loss': 0.0874, 'learning_rate': 6.112903225806452e-06, 'epoch': 69.44}\n",
            " 70% 8620/12400 [4:47:26<1:55:03,  1.83s/it]{'loss': 0.0199, 'learning_rate': 6.0967741935483874e-06, 'epoch': 69.52}\n",
            "{'loss': 0.0157, 'learning_rate': 6.080645161290323e-06, 'epoch': 69.6}\n",
            "                                            {'loss': 0.032, 'learning_rate': 6.064516129032259e-06, 'epoch': 69.68}\n",
            " 70% 8650/12400 [4:48:21<1:53:52,  1.82s/it]{'loss': 0.0714, 'learning_rate': 6.048387096774194e-06, 'epoch': 69.76}\n",
            "{'loss': 0.0519, 'learning_rate': 6.0322580645161295e-06, 'epoch': 69.84}\n",
            "{'loss': 0.0283, 'learning_rate': 6.016129032258065e-06, 'epoch': 69.92}\n",
            "{'loss': 0.0934, 'learning_rate': 6e-06, 'epoch': 70.0}\n",
            " 70% 8680/12400 [4:49:14<1:27:53,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 03:17:58,579 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:17:58,579 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:17:58,579 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.01it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "{'eval_loss': 0.6526777148246765, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.1422, 'eval_samples_per_second': 23.955, 'eval_steps_per_second': 1.531, 'epoch': 70.0}\n",
            "\n",
            " 70% 8680/12400 [4:49:23<1:27:53,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:18:07,723 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8680\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:18:07,725 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8680/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:18:11,185 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8680/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:18:11,186 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8680/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:18:20,871 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8432] due to args.save_total_limit\n",
            "{'loss': 0.0657, 'learning_rate': 5.983870967741936e-06, 'epoch': 70.08}\n",
            "{'loss': 0.0303, 'learning_rate': 5.967741935483872e-06, 'epoch': 70.16}\n",
            "{'loss': 0.0985, 'learning_rate': 5.951612903225808e-06, 'epoch': 70.24}\n",
            "{'loss': 0.0462, 'learning_rate': 5.935483870967742e-06, 'epoch': 70.32}\n",
            " 70% 8730/12400 [4:51:08<1:50:49,  1.81s/it]{'loss': 0.0493, 'learning_rate': 5.9193548387096776e-06, 'epoch': 70.4}\n",
            "{'loss': 0.07, 'learning_rate': 5.903225806451614e-06, 'epoch': 70.48}\n",
            "{'loss': 0.1002, 'learning_rate': 5.887096774193549e-06, 'epoch': 70.56}\n",
            "{'loss': 0.046, 'learning_rate': 5.8709677419354835e-06, 'epoch': 70.65}\n",
            " 71% 8770/12400 [4:52:21<1:49:35,  1.81s/it]{'loss': 0.0526, 'learning_rate': 5.85483870967742e-06, 'epoch': 70.73}\n",
            "{'loss': 0.0282, 'learning_rate': 5.838709677419355e-06, 'epoch': 70.81}\n",
            " 71% 8790/12400 [4:52:58<1:49:39,  1.82s/it]{'loss': 0.0204, 'learning_rate': 5.822580645161291e-06, 'epoch': 70.89}\n",
            "{'loss': 0.0067, 'learning_rate': 5.806451612903226e-06, 'epoch': 70.97}\n",
            " 71% 8804/12400 [4:53:22<1:26:49,  1.45s/it][INFO|trainer.py:2463] 2022-05-04 03:22:06,884 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:22:06,885 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:22:06,885 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6799373626708984, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.0836, 'eval_samples_per_second': 24.109, 'eval_steps_per_second': 1.541, 'epoch': 71.0}\n",
            " 71% 8804/12400 [4:53:31<1:26:49,  1.45s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:22:15,970 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8804\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:22:15,974 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8804/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:22:20,279 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8804/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:22:20,280 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8804/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:22:29,239 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8556] due to args.save_total_limit\n",
            "{'loss': 0.063, 'learning_rate': 5.790322580645161e-06, 'epoch': 71.05}\n",
            "{'loss': 0.0797, 'learning_rate': 5.774193548387097e-06, 'epoch': 71.13}\n",
            "{'loss': 0.0075, 'learning_rate': 5.758064516129032e-06, 'epoch': 71.21}\n",
            " 71% 8840/12400 [4:54:51<1:47:29,  1.81s/it]{'loss': 0.0391, 'learning_rate': 5.7419354838709685e-06, 'epoch': 71.29}\n",
            "{'loss': 0.0781, 'learning_rate': 5.725806451612904e-06, 'epoch': 71.37}\n",
            " 71% 8860/12400 [4:55:27<1:47:25,  1.82s/it]{'loss': 0.1113, 'learning_rate': 5.709677419354839e-06, 'epoch': 71.45}\n",
            " 72% 8870/12400 [4:55:45<1:47:07,  1.82s/it]{'loss': 0.0575, 'learning_rate': 5.6935483870967744e-06, 'epoch': 71.53}\n",
            "{'loss': 0.0533, 'learning_rate': 5.677419354838711e-06, 'epoch': 71.61}\n",
            "{'loss': 0.0659, 'learning_rate': 5.661290322580646e-06, 'epoch': 71.69}\n",
            "{'loss': 0.0552, 'learning_rate': 5.645161290322582e-06, 'epoch': 71.77}\n",
            "{'loss': 0.0163, 'learning_rate': 5.6290322580645165e-06, 'epoch': 71.85}\n",
            " 72% 8920/12400 [4:57:17<1:45:29,  1.82s/it]{'loss': 0.0347, 'learning_rate': 5.612903225806452e-06, 'epoch': 71.94}\n",
            " 72% 8928/12400 [4:57:30<1:21:45,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:26:14,598 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:26:14,598 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:26:14,598 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.681945264339447, 'eval_accuracy': 0.8356164383561644, 'eval_runtime': 9.0912, 'eval_samples_per_second': 24.089, 'eval_steps_per_second': 1.54, 'epoch': 72.0}\n",
            " 72% 8928/12400 [4:57:39<1:21:45,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:26:23,691 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-8928\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:26:23,693 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-8928/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:26:27,003 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-8928/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:26:27,004 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-8928/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:26:36,848 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8680] due to args.save_total_limit\n",
            "{'loss': 0.0286, 'learning_rate': 5.596774193548388e-06, 'epoch': 72.02}\n",
            " 72% 8940/12400 [4:58:14<1:52:56,  1.96s/it]{'loss': 0.0682, 'learning_rate': 5.580645161290323e-06, 'epoch': 72.1}\n",
            "{'loss': 0.0108, 'learning_rate': 5.564516129032258e-06, 'epoch': 72.18}\n",
            "{'loss': 0.0348, 'learning_rate': 5.548387096774194e-06, 'epoch': 72.26}\n",
            " 72% 8970/12400 [4:59:09<1:43:17,  1.81s/it]{'loss': 0.0354, 'learning_rate': 5.532258064516129e-06, 'epoch': 72.34}\n",
            " 72% 8980/12400 [4:59:28<1:43:29,  1.82s/it]{'loss': 0.0401, 'learning_rate': 5.516129032258065e-06, 'epoch': 72.42}\n",
            " 72% 8990/12400 [4:59:46<1:43:32,  1.82s/it]{'loss': 0.0555, 'learning_rate': 5.500000000000001e-06, 'epoch': 72.5}\n",
            "{'loss': 0.0825, 'learning_rate': 5.483870967741935e-06, 'epoch': 72.58}\n",
            "{'loss': 0.0532, 'learning_rate': 5.467741935483871e-06, 'epoch': 72.66}\n",
            "{'loss': 0.0471, 'learning_rate': 5.451612903225807e-06, 'epoch': 72.74}\n",
            " 73% 9030/12400 [5:00:59<1:42:05,  1.82s/it]{'loss': 0.0658, 'learning_rate': 5.435483870967743e-06, 'epoch': 72.82}\n",
            "{'loss': 0.0199, 'learning_rate': 5.419354838709678e-06, 'epoch': 72.9}\n",
            "{'loss': 0.0978, 'learning_rate': 5.4032258064516126e-06, 'epoch': 72.98}\n",
            " 73% 9052/12400 [5:01:38<1:19:21,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 03:30:22,415 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:30:22,415 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:30:22,415 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.53it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            " 73% 9052/12400 [5:01:47<1:19:21,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A{'eval_loss': 0.6695011854171753, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.1128, 'eval_samples_per_second': 24.032, 'eval_steps_per_second': 1.536, 'epoch': 73.0}\n",
            "\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:30:31,530 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9052\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:30:31,534 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9052/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:30:35,063 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9052/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:30:35,064 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9052/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:30:44,782 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8804] due to args.save_total_limit\n",
            " 73% 9060/12400 [5:02:15<2:10:47,  2.35s/it]{'loss': 0.0463, 'learning_rate': 5.387096774193549e-06, 'epoch': 73.06}\n",
            "{'loss': 0.0538, 'learning_rate': 5.370967741935484e-06, 'epoch': 73.15}\n",
            "{'loss': 0.08, 'learning_rate': 5.35483870967742e-06, 'epoch': 73.23}\n",
            "{'loss': 0.0078, 'learning_rate': 5.338709677419355e-06, 'epoch': 73.31}\n",
            "{'loss': 0.0638, 'learning_rate': 5.322580645161291e-06, 'epoch': 73.39}\n",
            "{'loss': 0.0508, 'learning_rate': 5.306451612903226e-06, 'epoch': 73.47}\n",
            "{'loss': 0.0643, 'learning_rate': 5.290322580645162e-06, 'epoch': 73.55}\n",
            "{'loss': 0.0814, 'learning_rate': 5.274193548387098e-06, 'epoch': 73.63}\n",
            " 74% 9140/12400 [5:04:41<1:38:33,  1.81s/it]{'loss': 0.0176, 'learning_rate': 5.258064516129032e-06, 'epoch': 73.71}\n",
            "{'loss': 0.0728, 'learning_rate': 5.241935483870968e-06, 'epoch': 73.79}\n",
            "{'loss': 0.0494, 'learning_rate': 5.2258064516129035e-06, 'epoch': 73.87}\n",
            "{'loss': 0.0029, 'learning_rate': 5.20967741935484e-06, 'epoch': 73.95}\n",
            " 74% 9176/12400 [5:05:46<1:15:55,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:34:30,324 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:34:30,324 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:34:30,325 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  3.00it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "{'eval_loss': 0.6572908163070679, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.0787, 'eval_samples_per_second': 24.122, 'eval_steps_per_second': 1.542, 'epoch': 74.0}\n",
            " 74% 9176/12400 [5:05:55<1:15:55,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:34:39,405 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9176\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:34:39,407 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9176/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:34:43,060 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9176/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:34:43,061 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9176/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:34:52,436 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-8928] due to args.save_total_limit\n",
            "{'loss': 0.0249, 'learning_rate': 5.193548387096775e-06, 'epoch': 74.03}\n",
            "{'loss': 0.0112, 'learning_rate': 5.1774193548387095e-06, 'epoch': 74.11}\n",
            "{'loss': 0.0251, 'learning_rate': 5.161290322580646e-06, 'epoch': 74.19}\n",
            "{'loss': 0.0316, 'learning_rate': 5.145161290322581e-06, 'epoch': 74.27}\n",
            " 74% 9220/12400 [5:07:29<1:35:54,  1.81s/it]{'loss': 0.055, 'learning_rate': 5.129032258064517e-06, 'epoch': 74.35}\n",
            "{'loss': 0.0609, 'learning_rate': 5.1129032258064515e-06, 'epoch': 74.44}\n",
            " 75% 9240/12400 [5:08:05<1:36:00,  1.82s/it]{'loss': 0.031, 'learning_rate': 5.096774193548387e-06, 'epoch': 74.52}\n",
            " 75% 9250/12400 [5:08:24<1:35:43,  1.82s/it]{'loss': 0.0146, 'learning_rate': 5.080645161290323e-06, 'epoch': 74.6}\n",
            " 75% 9260/12400 [5:08:42<1:35:02,  1.82s/it]{'loss': 0.0358, 'learning_rate': 5.064516129032258e-06, 'epoch': 74.68}\n",
            "{'loss': 0.0603, 'learning_rate': 5.0483870967741945e-06, 'epoch': 74.76}\n",
            " 75% 9280/12400 [5:09:18<1:34:42,  1.82s/it]{'loss': 0.0108, 'learning_rate': 5.032258064516129e-06, 'epoch': 74.84}\n",
            "{'loss': 0.0358, 'learning_rate': 5.016129032258065e-06, 'epoch': 74.92}\n",
            "{'loss': 0.0898, 'learning_rate': 5e-06, 'epoch': 75.0}\n",
            " 75% 9300/12400 [5:09:54<1:20:14,  1.55s/it][INFO|trainer.py:2463] 2022-05-04 03:38:38,463 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:38:38,463 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:38:38,463 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.54it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6584270000457764, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.0643, 'eval_samples_per_second': 24.161, 'eval_steps_per_second': 1.545, 'epoch': 75.0}\n",
            " 75% 9300/12400 [5:10:03<1:20:14,  1.55s/it]\n",
            "100% 14/14 [00:08<00:00,  1.66it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:38:47,529 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9300\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:38:47,532 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9300/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:38:51,178 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9300/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:38:51,178 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9300/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:39:00,602 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9052] due to args.save_total_limit\n",
            " 75% 9310/12400 [5:10:34<1:47:23,  2.09s/it]{'loss': 0.0471, 'learning_rate': 4.983870967741936e-06, 'epoch': 75.08}\n",
            " 75% 9320/12400 [5:10:53<1:35:53,  1.87s/it]{'loss': 0.0329, 'learning_rate': 4.967741935483871e-06, 'epoch': 75.16}\n",
            "{'loss': 0.0482, 'learning_rate': 4.951612903225807e-06, 'epoch': 75.24}\n",
            "{'loss': 0.0534, 'learning_rate': 4.9354838709677425e-06, 'epoch': 75.32}\n",
            " 75% 9350/12400 [5:11:48<1:32:14,  1.81s/it]{'loss': 0.0743, 'learning_rate': 4.919354838709678e-06, 'epoch': 75.4}\n",
            "{'loss': 0.0365, 'learning_rate': 4.903225806451613e-06, 'epoch': 75.48}\n",
            " 76% 9370/12400 [5:12:24<1:32:11,  1.83s/it]{'loss': 0.0776, 'learning_rate': 4.8870967741935484e-06, 'epoch': 75.56}\n",
            "{'loss': 0.0345, 'learning_rate': 4.870967741935485e-06, 'epoch': 75.65}\n",
            "{'loss': 0.0533, 'learning_rate': 4.85483870967742e-06, 'epoch': 75.73}\n",
            " 76% 9400/12400 [5:13:19<1:36:52,  1.94s/it]{'loss': 0.0594, 'learning_rate': 4.838709677419355e-06, 'epoch': 75.81}\n",
            "{'loss': 0.0411, 'learning_rate': 4.8225806451612905e-06, 'epoch': 75.89}\n",
            "{'loss': 0.0601, 'learning_rate': 4.806451612903227e-06, 'epoch': 75.97}\n",
            " 76% 9424/12400 [5:14:01<1:10:07,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:42:45,975 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:42:45,975 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:42:45,975 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.5934213995933533, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.0934, 'eval_samples_per_second': 24.083, 'eval_steps_per_second': 1.54, 'epoch': 76.0}\n",
            " 76% 9424/12400 [5:14:10<1:10:07,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:42:55,070 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9424\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:42:55,072 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9424/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:42:58,478 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9424/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:42:58,479 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9424/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:43:08,271 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9176] due to args.save_total_limit\n",
            " 76% 9430/12400 [5:14:35<2:23:18,  2.90s/it]{'loss': 0.0095, 'learning_rate': 4.790322580645161e-06, 'epoch': 76.05}\n",
            "                                            {'loss': 0.0637, 'learning_rate': 4.774193548387097e-06, 'epoch': 76.13}\n",
            "{'loss': 0.0917, 'learning_rate': 4.758064516129033e-06, 'epoch': 76.21}\n",
            "{'loss': 0.0078, 'learning_rate': 4.741935483870968e-06, 'epoch': 76.29}\n",
            " 76% 9470/12400 [5:15:48<1:28:21,  1.81s/it]{'loss': 0.0217, 'learning_rate': 4.725806451612904e-06, 'epoch': 76.37}\n",
            "{'loss': 0.1135, 'learning_rate': 4.7096774193548385e-06, 'epoch': 76.45}\n",
            " 77% 9490/12400 [5:16:24<1:28:35,  1.83s/it]{'loss': 0.0344, 'learning_rate': 4.693548387096775e-06, 'epoch': 76.53}\n",
            "{'loss': 0.0113, 'learning_rate': 4.67741935483871e-06, 'epoch': 76.61}\n",
            "{'loss': 0.091, 'learning_rate': 4.661290322580645e-06, 'epoch': 76.69}\n",
            " 77% 9520/12400 [5:17:19<1:27:02,  1.81s/it]{'loss': 0.0122, 'learning_rate': 4.6451612903225815e-06, 'epoch': 76.77}\n",
            " 77% 9530/12400 [5:17:38<1:26:50,  1.82s/it]{'loss': 0.0402, 'learning_rate': 4.629032258064517e-06, 'epoch': 76.85}\n",
            "                                            {'loss': 0.0719, 'learning_rate': 4.612903225806452e-06, 'epoch': 76.94}\n",
            " 77% 9548/12400 [5:18:09<1:07:02,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:46:53,709 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:46:53,709 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:46:53,709 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6436198353767395, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.0834, 'eval_samples_per_second': 24.11, 'eval_steps_per_second': 1.541, 'epoch': 77.0}\n",
            " 77% 9548/12400 [5:18:18<1:07:02,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:47:02,795 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9548\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:47:02,796 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9548/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:47:06,200 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9548/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:47:06,201 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9548/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:47:15,991 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9300] due to args.save_total_limit\n",
            "{'loss': 0.089, 'learning_rate': 4.596774193548387e-06, 'epoch': 77.02}\n",
            "{'loss': 0.0577, 'learning_rate': 4.580645161290323e-06, 'epoch': 77.1}\n",
            " 77% 9570/12400 [5:19:12<1:27:39,  1.86s/it]{'loss': 0.0727, 'learning_rate': 4.564516129032259e-06, 'epoch': 77.18}\n",
            " 77% 9580/12400 [5:19:30<1:25:38,  1.82s/it]{'loss': 0.0665, 'learning_rate': 4.548387096774194e-06, 'epoch': 77.26}\n",
            " 77% 9590/12400 [5:19:48<1:24:40,  1.81s/it]{'loss': 0.0631, 'learning_rate': 4.5322580645161295e-06, 'epoch': 77.34}\n",
            "{'loss': 0.0586, 'learning_rate': 4.516129032258065e-06, 'epoch': 77.42}\n",
            "{'loss': 0.0417, 'learning_rate': 4.5e-06, 'epoch': 77.5}\n",
            " 78% 9620/12400 [5:20:44<1:24:39,  1.83s/it]{'loss': 0.0705, 'learning_rate': 4.4838709677419354e-06, 'epoch': 77.58}\n",
            "{'loss': 0.0786, 'learning_rate': 4.467741935483872e-06, 'epoch': 77.66}\n",
            "                                            {'loss': 0.0246, 'learning_rate': 4.451612903225807e-06, 'epoch': 77.74}\n",
            "{'loss': 0.0416, 'learning_rate': 4.435483870967742e-06, 'epoch': 77.82}\n",
            " 78% 9660/12400 [5:21:56<1:22:52,  1.81s/it]{'loss': 0.0284, 'learning_rate': 4.419354838709678e-06, 'epoch': 77.9}\n",
            "{'loss': 0.0064, 'learning_rate': 4.403225806451613e-06, 'epoch': 77.98}\n",
            " 78% 9672/12400 [5:22:17<1:04:27,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 03:51:01,556 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:51:01,556 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:51:01,556 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.87it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6165964007377625, 'eval_accuracy': 0.867579908675799, 'eval_runtime': 9.0646, 'eval_samples_per_second': 24.16, 'eval_steps_per_second': 1.544, 'epoch': 78.0}\n",
            " 78% 9672/12400 [5:22:26<1:04:27,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:51:10,622 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9672\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:51:10,624 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9672/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:51:13,979 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9672/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:51:13,980 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9672/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:51:23,893 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9424] due to args.save_total_limit\n",
            "                                            {'loss': 0.0074, 'learning_rate': 4.387096774193549e-06, 'epoch': 78.06}\n",
            "{'loss': 0.0867, 'learning_rate': 4.370967741935484e-06, 'epoch': 78.15}\n",
            "{'loss': 0.0155, 'learning_rate': 4.35483870967742e-06, 'epoch': 78.23}\n",
            " 78% 9710/12400 [5:23:49<1:21:18,  1.81s/it]{'loss': 0.0122, 'learning_rate': 4.338709677419356e-06, 'epoch': 78.31}\n",
            " 78% 9720/12400 [5:24:08<1:20:49,  1.81s/it]{'loss': 0.0595, 'learning_rate': 4.32258064516129e-06, 'epoch': 78.39}\n",
            "{'loss': 0.0223, 'learning_rate': 4.306451612903226e-06, 'epoch': 78.47}\n",
            " 79% 9740/12400 [5:24:44<1:20:47,  1.82s/it]{'loss': 0.0538, 'learning_rate': 4.290322580645162e-06, 'epoch': 78.55}\n",
            " 79% 9750/12400 [5:25:02<1:20:24,  1.82s/it]{'loss': 0.0659, 'learning_rate': 4.274193548387097e-06, 'epoch': 78.63}\n",
            "{'loss': 0.0326, 'learning_rate': 4.258064516129032e-06, 'epoch': 78.71}\n",
            "{'loss': 0.0161, 'learning_rate': 4.2419354838709685e-06, 'epoch': 78.79}\n",
            "{'loss': 0.0068, 'learning_rate': 4.225806451612904e-06, 'epoch': 78.87}\n",
            "{'loss': 0.0202, 'learning_rate': 4.209677419354839e-06, 'epoch': 78.95}\n",
            " 79% 9796/12400 [5:26:25<1:01:21,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:55:09,367 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:55:09,367 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:55:09,367 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  2.97it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.11it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 0.6087521314620972, 'eval_accuracy': 0.867579908675799, 'eval_runtime': 9.1134, 'eval_samples_per_second': 24.031, 'eval_steps_per_second': 1.536, 'epoch': 79.0}\n",
            " 79% 9796/12400 [5:26:34<1:01:21,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:55:18,482 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9796\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:55:18,484 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9796/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:55:22,073 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9796/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:55:22,074 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9796/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:55:31,634 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9548] due to args.save_total_limit\n",
            " 79% 9800/12400 [5:26:55<2:59:24,  4.14s/it]{'loss': 0.0053, 'learning_rate': 4.193548387096774e-06, 'epoch': 79.03}\n",
            "{'loss': 0.0225, 'learning_rate': 4.17741935483871e-06, 'epoch': 79.11}\n",
            "{'loss': 0.0688, 'learning_rate': 4.161290322580646e-06, 'epoch': 79.19}\n",
            " 79% 9830/12400 [5:27:50<1:17:54,  1.82s/it]{'loss': 0.0472, 'learning_rate': 4.14516129032258e-06, 'epoch': 79.27}\n",
            " 79% 9840/12400 [5:28:08<1:17:31,  1.82s/it]{'loss': 0.053, 'learning_rate': 4.1290322580645165e-06, 'epoch': 79.35}\n",
            "{'loss': 0.0687, 'learning_rate': 4.112903225806452e-06, 'epoch': 79.44}\n",
            "{'loss': 0.0106, 'learning_rate': 4.096774193548387e-06, 'epoch': 79.52}\n",
            "{'loss': 0.0687, 'learning_rate': 4.080645161290323e-06, 'epoch': 79.6}\n",
            " 80% 9880/12400 [5:29:21<1:16:33,  1.82s/it]{'loss': 0.04, 'learning_rate': 4.064516129032259e-06, 'epoch': 79.68}\n",
            " 80% 9890/12400 [5:29:39<1:16:04,  1.82s/it]{'loss': 0.0314, 'learning_rate': 4.048387096774194e-06, 'epoch': 79.76}\n",
            "{'loss': 0.0181, 'learning_rate': 4.032258064516129e-06, 'epoch': 79.84}\n",
            "{'loss': 0.0714, 'learning_rate': 4.0161290322580645e-06, 'epoch': 79.92}\n",
            "{'loss': 0.0129, 'learning_rate': 4.000000000000001e-06, 'epoch': 80.0}\n",
            " 80% 9920/12400 [5:30:33<58:23,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 03:59:17,639 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 03:59:17,639 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 03:59:17,639 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.51it/s]\u001b[A\n",
            "                                          \n",
            "{'eval_loss': 0.6902903318405151, 'eval_accuracy': 0.8401826484018264, 'eval_runtime': 9.1318, 'eval_samples_per_second': 23.982, 'eval_steps_per_second': 1.533, 'epoch': 80.0}\n",
            " 80% 9920/12400 [5:30:42<58:23,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 03:59:26,773 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-9920\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 03:59:26,775 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-9920/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 03:59:30,253 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-9920/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 03:59:30,254 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-9920/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 03:59:39,867 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9672] due to args.save_total_limit\n",
            "{'loss': 0.0382, 'learning_rate': 3.983870967741936e-06, 'epoch': 80.08}\n",
            "{'loss': 0.0678, 'learning_rate': 3.967741935483871e-06, 'epoch': 80.16}\n",
            "{'loss': 0.0737, 'learning_rate': 3.951612903225807e-06, 'epoch': 80.24}\n",
            "{'loss': 0.0463, 'learning_rate': 3.935483870967742e-06, 'epoch': 80.32}\n",
            "{'loss': 0.0144, 'learning_rate': 3.919354838709677e-06, 'epoch': 80.4}\n",
            "{'loss': 0.0504, 'learning_rate': 3.903225806451613e-06, 'epoch': 80.48}\n",
            "{'loss': 0.0041, 'learning_rate': 3.887096774193549e-06, 'epoch': 80.56}\n",
            "{'loss': 0.1501, 'learning_rate': 3.870967741935484e-06, 'epoch': 80.65}\n",
            " 81% 10010/12400 [5:33:40<1:12:36,  1.82s/it]{'loss': 0.0618, 'learning_rate': 3.85483870967742e-06, 'epoch': 80.73}\n",
            " 81% 10020/12400 [5:33:58<1:12:16,  1.82s/it]{'loss': 0.0052, 'learning_rate': 3.838709677419355e-06, 'epoch': 80.81}\n",
            " 81% 10030/12400 [5:34:17<1:11:48,  1.82s/it]{'loss': 0.0388, 'learning_rate': 3.822580645161291e-06, 'epoch': 80.89}\n",
            "{'loss': 0.0116, 'learning_rate': 3.8064516129032257e-06, 'epoch': 80.97}\n",
            " 81% 10044/12400 [5:34:41<55:30,  1.41s/it]  [INFO|trainer.py:2463] 2022-05-04 04:03:25,425 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:03:25,425 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:03:25,425 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.06it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.56it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6468758583068848, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.0956, 'eval_samples_per_second': 24.078, 'eval_steps_per_second': 1.539, 'epoch': 81.0}\n",
            " 81% 10044/12400 [5:34:50<55:30,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:03:34,523 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10044\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:03:34,526 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10044/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:03:38,019 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10044/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:03:38,020 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10044/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:03:47,492 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9796] due to args.save_total_limit\n",
            "{'loss': 0.064, 'learning_rate': 3.7903225806451614e-06, 'epoch': 81.05}\n",
            "{'loss': 0.0074, 'learning_rate': 3.774193548387097e-06, 'epoch': 81.13}\n",
            "{'loss': 0.0135, 'learning_rate': 3.7580645161290324e-06, 'epoch': 81.21}\n",
            " 81% 10080/12400 [5:36:09<1:09:56,  1.81s/it]{'loss': 0.0132, 'learning_rate': 3.741935483870968e-06, 'epoch': 81.29}\n",
            " 81% 10090/12400 [5:36:27<1:09:35,  1.81s/it]{'loss': 0.0463, 'learning_rate': 3.7258064516129035e-06, 'epoch': 81.37}\n",
            " 81% 10100/12400 [5:36:46<1:14:20,  1.94s/it]{'loss': 0.0124, 'learning_rate': 3.7096774193548392e-06, 'epoch': 81.45}\n",
            " 82% 10110/12400 [5:37:04<1:09:48,  1.83s/it]{'loss': 0.0247, 'learning_rate': 3.693548387096775e-06, 'epoch': 81.53}\n",
            "{'loss': 0.0034, 'learning_rate': 3.67741935483871e-06, 'epoch': 81.61}\n",
            "{'loss': 0.0895, 'learning_rate': 3.6612903225806456e-06, 'epoch': 81.69}\n",
            " 82% 10140/12400 [5:37:59<1:08:22,  1.82s/it]{'loss': 0.0624, 'learning_rate': 3.645161290322581e-06, 'epoch': 81.77}\n",
            " 82% 10150/12400 [5:38:17<1:08:15,  1.82s/it]{'loss': 0.0129, 'learning_rate': 3.6290322580645166e-06, 'epoch': 81.85}\n",
            " 82% 10160/12400 [5:38:35<1:08:02,  1.82s/it]{'loss': 0.016, 'learning_rate': 3.6129032258064515e-06, 'epoch': 81.94}\n",
            " 82% 10168/12400 [5:38:48<52:33,  1.41s/it]  [INFO|trainer.py:2463] 2022-05-04 04:07:32,906 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:07:32,906 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:07:32,906 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.52it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.51it/s]\u001b[A\n",
            "                                           \n",
            " 82% 10168/12400 [5:38:57<52:33,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A{'eval_loss': 0.6957001686096191, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.11, 'eval_samples_per_second': 24.04, 'eval_steps_per_second': 1.537, 'epoch': 82.0}\n",
            "[INFO|trainer.py:2213] 2022-05-04 04:07:42,018 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10168\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:07:42,021 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10168/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:07:45,427 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10168/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:07:45,428 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10168/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:07:55,227 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-9920] due to args.save_total_limit\n",
            "{'loss': 0.025, 'learning_rate': 3.5967741935483872e-06, 'epoch': 82.02}\n",
            " 82% 10180/12400 [5:39:33<1:12:21,  1.96s/it]{'loss': 0.0583, 'learning_rate': 3.580645161290323e-06, 'epoch': 82.1}\n",
            "{'loss': 0.018, 'learning_rate': 3.5645161290322583e-06, 'epoch': 82.18}\n",
            "{'loss': 0.0403, 'learning_rate': 3.548387096774194e-06, 'epoch': 82.26}\n",
            " 82% 10210/12400 [5:40:28<1:05:59,  1.81s/it]{'loss': 0.0431, 'learning_rate': 3.5322580645161293e-06, 'epoch': 82.34}\n",
            "{'loss': 0.1014, 'learning_rate': 3.516129032258065e-06, 'epoch': 82.42}\n",
            "{'loss': 0.0331, 'learning_rate': 3.5e-06, 'epoch': 82.5}\n",
            " 83% 10240/12400 [5:41:23<1:05:31,  1.82s/it]{'loss': 0.0205, 'learning_rate': 3.4838709677419357e-06, 'epoch': 82.58}\n",
            "{'loss': 0.0326, 'learning_rate': 3.4677419354838714e-06, 'epoch': 82.66}\n",
            "{'loss': 0.019, 'learning_rate': 3.4516129032258067e-06, 'epoch': 82.74}\n",
            " 83% 10270/12400 [5:42:17<1:04:30,  1.82s/it]{'loss': 0.0119, 'learning_rate': 3.4354838709677425e-06, 'epoch': 82.82}\n",
            "{'loss': 0.0431, 'learning_rate': 3.4193548387096773e-06, 'epoch': 82.9}\n",
            " 83% 10290/12400 [5:42:54<1:04:04,  1.82s/it]{'loss': 0.0464, 'learning_rate': 3.403225806451613e-06, 'epoch': 82.98}\n",
            " 83% 10292/12400 [5:42:56<49:51,  1.42s/it]  [INFO|trainer.py:2463] 2022-05-04 04:11:40,675 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:11:40,676 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:11:40,676 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            " 83% 10292/12400 [5:43:05<49:51,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A{'eval_loss': 0.630573034286499, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.0786, 'eval_samples_per_second': 24.123, 'eval_steps_per_second': 1.542, 'epoch': 83.0}\n",
            "[INFO|trainer.py:2213] 2022-05-04 04:11:49,756 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10292\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:11:49,758 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10292/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:11:53,124 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10292/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:11:53,124 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10292/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:12:02,874 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10044] due to args.save_total_limit\n",
            " 83% 10300/12400 [5:43:33<1:26:18,  2.47s/it]{'loss': 0.0485, 'learning_rate': 3.3870967741935484e-06, 'epoch': 83.06}\n",
            " 83% 10310/12400 [5:43:52<1:05:35,  1.88s/it]{'loss': 0.051, 'learning_rate': 3.370967741935484e-06, 'epoch': 83.15}\n",
            " 83% 10320/12400 [5:44:10<1:03:27,  1.83s/it]{'loss': 0.0071, 'learning_rate': 3.35483870967742e-06, 'epoch': 83.23}\n",
            "{'loss': 0.0138, 'learning_rate': 3.338709677419355e-06, 'epoch': 83.31}\n",
            "{'loss': 0.057, 'learning_rate': 3.322580645161291e-06, 'epoch': 83.39}\n",
            " 83% 10350/12400 [5:45:05<1:02:11,  1.82s/it]{'loss': 0.0407, 'learning_rate': 3.306451612903226e-06, 'epoch': 83.47}\n",
            "{'loss': 0.0632, 'learning_rate': 3.2903225806451615e-06, 'epoch': 83.55}\n",
            "{'loss': 0.0344, 'learning_rate': 3.274193548387097e-06, 'epoch': 83.63}\n",
            " 84% 10380/12400 [5:45:59<1:01:05,  1.81s/it]{'loss': 0.0519, 'learning_rate': 3.2580645161290326e-06, 'epoch': 83.71}\n",
            "{'loss': 0.0504, 'learning_rate': 3.2419354838709683e-06, 'epoch': 83.79}\n",
            " 84% 10400/12400 [5:46:36<1:04:28,  1.93s/it]{'loss': 0.0546, 'learning_rate': 3.225806451612903e-06, 'epoch': 83.87}\n",
            "{'loss': 0.0113, 'learning_rate': 3.209677419354839e-06, 'epoch': 83.95}\n",
            " 84% 10416/12400 [5:47:04<46:52,  1.42s/it]  [INFO|trainer.py:2463] 2022-05-04 04:15:48,751 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:15:48,751 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:15:48,751 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            " 84% 10416/12400 [5:47:13<46:52,  1.42s/it]\n",
            "{'eval_loss': 0.6311442255973816, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.0731, 'eval_samples_per_second': 24.137, 'eval_steps_per_second': 1.543, 'epoch': 84.0}\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:15:57,826 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10416\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:15:57,828 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10416/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:16:01,211 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10416/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:16:01,211 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10416/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:16:11,065 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10168] due to args.save_total_limit\n",
            "{'loss': 0.0553, 'learning_rate': 3.1935483870967742e-06, 'epoch': 84.03}\n",
            "{'loss': 0.0696, 'learning_rate': 3.17741935483871e-06, 'epoch': 84.11}\n",
            "{'loss': 0.0185, 'learning_rate': 3.1612903225806453e-06, 'epoch': 84.19}\n",
            "{'loss': 0.0653, 'learning_rate': 3.145161290322581e-06, 'epoch': 84.27}\n",
            "{'loss': 0.0703, 'learning_rate': 3.1290322580645167e-06, 'epoch': 84.35}\n",
            " 84% 10470/12400 [5:49:05<58:24,  1.82s/it]{'loss': 0.0148, 'learning_rate': 3.1129032258064516e-06, 'epoch': 84.44}\n",
            "{'loss': 0.0404, 'learning_rate': 3.0967741935483874e-06, 'epoch': 84.52}\n",
            "{'loss': 0.0079, 'learning_rate': 3.0806451612903227e-06, 'epoch': 84.6}\n",
            "                                             {'loss': 0.0034, 'learning_rate': 3.0645161290322584e-06, 'epoch': 84.68}\n",
            " 85% 10510/12400 [5:50:18<57:18,  1.82s/it]{'loss': 0.0558, 'learning_rate': 3.0483870967741937e-06, 'epoch': 84.76}\n",
            " 85% 10520/12400 [5:50:37<56:55,  1.82s/it]{'loss': 0.0333, 'learning_rate': 3.0322580645161295e-06, 'epoch': 84.84}\n",
            " 85% 10530/12400 [5:50:55<56:47,  1.82s/it]{'loss': 0.0052, 'learning_rate': 3.0161290322580648e-06, 'epoch': 84.92}\n",
            " 85% 10540/12400 [5:51:12<43:48,  1.41s/it]{'loss': 0.1017, 'learning_rate': 3e-06, 'epoch': 85.0}\n",
            " 85% 10540/12400 [5:51:12<43:48,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 04:19:56,481 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:19:56,481 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:19:56,482 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.84it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.71it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.63it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.59it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6655557751655579, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.1156, 'eval_samples_per_second': 24.025, 'eval_steps_per_second': 1.536, 'epoch': 85.0}\n",
            " 85% 10540/12400 [5:51:21<43:48,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:20:05,599 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10540\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:20:05,601 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10540/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:20:09,368 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10540/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:20:09,369 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10540/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:20:18,879 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10292] due to args.save_total_limit\n",
            "{'loss': 0.0708, 'learning_rate': 2.983870967741936e-06, 'epoch': 85.08}\n",
            " 85% 10560/12400 [5:52:11<57:12,  1.87s/it]{'loss': 0.0305, 'learning_rate': 2.967741935483871e-06, 'epoch': 85.16}\n",
            " 85% 10570/12400 [5:52:29<55:48,  1.83s/it]{'loss': 0.014, 'learning_rate': 2.951612903225807e-06, 'epoch': 85.24}\n",
            "{'loss': 0.0718, 'learning_rate': 2.9354838709677417e-06, 'epoch': 85.32}\n",
            " 85% 10590/12400 [5:53:06<54:42,  1.81s/it]{'loss': 0.0081, 'learning_rate': 2.9193548387096775e-06, 'epoch': 85.4}\n",
            " 85% 10600/12400 [5:53:24<58:23,  1.95s/it]{'loss': 0.0249, 'learning_rate': 2.903225806451613e-06, 'epoch': 85.48}\n",
            "{'loss': 0.0058, 'learning_rate': 2.8870967741935485e-06, 'epoch': 85.56}\n",
            " 86% 10620/12400 [5:54:01<53:53,  1.82s/it]{'loss': 0.0926, 'learning_rate': 2.8709677419354843e-06, 'epoch': 85.65}\n",
            " 86% 10630/12400 [5:54:19<53:38,  1.82s/it]{'loss': 0.0323, 'learning_rate': 2.8548387096774196e-06, 'epoch': 85.73}\n",
            " 86% 10640/12400 [5:54:37<53:15,  1.82s/it]{'loss': 0.0389, 'learning_rate': 2.8387096774193553e-06, 'epoch': 85.81}\n",
            "{'loss': 0.0154, 'learning_rate': 2.822580645161291e-06, 'epoch': 85.89}\n",
            "{'loss': 0.0179, 'learning_rate': 2.806451612903226e-06, 'epoch': 85.97}\n",
            " 86% 10664/12400 [5:55:20<40:56,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 04:24:04,299 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:24:04,299 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:24:04,300 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6538001894950867, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.0835, 'eval_samples_per_second': 24.11, 'eval_steps_per_second': 1.541, 'epoch': 86.0}\n",
            " 86% 10664/12400 [5:55:29<40:56,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:24:13,385 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10664\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:24:13,387 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10664/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:24:16,775 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10664/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:24:16,776 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10664/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:24:26,450 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10416] due to args.save_total_limit\n",
            " 86% 10670/12400 [5:55:53<1:23:23,  2.89s/it]{'loss': 0.026, 'learning_rate': 2.7903225806451617e-06, 'epoch': 86.05}\n",
            "{'loss': 0.0817, 'learning_rate': 2.774193548387097e-06, 'epoch': 86.13}\n",
            "{'loss': 0.0618, 'learning_rate': 2.7580645161290327e-06, 'epoch': 86.21}\n",
            " 86% 10700/12400 [5:56:48<54:55,  1.94s/it]{'loss': 0.0103, 'learning_rate': 2.7419354838709676e-06, 'epoch': 86.29}\n",
            "{'loss': 0.0127, 'learning_rate': 2.7258064516129033e-06, 'epoch': 86.37}\n",
            "{'loss': 0.0286, 'learning_rate': 2.709677419354839e-06, 'epoch': 86.45}\n",
            "{'loss': 0.0274, 'learning_rate': 2.6935483870967744e-06, 'epoch': 86.53}\n",
            "{'loss': 0.0549, 'learning_rate': 2.67741935483871e-06, 'epoch': 86.61}\n",
            " 87% 10750/12400 [5:58:19<50:04,  1.82s/it]{'loss': 0.0652, 'learning_rate': 2.6612903225806454e-06, 'epoch': 86.69}\n",
            "{'loss': 0.0996, 'learning_rate': 2.645161290322581e-06, 'epoch': 86.77}\n",
            "{'loss': 0.0171, 'learning_rate': 2.629032258064516e-06, 'epoch': 86.85}\n",
            " 87% 10780/12400 [5:59:14<49:09,  1.82s/it]{'loss': 0.0346, 'learning_rate': 2.6129032258064518e-06, 'epoch': 86.94}\n",
            " 87% 10788/12400 [5:59:27<37:55,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 04:28:11,904 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:28:11,904 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:28:11,904 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.87it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "{'eval_loss': 0.6270046234130859, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.061, 'eval_samples_per_second': 24.17, 'eval_steps_per_second': 1.545, 'epoch': 87.0}\n",
            "\n",
            " 87% 10788/12400 [5:59:36<37:55,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:28:20,967 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10788\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:28:20,968 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10788/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:28:24,351 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10788/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:28:24,351 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10788/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:28:34,034 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10540] due to args.save_total_limit\n",
            "{'loss': 0.0055, 'learning_rate': 2.5967741935483875e-06, 'epoch': 87.02}\n",
            "{'loss': 0.0511, 'learning_rate': 2.580645161290323e-06, 'epoch': 87.1}\n",
            "{'loss': 0.0081, 'learning_rate': 2.5645161290322585e-06, 'epoch': 87.18}\n",
            "{'loss': 0.0335, 'learning_rate': 2.5483870967741934e-06, 'epoch': 87.26}\n",
            " 87% 10830/12400 [6:01:07<47:18,  1.81s/it]{'loss': 0.0048, 'learning_rate': 2.532258064516129e-06, 'epoch': 87.34}\n",
            "{'loss': 0.0627, 'learning_rate': 2.5161290322580645e-06, 'epoch': 87.42}\n",
            " 88% 10850/12400 [6:01:43<47:07,  1.82s/it]{'loss': 0.0506, 'learning_rate': 2.5e-06, 'epoch': 87.5}\n",
            "{'loss': 0.0301, 'learning_rate': 2.4838709677419355e-06, 'epoch': 87.58}\n",
            "{'loss': 0.0235, 'learning_rate': 2.4677419354838712e-06, 'epoch': 87.66}\n",
            "{'loss': 0.026, 'learning_rate': 2.4516129032258066e-06, 'epoch': 87.74}\n",
            "                                           {'loss': 0.0208, 'learning_rate': 2.4354838709677423e-06, 'epoch': 87.82}\n",
            "{'loss': 0.0154, 'learning_rate': 2.4193548387096776e-06, 'epoch': 87.9}\n",
            "{'loss': 0.0232, 'learning_rate': 2.4032258064516133e-06, 'epoch': 87.98}\n",
            " 88% 10912/12400 [6:03:35<35:19,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 04:32:19,797 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:32:19,797 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:32:19,798 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.16it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.87it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            " 88% 10912/12400 [6:03:44<35:19,  1.42s/it]\n",
            "{'eval_loss': 0.6272167563438416, 'eval_accuracy': 0.8447488584474886, 'eval_runtime': 9.0876, 'eval_samples_per_second': 24.099, 'eval_steps_per_second': 1.541, 'epoch': 88.0}\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:32:28,887 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-10912\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:32:28,889 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-10912/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:32:32,299 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-10912/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:32:32,300 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-10912/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:32:42,698 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10664] due to args.save_total_limit\n",
            "{'loss': 0.0091, 'learning_rate': 2.3870967741935486e-06, 'epoch': 88.06}\n",
            " 88% 10930/12400 [6:04:31<45:53,  1.87s/it]{'loss': 0.0137, 'learning_rate': 2.370967741935484e-06, 'epoch': 88.15}\n",
            "{'loss': 0.0182, 'learning_rate': 2.3548387096774193e-06, 'epoch': 88.23}\n",
            "{'loss': 0.002, 'learning_rate': 2.338709677419355e-06, 'epoch': 88.31}\n",
            "{'loss': 0.0274, 'learning_rate': 2.3225806451612907e-06, 'epoch': 88.39}\n",
            " 88% 10970/12400 [6:05:44<43:25,  1.82s/it]{'loss': 0.0405, 'learning_rate': 2.306451612903226e-06, 'epoch': 88.47}\n",
            "{'loss': 0.0383, 'learning_rate': 2.2903225806451614e-06, 'epoch': 88.55}\n",
            "{'loss': 0.0414, 'learning_rate': 2.274193548387097e-06, 'epoch': 88.63}\n",
            "{'loss': 0.0121, 'learning_rate': 2.2580645161290324e-06, 'epoch': 88.71}\n",
            "{'loss': 0.0045, 'learning_rate': 2.2419354838709677e-06, 'epoch': 88.79}\n",
            " 89% 11020/12400 [6:07:16<41:55,  1.82s/it]{'loss': 0.0244, 'learning_rate': 2.2258064516129034e-06, 'epoch': 88.87}\n",
            "                                           {'loss': 0.0321, 'learning_rate': 2.209677419354839e-06, 'epoch': 88.95}\n",
            " 89% 11036/12400 [6:07:44<32:09,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 04:36:28,253 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:36:28,254 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:36:28,254 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.6139584183692932, 'eval_accuracy': 0.8538812785388128, 'eval_runtime': 9.0682, 'eval_samples_per_second': 24.15, 'eval_steps_per_second': 1.544, 'epoch': 89.0}\n",
            " 89% 11036/12400 [6:07:53<32:09,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:36:37,324 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11036\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:36:37,327 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11036/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:36:40,880 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11036/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:36:40,880 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11036/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:36:50,434 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10788] due to args.save_total_limit\n",
            " 89% 11040/12400 [6:08:13<1:30:53,  4.01s/it]{'loss': 0.0065, 'learning_rate': 2.1935483870967745e-06, 'epoch': 89.03}\n",
            " 89% 11050/12400 [6:08:31<42:44,  1.90s/it]{'loss': 0.0378, 'learning_rate': 2.17741935483871e-06, 'epoch': 89.11}\n",
            " 89% 11060/12400 [6:08:50<41:21,  1.85s/it]{'loss': 0.0353, 'learning_rate': 2.161290322580645e-06, 'epoch': 89.19}\n",
            "{'loss': 0.0226, 'learning_rate': 2.145161290322581e-06, 'epoch': 89.27}\n",
            "{'loss': 0.0459, 'learning_rate': 2.129032258064516e-06, 'epoch': 89.35}\n",
            "{'loss': 0.0052, 'learning_rate': 2.112903225806452e-06, 'epoch': 89.44}\n",
            " 90% 11100/12400 [6:10:03<42:05,  1.94s/it]{'loss': 0.0224, 'learning_rate': 2.096774193548387e-06, 'epoch': 89.52}\n",
            " 90% 11110/12400 [6:10:21<39:14,  1.82s/it]{'loss': 0.0206, 'learning_rate': 2.080645161290323e-06, 'epoch': 89.6}\n",
            "{'loss': 0.0707, 'learning_rate': 2.0645161290322582e-06, 'epoch': 89.68}\n",
            "{'loss': 0.0233, 'learning_rate': 2.0483870967741936e-06, 'epoch': 89.76}\n",
            "{'loss': 0.0487, 'learning_rate': 2.0322580645161293e-06, 'epoch': 89.84}\n",
            " 90% 11150/12400 [6:11:34<37:52,  1.82s/it]{'loss': 0.0358, 'learning_rate': 2.0161290322580646e-06, 'epoch': 89.92}\n",
            "{'loss': 0.0285, 'learning_rate': 2.0000000000000003e-06, 'epoch': 90.0}\n",
            " 90% 11160/12400 [6:11:51<29:07,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 04:40:35,778 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:40:35,779 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:40:35,779 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:04,  3.00it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.55it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            " 90% 11160/12400 [6:12:00<29:07,  1.41s/it]\n",
            "{'eval_loss': 0.6113823056221008, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.093, 'eval_samples_per_second': 24.084, 'eval_steps_per_second': 1.54, 'epoch': 90.0}\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:40:44,874 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11160\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:40:44,876 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11160/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:40:48,297 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11160/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:40:48,298 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11160/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:40:58,075 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-10912] due to args.save_total_limit\n",
            "{'loss': 0.0566, 'learning_rate': 1.9838709677419356e-06, 'epoch': 90.08}\n",
            " 90% 11180/12400 [6:12:50<38:03,  1.87s/it]{'loss': 0.0723, 'learning_rate': 1.967741935483871e-06, 'epoch': 90.16}\n",
            "{'loss': 0.0052, 'learning_rate': 1.9516129032258067e-06, 'epoch': 90.24}\n",
            "{'loss': 0.0398, 'learning_rate': 1.935483870967742e-06, 'epoch': 90.32}\n",
            "{'loss': 0.0107, 'learning_rate': 1.9193548387096773e-06, 'epoch': 90.4}\n",
            "{'loss': 0.0467, 'learning_rate': 1.9032258064516128e-06, 'epoch': 90.48}\n",
            " 91% 11230/12400 [6:14:22<35:33,  1.82s/it]{'loss': 0.0561, 'learning_rate': 1.8870967741935486e-06, 'epoch': 90.56}\n",
            "{'loss': 0.059, 'learning_rate': 1.870967741935484e-06, 'epoch': 90.65}\n",
            "{'loss': 0.0087, 'learning_rate': 1.8548387096774196e-06, 'epoch': 90.73}\n",
            " 91% 11260/12400 [6:15:17<34:38,  1.82s/it]{'loss': 0.0257, 'learning_rate': 1.838709677419355e-06, 'epoch': 90.81}\n",
            "{'loss': 0.0028, 'learning_rate': 1.8225806451612904e-06, 'epoch': 90.89}\n",
            " 91% 11280/12400 [6:15:53<33:55,  1.82s/it]{'loss': 0.0061, 'learning_rate': 1.8064516129032258e-06, 'epoch': 90.97}\n",
            " 91% 11284/12400 [6:15:59<26:19,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 04:44:43,729 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:44:43,729 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:44:43,729 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            "{'eval_loss': 0.6133231520652771, 'eval_accuracy': 0.8493150684931506, 'eval_runtime': 9.0588, 'eval_samples_per_second': 24.175, 'eval_steps_per_second': 1.545, 'epoch': 91.0}\n",
            " 91% 11284/12400 [6:16:08<26:19,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:44:52,790 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11284\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:44:52,792 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11284/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:44:56,162 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11284/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:44:56,163 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11284/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:45:05,881 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11036] due to args.save_total_limit\n",
            "{'loss': 0.0616, 'learning_rate': 1.7903225806451615e-06, 'epoch': 91.05}\n",
            " 91% 11300/12400 [6:16:51<36:43,  2.00s/it]{'loss': 0.0481, 'learning_rate': 1.774193548387097e-06, 'epoch': 91.13}\n",
            "{'loss': 0.039, 'learning_rate': 1.7580645161290325e-06, 'epoch': 91.21}\n",
            " 91% 11320/12400 [6:17:28<32:42,  1.82s/it]{'loss': 0.0225, 'learning_rate': 1.7419354838709678e-06, 'epoch': 91.29}\n",
            "{'loss': 0.0302, 'learning_rate': 1.7258064516129034e-06, 'epoch': 91.37}\n",
            "{'loss': 0.0956, 'learning_rate': 1.7096774193548387e-06, 'epoch': 91.45}\n",
            " 92% 11350/12400 [6:18:22<31:51,  1.82s/it]{'loss': 0.0378, 'learning_rate': 1.6935483870967742e-06, 'epoch': 91.53}\n",
            " 92% 11360/12400 [6:18:41<31:33,  1.82s/it]{'loss': 0.0342, 'learning_rate': 1.67741935483871e-06, 'epoch': 91.61}\n",
            " 92% 11370/12400 [6:18:59<31:13,  1.82s/it]{'loss': 0.0246, 'learning_rate': 1.6612903225806455e-06, 'epoch': 91.69}\n",
            " 92% 11380/12400 [6:19:17<30:55,  1.82s/it]{'loss': 0.0037, 'learning_rate': 1.6451612903225808e-06, 'epoch': 91.77}\n",
            "{'loss': 0.0549, 'learning_rate': 1.6290322580645163e-06, 'epoch': 91.85}\n",
            "{'loss': 0.031, 'learning_rate': 1.6129032258064516e-06, 'epoch': 91.94}\n",
            " 92% 11408/12400 [6:20:07<23:31,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 04:48:51,760 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:48:51,760 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:48:51,760 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.66it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            " 92% 11408/12400 [6:20:16<23:31,  1.42s/it]\n",
            "{'eval_loss': 0.6024812459945679, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.0531, 'eval_samples_per_second': 24.191, 'eval_steps_per_second': 1.546, 'epoch': 92.0}\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:49:00,815 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11408\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:49:00,817 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11408/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:49:04,318 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11408/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:49:04,319 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11408/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:49:13,844 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11160] due to args.save_total_limit\n",
            "{'loss': 0.0176, 'learning_rate': 1.5967741935483871e-06, 'epoch': 92.02}\n",
            " 92% 11420/12400 [6:20:51<32:05,  1.96s/it]{'loss': 0.0048, 'learning_rate': 1.5806451612903226e-06, 'epoch': 92.1}\n",
            "{'loss': 0.0057, 'learning_rate': 1.5645161290322584e-06, 'epoch': 92.18}\n",
            "{'loss': 0.0246, 'learning_rate': 1.5483870967741937e-06, 'epoch': 92.26}\n",
            " 92% 11450/12400 [6:21:46<28:36,  1.81s/it]{'loss': 0.0675, 'learning_rate': 1.5322580645161292e-06, 'epoch': 92.34}\n",
            "{'loss': 0.0322, 'learning_rate': 1.5161290322580647e-06, 'epoch': 92.42}\n",
            "{'loss': 0.0751, 'learning_rate': 1.5e-06, 'epoch': 92.5}\n",
            " 93% 11480/12400 [6:22:41<27:55,  1.82s/it]{'loss': 0.0081, 'learning_rate': 1.4838709677419356e-06, 'epoch': 92.58}\n",
            "{'loss': 0.024, 'learning_rate': 1.4677419354838709e-06, 'epoch': 92.66}\n",
            "                                           {'loss': 0.0339, 'learning_rate': 1.4516129032258066e-06, 'epoch': 92.74}\n",
            " 93% 11510/12400 [6:23:36<27:01,  1.82s/it]{'loss': 0.0363, 'learning_rate': 1.4354838709677421e-06, 'epoch': 92.82}\n",
            " 93% 11520/12400 [6:23:54<26:37,  1.82s/it]{'loss': 0.0321, 'learning_rate': 1.4193548387096776e-06, 'epoch': 92.9}\n",
            "{'loss': 0.0028, 'learning_rate': 1.403225806451613e-06, 'epoch': 92.98}\n",
            " 93% 11532/12400 [6:24:15<20:23,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 04:52:59,191 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:52:59,191 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:52:59,191 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.54it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.5984054207801819, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.0483, 'eval_samples_per_second': 24.204, 'eval_steps_per_second': 1.547, 'epoch': 93.0}\n",
            " 93% 11532/12400 [6:24:24<20:23,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:53:08,241 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11532\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:53:08,243 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11532/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:53:11,620 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11532/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:53:11,621 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11532/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:53:21,349 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11284] due to args.save_total_limit\n",
            " 93% 11540/12400 [6:24:51<33:34,  2.34s/it]{'loss': 0.0442, 'learning_rate': 1.3870967741935485e-06, 'epoch': 93.06}\n",
            "{'loss': 0.0892, 'learning_rate': 1.3709677419354838e-06, 'epoch': 93.15}\n",
            "{'loss': 0.0337, 'learning_rate': 1.3548387096774195e-06, 'epoch': 93.23}\n",
            " 93% 11570/12400 [6:25:47<25:02,  1.81s/it]{'loss': 0.0239, 'learning_rate': 1.338709677419355e-06, 'epoch': 93.31}\n",
            "{'loss': 0.0501, 'learning_rate': 1.3225806451612906e-06, 'epoch': 93.39}\n",
            " 93% 11590/12400 [6:26:23<24:37,  1.82s/it]{'loss': 0.0089, 'learning_rate': 1.3064516129032259e-06, 'epoch': 93.47}\n",
            "                                           {'loss': 0.0642, 'learning_rate': 1.2903225806451614e-06, 'epoch': 93.55}\n",
            "{'loss': 0.002, 'learning_rate': 1.2741935483870967e-06, 'epoch': 93.63}\n",
            " 94% 11620/12400 [6:27:18<23:40,  1.82s/it]{'loss': 0.0524, 'learning_rate': 1.2580645161290322e-06, 'epoch': 93.71}\n",
            "{'loss': 0.0412, 'learning_rate': 1.2419354838709678e-06, 'epoch': 93.79}\n",
            "{'loss': 0.0483, 'learning_rate': 1.2258064516129033e-06, 'epoch': 93.87}\n",
            "{'loss': 0.1194, 'learning_rate': 1.2096774193548388e-06, 'epoch': 93.95}\n",
            " 94% 11656/12400 [6:28:22<17:33,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 04:57:06,818 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 04:57:06,818 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 04:57:06,818 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.02it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.14it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            "{'eval_loss': 0.590933620929718, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.0947, 'eval_samples_per_second': 24.08, 'eval_steps_per_second': 1.539, 'epoch': 94.0}\n",
            " 94% 11656/12400 [6:28:31<17:33,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 04:57:15,915 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11656\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 04:57:15,918 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11656/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 04:57:19,544 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11656/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 04:57:19,545 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11656/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 04:57:29,056 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11408] due to args.save_total_limit\n",
            "{'loss': 0.0026, 'learning_rate': 1.1935483870967743e-06, 'epoch': 94.03}\n",
            " 94% 11670/12400 [6:29:10<23:08,  1.90s/it]{'loss': 0.0559, 'learning_rate': 1.1774193548387096e-06, 'epoch': 94.11}\n",
            " 94% 11680/12400 [6:29:29<22:17,  1.86s/it]{'loss': 0.0537, 'learning_rate': 1.1612903225806454e-06, 'epoch': 94.19}\n",
            "{'loss': 0.036, 'learning_rate': 1.1451612903225807e-06, 'epoch': 94.27}\n",
            "{'loss': 0.0231, 'learning_rate': 1.1290322580645162e-06, 'epoch': 94.35}\n",
            " 94% 11710/12400 [6:30:24<20:55,  1.82s/it]{'loss': 0.0226, 'learning_rate': 1.1129032258064517e-06, 'epoch': 94.44}\n",
            "{'loss': 0.06, 'learning_rate': 1.0967741935483872e-06, 'epoch': 94.52}\n",
            " 95% 11730/12400 [6:31:00<20:22,  1.82s/it]{'loss': 0.0049, 'learning_rate': 1.0806451612903226e-06, 'epoch': 94.6}\n",
            "{'loss': 0.0293, 'learning_rate': 1.064516129032258e-06, 'epoch': 94.68}\n",
            "{'loss': 0.048, 'learning_rate': 1.0483870967741936e-06, 'epoch': 94.76}\n",
            " 95% 11760/12400 [6:31:55<19:21,  1.81s/it]{'loss': 0.0553, 'learning_rate': 1.0322580645161291e-06, 'epoch': 94.84}\n",
            " 95% 11770/12400 [6:32:13<19:06,  1.82s/it]{'loss': 0.035, 'learning_rate': 1.0161290322580646e-06, 'epoch': 94.92}\n",
            "{'loss': 0.0659, 'learning_rate': 1.0000000000000002e-06, 'epoch': 95.0}\n",
            " 95% 11780/12400 [6:32:30<14:35,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 05:01:14,426 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:01:14,426 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:01:14,426 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.87it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.66it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            "{'eval_loss': 0.59425288438797, 'eval_accuracy': 0.8584474885844748, 'eval_runtime': 9.0639, 'eval_samples_per_second': 24.162, 'eval_steps_per_second': 1.545, 'epoch': 95.0}\n",
            " 95% 11780/12400 [6:32:39<14:35,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 05:01:23,492 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11780\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:01:23,494 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11780/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:01:26,912 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11780/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:01:26,913 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11780/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 05:01:36,593 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11532] due to args.save_total_limit\n",
            "{'loss': 0.024, 'learning_rate': 9.838709677419355e-07, 'epoch': 95.08}\n",
            "{'loss': 0.0461, 'learning_rate': 9.67741935483871e-07, 'epoch': 95.16}\n",
            " 95% 11810/12400 [6:33:48<17:57,  1.83s/it]{'loss': 0.0183, 'learning_rate': 9.516129032258064e-07, 'epoch': 95.24}\n",
            "{'loss': 0.0237, 'learning_rate': 9.35483870967742e-07, 'epoch': 95.32}\n",
            "{'loss': 0.033, 'learning_rate': 9.193548387096775e-07, 'epoch': 95.4}\n",
            "{'loss': 0.0157, 'learning_rate': 9.032258064516129e-07, 'epoch': 95.48}\n",
            " 96% 11850/12400 [6:35:00<16:42,  1.82s/it]{'loss': 0.0332, 'learning_rate': 8.870967741935485e-07, 'epoch': 95.56}\n",
            "                                           {'loss': 0.0095, 'learning_rate': 8.709677419354839e-07, 'epoch': 95.65}\n",
            "{'loss': 0.0018, 'learning_rate': 8.548387096774193e-07, 'epoch': 95.73}\n",
            "{'loss': 0.0897, 'learning_rate': 8.38709677419355e-07, 'epoch': 95.81}\n",
            "{'loss': 0.0053, 'learning_rate': 8.225806451612904e-07, 'epoch': 95.89}\n",
            " 96% 11900/12400 [6:36:32<16:05,  1.93s/it]{'loss': 0.0319, 'learning_rate': 8.064516129032258e-07, 'epoch': 95.97}\n",
            " 96% 11904/12400 [6:36:38<11:57,  1.45s/it][INFO|trainer.py:2463] 2022-05-04 05:05:22,481 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:05:22,481 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:05:22,481 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.05it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.16it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.87it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.597434401512146, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.0784, 'eval_samples_per_second': 24.123, 'eval_steps_per_second': 1.542, 'epoch': 96.0}\n",
            " 96% 11904/12400 [6:36:47<11:57,  1.45s/it]\n",
            "100% 14/14 [00:08<00:00,  1.63it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 05:05:31,562 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-11904\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:05:31,563 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-11904/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:05:34,947 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-11904/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:05:34,948 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-11904/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 05:05:44,602 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11656] due to args.save_total_limit\n",
            "{'loss': 0.0835, 'learning_rate': 7.903225806451613e-07, 'epoch': 96.05}\n",
            "{'loss': 0.0489, 'learning_rate': 7.741935483870968e-07, 'epoch': 96.13}\n",
            " 96% 11930/12400 [6:37:48<14:24,  1.84s/it]{'loss': 0.0146, 'learning_rate': 7.580645161290324e-07, 'epoch': 96.21}\n",
            " 96% 11940/12400 [6:38:06<13:56,  1.82s/it]{'loss': 0.0344, 'learning_rate': 7.419354838709678e-07, 'epoch': 96.29}\n",
            "{'loss': 0.0085, 'learning_rate': 7.258064516129033e-07, 'epoch': 96.37}\n",
            "{'loss': 0.0618, 'learning_rate': 7.096774193548388e-07, 'epoch': 96.45}\n",
            " 97% 11970/12400 [6:39:01<13:03,  1.82s/it]{'loss': 0.0755, 'learning_rate': 6.935483870967742e-07, 'epoch': 96.53}\n",
            " 97% 11980/12400 [6:39:19<12:45,  1.82s/it]{'loss': 0.0521, 'learning_rate': 6.774193548387098e-07, 'epoch': 96.61}\n",
            " 97% 11990/12400 [6:39:37<12:25,  1.82s/it]{'loss': 0.0083, 'learning_rate': 6.612903225806453e-07, 'epoch': 96.69}\n",
            "{'loss': 0.0425, 'learning_rate': 6.451612903225807e-07, 'epoch': 96.77}\n",
            " 97% 12010/12400 [6:40:14<11:52,  1.83s/it]{'loss': 0.0584, 'learning_rate': 6.290322580645161e-07, 'epoch': 96.85}\n",
            " 97% 12020/12400 [6:40:32<11:31,  1.82s/it]{'loss': 0.0066, 'learning_rate': 6.129032258064516e-07, 'epoch': 96.94}\n",
            " 97% 12028/12400 [6:40:45<08:46,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 05:09:30,079 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:09:30,080 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:09:30,080 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.15it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.73it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.65it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.52it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.52it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.5967830419540405, 'eval_accuracy': 0.867579908675799, 'eval_runtime': 9.0861, 'eval_samples_per_second': 24.103, 'eval_steps_per_second': 1.541, 'epoch': 97.0}\n",
            " 97% 12028/12400 [6:40:55<08:46,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 05:09:39,168 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-12028\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:09:39,171 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-12028/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:09:42,826 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-12028/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:09:42,827 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-12028/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 05:09:52,330 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11780] due to args.save_total_limit\n",
            " 97% 12030/12400 [6:41:11<38:58,  6.32s/it]{'loss': 0.0585, 'learning_rate': 5.967741935483872e-07, 'epoch': 97.02}\n",
            " 97% 12040/12400 [6:41:30<11:45,  1.96s/it]{'loss': 0.0194, 'learning_rate': 5.806451612903227e-07, 'epoch': 97.1}\n",
            "{'loss': 0.0421, 'learning_rate': 5.645161290322581e-07, 'epoch': 97.18}\n",
            "{'loss': 0.0158, 'learning_rate': 5.483870967741936e-07, 'epoch': 97.26}\n",
            " 97% 12070/12400 [6:42:25<09:55,  1.81s/it]{'loss': 0.0102, 'learning_rate': 5.32258064516129e-07, 'epoch': 97.34}\n",
            "{'loss': 0.1001, 'learning_rate': 5.161290322580646e-07, 'epoch': 97.42}\n",
            "{'loss': 0.0416, 'learning_rate': 5.000000000000001e-07, 'epoch': 97.5}\n",
            "{'loss': 0.0495, 'learning_rate': 4.838709677419355e-07, 'epoch': 97.58}\n",
            " 98% 12110/12400 [6:43:38<08:49,  1.83s/it]{'loss': 0.0487, 'learning_rate': 4.67741935483871e-07, 'epoch': 97.66}\n",
            "{'loss': 0.003, 'learning_rate': 4.5161290322580644e-07, 'epoch': 97.74}\n",
            " 98% 12130/12400 [6:44:14<08:11,  1.82s/it]{'loss': 0.0183, 'learning_rate': 4.3548387096774196e-07, 'epoch': 97.82}\n",
            "{'loss': 0.0042, 'learning_rate': 4.193548387096775e-07, 'epoch': 97.9}\n",
            "{'loss': 0.0673, 'learning_rate': 4.032258064516129e-07, 'epoch': 97.98}\n",
            " 98% 12152/12400 [6:44:53<05:52,  1.42s/it][INFO|trainer.py:2463] 2022-05-04 05:13:37,700 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:13:37,700 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:13:37,700 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            " 98% 12152/12400 [6:45:02<05:52,  1.42s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 05:13:46,782 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-12152\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:13:46,785 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-12152/config.json\n",
            "{'eval_loss': 0.5933355689048767, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.08, 'eval_samples_per_second': 24.119, 'eval_steps_per_second': 1.542, 'epoch': 98.0}\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:13:50,187 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-12152/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:13:50,188 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-12152/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 05:13:59,838 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-11904] due to args.save_total_limit\n",
            "{'loss': 0.0206, 'learning_rate': 3.870967741935484e-07, 'epoch': 98.06}\n",
            "{'loss': 0.0581, 'learning_rate': 3.709677419354839e-07, 'epoch': 98.15}\n",
            "{'loss': 0.0509, 'learning_rate': 3.548387096774194e-07, 'epoch': 98.23}\n",
            " 98% 12190/12400 [6:46:25<06:19,  1.81s/it]{'loss': 0.0422, 'learning_rate': 3.387096774193549e-07, 'epoch': 98.31}\n",
            "{'loss': 0.0255, 'learning_rate': 3.2258064516129035e-07, 'epoch': 98.39}\n",
            "{'loss': 0.0094, 'learning_rate': 3.064516129032258e-07, 'epoch': 98.47}\n",
            "{'loss': 0.0668, 'learning_rate': 2.9032258064516134e-07, 'epoch': 98.55}\n",
            " 99% 12230/12400 [6:47:38<05:09,  1.82s/it]{'loss': 0.0322, 'learning_rate': 2.741935483870968e-07, 'epoch': 98.63}\n",
            "{'loss': 0.0293, 'learning_rate': 2.580645161290323e-07, 'epoch': 98.71}\n",
            "{'loss': 0.0051, 'learning_rate': 2.4193548387096775e-07, 'epoch': 98.79}\n",
            "{'loss': 0.0017, 'learning_rate': 2.2580645161290322e-07, 'epoch': 98.87}\n",
            " 99% 12270/12400 [6:48:51<03:56,  1.82s/it]{'loss': 0.0205, 'learning_rate': 2.0967741935483874e-07, 'epoch': 98.95}\n",
            " 99% 12276/12400 [6:49:01<02:55,  1.41s/it][INFO|trainer.py:2463] 2022-05-04 05:17:45,254 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:17:45,254 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:17:45,254 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.04it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.11it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.85it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.61it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.58it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.55it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.54it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.53it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.5935453176498413, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.0585, 'eval_samples_per_second': 24.176, 'eval_steps_per_second': 1.546, 'epoch': 99.0}\n",
            " 99% 12276/12400 [6:49:10<02:55,  1.41s/it]\n",
            "100% 14/14 [00:08<00:00,  1.65it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 05:17:54,315 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-12276\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:17:54,318 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-12276/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:17:57,707 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-12276/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:17:57,708 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-12276/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 05:18:07,470 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-12028] due to args.save_total_limit\n",
            "{'loss': 0.0258, 'learning_rate': 1.935483870967742e-07, 'epoch': 99.03}\n",
            " 99% 12290/12400 [6:49:49<03:29,  1.91s/it]{'loss': 0.0027, 'learning_rate': 1.774193548387097e-07, 'epoch': 99.11}\n",
            " 99% 12300/12400 [6:50:08<03:16,  1.97s/it]{'loss': 0.0353, 'learning_rate': 1.6129032258064518e-07, 'epoch': 99.19}\n",
            " 99% 12310/12400 [6:50:26<02:43,  1.82s/it]{'loss': 0.0536, 'learning_rate': 1.4516129032258067e-07, 'epoch': 99.27}\n",
            "{'loss': 0.0351, 'learning_rate': 1.2903225806451614e-07, 'epoch': 99.35}\n",
            " 99% 12330/12400 [6:51:02<02:07,  1.82s/it]{'loss': 0.1124, 'learning_rate': 1.1290322580645161e-07, 'epoch': 99.44}\n",
            "{'loss': 0.1056, 'learning_rate': 9.67741935483871e-08, 'epoch': 99.52}\n",
            "100% 12350/12400 [6:51:39<01:31,  1.82s/it]{'loss': 0.0071, 'learning_rate': 8.064516129032259e-08, 'epoch': 99.6}\n",
            "{'loss': 0.0074, 'learning_rate': 6.451612903225807e-08, 'epoch': 99.68}\n",
            "{'loss': 0.0303, 'learning_rate': 4.838709677419355e-08, 'epoch': 99.76}\n",
            "{'loss': 0.0254, 'learning_rate': 3.2258064516129035e-08, 'epoch': 99.84}\n",
            "{'loss': 0.0108, 'learning_rate': 1.6129032258064518e-08, 'epoch': 99.92}\n",
            "100% 12400/12400 [6:53:09<00:00,  1.55s/it]{'loss': 0.0382, 'learning_rate': 0.0, 'epoch': 100.0}\n",
            "100% 12400/12400 [6:53:09<00:00,  1.55s/it][INFO|trainer.py:2463] 2022-05-04 05:21:53,462 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:21:53,462 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:21:53,463 >>   Batch size = 16\n",
            "\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 14% 2/14 [00:00<00:03,  3.03it/s]\u001b[A\n",
            " 21% 3/14 [00:01<00:05,  2.13it/s]\u001b[A\n",
            " 29% 4/14 [00:01<00:05,  1.86it/s]\u001b[A\n",
            " 36% 5/14 [00:02<00:05,  1.72it/s]\u001b[A\n",
            " 43% 6/14 [00:03<00:04,  1.64it/s]\u001b[A\n",
            " 50% 7/14 [00:03<00:04,  1.60it/s]\u001b[A\n",
            " 57% 8/14 [00:04<00:03,  1.57it/s]\u001b[A\n",
            " 64% 9/14 [00:05<00:03,  1.56it/s]\u001b[A\n",
            " 71% 10/14 [00:05<00:02,  1.54it/s]\u001b[A\n",
            " 79% 11/14 [00:06<00:01,  1.53it/s]\u001b[A\n",
            " 86% 12/14 [00:07<00:01,  1.53it/s]\u001b[A\n",
            " 93% 13/14 [00:07<00:00,  1.52it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 0.5904573202133179, 'eval_accuracy': 0.863013698630137, 'eval_runtime': 9.1197, 'eval_samples_per_second': 24.014, 'eval_steps_per_second': 1.535, 'epoch': 100.0}\n",
            "100% 12400/12400 [6:53:18<00:00,  1.55s/it]\n",
            "100% 14/14 [00:08<00:00,  1.64it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2213] 2022-05-04 05:22:02,584 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/checkpoint-12400\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:22:02,586 >> Configuration saved in ./orchid219_vit-mae-large_ft/checkpoint-12400/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:22:06,340 >> Model weights saved in ./orchid219_vit-mae-large_ft/checkpoint-12400/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:22:06,340 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/checkpoint-12400/preprocessor_config.json\n",
            "[INFO|trainer.py:2291] 2022-05-04 05:22:15,840 >> Deleting older checkpoint [orchid219_vit-mae-large_ft/checkpoint-12152] due to args.save_total_limit\n",
            "[INFO|trainer.py:1537] 2022-05-04 05:22:15,979 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1602] 2022-05-04 05:22:15,979 >> Loading best model from ./orchid219_vit-mae-large_ft/checkpoint-5208 (score: 0.5173339247703552).\n",
            "100% 12400/12400 [6:53:38<00:00,  1.55s/it]{'train_runtime': 24825.8939, 'train_samples_per_second': 7.939, 'train_steps_per_second': 0.499, 'train_loss': 0.3382355524066295, 'epoch': 100.0}\n",
            "100% 12400/12400 [6:53:38<00:00,  2.00s/it]\n",
            "[INFO|trainer.py:2213] 2022-05-04 05:22:22,467 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:22:22,469 >> Configuration saved in ./orchid219_vit-mae-large_ft/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:22:26,129 >> Model weights saved in ./orchid219_vit-mae-large_ft/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:22:26,130 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/preprocessor_config.json\n",
            "[INFO|trainer.py:2213] 2022-05-04 05:22:26,131 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:22:26,133 >> Configuration saved in ./orchid219_vit-mae-large_ft/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:22:30,968 >> Model weights saved in ./orchid219_vit-mae-large_ft/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:22:30,969 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/preprocessor_config.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "05/04/2022 05:23:01 - WARNING - huggingface_hub.repository - Several commits (2) will be pushed upstream.\n",
            "05/04/2022 05:23:01 - WARNING - huggingface_hub.repository - The progress bars may be unreliable.\n",
            "The progress bars may be unreliable.\n",
            "Upload file pytorch_model.bin:   0% 3.33k/1.13G [00:00<?, ?B/s]\n",
            "Upload file pytorch_model.bin:   0% 495k/1.13G [00:01<40:13, 503kB/s]\n",
            "Upload file pytorch_model.bin:   2% 20.2M/1.13G [00:18<16:58, 1.17MB/s]\n",
            "Upload file pytorch_model.bin: 100% 1.13G/1.13G [14:53<00:00, 1.37MB/s]To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   208f91d..e2a8d66  main -> main\n",
            "\n",
            "05/04/2022 05:38:04 - WARNING - huggingface_hub.repository - To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   208f91d..e2a8d66  main -> main\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 1.13G/1.13G [14:56<00:00, 1.35MB/s]\n",
            "\n",
            "Upload file runs/May03_22-28-11_45fd5c3a3736/events.out.tfevents.1651616916.45fd5c3a3736.1352.0: 100% 232k/232k [14:56<00:00, 226B/s] \u001b[A\n",
            "Upload file runs/May03_22-28-11_45fd5c3a3736/events.out.tfevents.1651616916.45fd5c3a3736.1352.0: 100% 232k/232k [14:56<00:00, 262B/s]\n",
            "To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   e2a8d66..5fb72fa  main -> main\n",
            "\n",
            "05/04/2022 05:38:13 - WARNING - huggingface_hub.repository - To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   e2a8d66..5fb72fa  main -> main\n",
            "\n",
            "***** train metrics *****\n",
            "  epoch                    =      100.0\n",
            "  train_loss               =     0.3382\n",
            "  train_runtime            = 6:53:45.89\n",
            "  train_samples_per_second =      7.939\n",
            "  train_steps_per_second   =      0.499\n",
            "[INFO|trainer.py:2463] 2022-05-04 05:38:16,543 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2465] 2022-05-04 05:38:16,544 >>   Num examples = 219\n",
            "[INFO|trainer.py:2468] 2022-05-04 05:38:16,544 >>   Batch size = 16\n",
            "100% 14/14 [00:07<00:00,  1.74it/s]***** eval metrics *****\n",
            "  epoch                   =      100.0\n",
            "100% 14/14 [00:08<00:00,  1.74it/s]\n",
            "  eval_accuracy           =     0.8493\n",
            "  eval_loss               =     0.5173\n",
            "  eval_runtime            = 0:00:08.70\n",
            "  eval_samples_per_second =     25.169\n",
            "  eval_steps_per_second   =      1.609\n",
            "[INFO|trainer.py:2213] 2022-05-04 05:38:25,275 >> Saving model checkpoint to ./orchid219_vit-mae-large_ft/\n",
            "[INFO|configuration_utils.py:446] 2022-05-04 05:38:25,277 >> Configuration saved in ./orchid219_vit-mae-large_ft/config.json\n",
            "[INFO|modeling_utils.py:1542] 2022-05-04 05:38:30,210 >> Model weights saved in ./orchid219_vit-mae-large_ft/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-05-04 05:38:30,211 >> Feature extractor saved in ./orchid219_vit-mae-large_ft/preprocessor_config.json\n",
            "Upload file runs/May03_22-28-11_45fd5c3a3736/events.out.tfevents.1651642705.45fd5c3a3736.1352.2: 100% 363/363 [00:00<?, ?B/s]To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   5fb72fa..3530eec  main -> main\n",
            "\n",
            "05/04/2022 05:38:46 - WARNING - huggingface_hub.repository - To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   5fb72fa..3530eec  main -> main\n",
            "\n",
            "Upload file runs/May03_22-28-11_45fd5c3a3736/events.out.tfevents.1651642705.45fd5c3a3736.1352.2: 100% 363/363 [00:03<?, ?B/s]\n",
            "To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   3530eec..b63c435  main -> main\n",
            "\n",
            "05/04/2022 05:38:56 - WARNING - huggingface_hub.repository - To https://huggingface.co/gary109/orchid219_vit-mae-large\n",
            "   3530eec..b63c435  main -> main\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▃▆▇▇▇▇▇██▇██▇██████████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▆▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▆█▅▆▆▇▅▆▆▆▆▆▆▆▅▆▅▆▅▅▆▆▆▆▅▅▅▆▆▅▅▆▅▆▅▆▅▅▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▃▁▄▃▃▂▃▃▃▃▃▃▃▃▄▃▃▃▄▄▃▃▃▃▄▃▄▃▃▄▃▃▄▃▃▃▄▄▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▁▄▃▃▂▃▃▃▃▃▃▃▃▃▃▃▃▄▄▃▃▃▃▄▃▃▃▃▄▃▃▃▃▃▃▄▄▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.84932\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.51733\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 8.7011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 25.169\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.609\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 100.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 12400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0382\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 5.403202170707484e+19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.33824\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 24825.8939\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 7.939\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.499\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33m./orchid219_vit-mae-large_ft/\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/gary109/huggingface/runs/2xthn2ny\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220503_222840-2xthn2ny/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## facebook/data2vec-vision-base-ft1k\n",
        "---"
      ],
      "metadata": {
        "id": "Zl3ycpATNA-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"facebook/data2vec-vision-base\" \\\n",
        "    --output_dir=\"./orchid219_data2vec-vision-base\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id=\"orchid219_data2vec-vision-base\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 5 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337 \n",
        "    # --cache_dir=\"./cache_data2vec-vision-base-ft1k\"\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing\n",
        "\n",
        "# --model_name_or_path \"gary109/orchid219_pretrain_vit-base-patch16-224-in21k-mae\" \\\n",
        "    #orchid219_pretrain_vit-base-patch16-224-in21k-mae\n",
        "    # --model_name_or_path \"gary109/orchid219_vit-base-patch16-224-in21k\" "
      ],
      "metadata": {
        "id": "HYRn6_6PNAaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Others\n",
        "---\n",
        "- google/vit-base-patch16-224\n",
        "- google/vit-base-patch16-384\n",
        "- google/vit-base-patch32-384\n",
        "\n",
        "- google/vit-large-patch16-384\n",
        "- google/vit-large-patch16-224\n",
        "- google/vit-large-patch32-384"
      ],
      "metadata": {
        "id": "wVPViAfE4vc6"
      }
    }
  ]
}